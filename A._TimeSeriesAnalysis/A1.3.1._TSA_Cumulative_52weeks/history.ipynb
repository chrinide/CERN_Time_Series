{
 "metadata": {
  "name": "/ipykee/workdir/tmpCD26Vg/A"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load original data\n",
      "data = pd.read_excel('popularity-728days_my.xls')\n",
      "data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load original data\n",
      "data = pd.read_excel('../../popularity-728days_my.xls')\n",
      "data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load results of forecast of rolling mean time series\n",
      "data_res = pd.read_csv('../../Cern_Time_Series/df_predict_labeled_1year_6month_cumulative_10_014.csv')\n",
      "data_res.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Select data\n",
      "selection = ((data['Now'] - data['Creation-week']) > 52)&((data['Now'] - data['FirstUsage']) > 52)&((data[52] - data[1]) != 0)\n",
      "data_res_sel = data_res[selection].copy()\n",
      "#data_sel = data.copy()\n",
      "\n",
      "data_res_sel.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Data modification\n",
      "data_res_sel['slope_rel'] = data_res_sel.get(['slope'])/data_res_sel.get(['slope_std']).values\n",
      "data_res_sel['y_0_rel'] = data_res_sel.get(['y_0'])/data_res_sel.get(['y_0_std']).values\n",
      "data_res_sel['y_1_rel'] = data_res_sel.get(['y_1'])/data_res_sel.get(['y_1_std']).values\n",
      "data_res_sel['y_f_rel'] = data_res_sel.get(['y_f'])/data_res_sel.get(['y_f_std']).values\n",
      "data_res_sel['DiskSize'] = data[selection].get('DiskSize').values\n",
      "data_res_sel['LFNSize'] = data[selection].get('LFNSize').values\n",
      "data_res_sel['Nb Replicas'] = data[selection].get('Nb Replicas').values\n",
      "data_res_sel.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Preparing signal and background data for classifier\n",
      "data_sig = data_res_sel[data_res_sel.LabelReal == 1]\n",
      "data_bck = data_res_sel[data_res_sel.LabelReal == 0]\n",
      "\n",
      "#save signal and background data for classifier\n",
      "data_sig.to_csv('../../Cern_Time_Series/Classification/data_sig_res_1year_6month_cumulative_10_15.csv')\n",
      "data_bck.to_csv('../../Cern_Time_Series/Classification/data_bck_res_1year_6month_cumulative_10_15.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Histogramms of the TSA results\n",
      "import matplotlib.pyplot as plt\n",
      "#pd.options.display.mpl_style = 'default'\n",
      "\n",
      "var_plot = [u'Neg_Prob', u'slope', u'slope_std', u'y_0', u'y_0_std', u'y_1', u'y_1_std',\n",
      "            u'y_f', u'y_f_std', u'LabelReal', u'slope_rel', u'y_0_rel', u'y_1_rel', u'y_f_rel', u'DiskSize']\n",
      "for i in var_plot:\n",
      "    plt.subplot(1,1,1)\n",
      "    \n",
      "    a = np.percentile(data_res_sel[i].values, 0.5)\n",
      "    if i == 'Neg_Prob' :\n",
      "        b = np.percentile(data_res_sel[i].values, 100)\n",
      "    else:\n",
      "        b = np.percentile(data_res_sel[i].values, 90)\n",
      "        \n",
      "    plt.hist(data_sig[i].values, bins = 20, label='signal', alpha = 0.4, color = 'r',range= (a,b))\n",
      "    plt.hist(data_bck[i].values, bins = 20, label='bck', alpha = 0.4, color = 'b', range= (a,b))\n",
      "    plt.title(i)\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert data to DataStorage\n",
      "from cern_utils import converter_csv\n",
      "\n",
      "#Load signal and background data\n",
      "signal_data = converter_csv.load_from_csv('../../Cern_Time_Series/Classification/data_sig_res_1year_6month_cumulative_10_15.csv', sep=',')\n",
      "bck_data = converter_csv.load_from_csv('../../Cern_Time_Series/Classification/data_bck_res_1year_6month_cumulative_10_15.csv', sep=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get train and test data\n",
      "signal_train, signal_test = signal_data.get_train_test(train_size=0.5)\n",
      "bck_train, bck_test = bck_data.get_train_test(train_size=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = signal_data.columns\n",
      "print columns\n",
      "\n",
      "#select variables for classifier\n",
      "variables = [ 'Neg_Prob', 'slope', 'slope_std', 'y_0', 'y_0_std', 'y_1', 'y_1_std', 'y_f', 'y_f_std',\n",
      "            'slope_rel', 'y_0_rel', 'y_1_rel', 'y_f_rel']\n",
      "print variables"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"../../xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from cern_utils import xgboost_classifier\n",
      "\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.1\n",
      "param['max_depth'] = 3\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 1\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "xgboost = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "xgboost.set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "xgboost.num_boost_round = 500\n",
      "xgboost.watch = False\n",
      "\n",
      "#trainig classifier\n",
      "xgboost.fit(signal_train, bck_train)#,\\\n",
      "            #weight_sig=signal_train.get_data(['total_usage']).values,\\\n",
      "            #weight_bck=bck_train.get_data(['total_usage']).values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get prediction on data after classification\n",
      "from cern_utils.predictions_report import PredictionsInfo\n",
      "report = PredictionsInfo({'xgboost': xgboost}, signal_test, bck_test)\n",
      "report_train = PredictionsInfo({'xgboost': xgboost}, signal_train, bck_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = xgboost.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def deviance(y_true, y_pred, sample_weight):\n",
      "    return gbc.base_classifier.loss_(y_true, y_pred)\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred)  \n",
      "\n",
      "def average_precision(y_true, y_pred, sample_weight):\n",
      "    return average_precision_score(y_true, y_pred)  \n",
      "\n",
      "\n",
      "report.learning_curve( { 'roc_auc':roc_auc, 'average_precision':average_precision}, steps=100).plot(figsize = (7,5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "%pylab inline\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def log_loss(y_true, y_pred):\n",
      "    return log_loss(y_true, y_pred)\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred)  \n",
      "\n",
      "def average_precision(y_true, y_pred, sample_weight):\n",
      "    return average_precision_score(y_true, y_pred)  \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report.learning_curve( { 'roc_auc(test)':roc_auc}, steps=100)\n",
      "lc_train = report_train.learning_curve( { 'roc_auc(train)':roc_auc}, steps=100)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10, 6))\n",
      "av_test = report.learning_curve( {  'average_precision(test)':average_precision}, steps=100)\n",
      "av_train = report_train.learning_curve( {  'average_precision(train)':average_precision}, steps=100)\n",
      "av_test.plots[0].plot()\n",
      "av_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10, 6))\n",
      "ll_test = report.learning_curve( { 'log_loss(test)':roc_auc}, steps=100)\n",
      "ll_train = report_train.learning_curve( { 'log_loss(train)':roc_auc}, steps=100)\n",
      "ll_test.plots[0].plot()\n",
      "ll_train.plots[0].plot()\n",
      "legend( loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report.prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train.prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Correlation matrix\n",
      "#report.features_correlation_matrix().plot(show_legend=False, figsize=(15,5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#report.features_pdf(bins = 10).plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report.roc().plot()\n",
      "report_train.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define metric functions\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.metrics import precision_score\n",
      "\n",
      "\n",
      "import numpy\n",
      "\n",
      "\n",
      "def accuracy(s, b, t_s, t_b, s_NORM=1., b_NORM = 1.): \n",
      "\n",
      "    return (s + t_b - b)/(t_s + t_b)\n",
      "\n",
      "def precision(s, b, t_s, t_b, s_NORM=1., b_NORM = 1.):\n",
      "    return 1- b/t_b\n",
      "\n",
      "report.metrics_vs_cut({'precision': precision, 'accuracy': accuracy}).plot(new_plot=True, figsize=(8, 4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "report.prediction_pdf(bins = 20, normed = True, plot_type='bar').plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Normed signal\n",
      "%pylab inline\n",
      "from cern_utils import calc_util\n",
      "iron = calc_util.classifier_flatten(report.prediction_sig['xgboost'])\n",
      "\n",
      "_ = hist(iron(report.prediction_sig['xgboost']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(iron(report.prediction_bck['xgboost']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cern_utils import calc_util\n",
      "\n",
      "def CondSize(report, signal_test, bck_test, classifier='xgboost', cut=0.6, peaks=5, imax=26):\n",
      "\n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    \n",
      "    cond_sig = (iron(report.prediction_sig[classifier]) < cut)\\\n",
      "    &(signal_test.get_data(['nb_peaks']).values<=peaks)[:,0]\\\n",
      "    &(signal_test.get_data(['inter_max']).values>=imax)[:,0]\n",
      "    \n",
      "    cond_bck = (iron(report.prediction_bck[classifier]) < cut)\\\n",
      "    &(bck_test.get_data(['nb_peaks']).values<=peaks)[:,0]\\\n",
      "    &(bck_test.get_data(['inter_max']).values>=imax)[:,0]\n",
      "\n",
      "    nzrs = (signal_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    nzrb = (bck_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "\n",
      "    sz_signal=signal_test.get_data(['DiskSize'])[(cond_sig)&nzrs].values.sum()\\\n",
      "    +bck_test.get_data(['DiskSize'])[(cond_bck)&nzrb].values.sum()\\\n",
      "    -signal_test.get_data(['LFNSize'])[(cond_sig)&nzrs].values.sum()\\\n",
      "    -bck_test.get_data(['LFNSize'])[(cond_bck)&nzrb].values.sum()\n",
      "\n",
      "    return sz_signal\n",
      "\n",
      "def RFiles(report, signal_test, bck_test, classifier='xgboost', mincut=0.01, maxcut=1, N=100, pq=95):\n",
      "    print \"Total number of the 'signal' files is \", signal_test.get_indices().shape[0]\n",
      "    print \"Total number of files is \", signal_test.get_indices().shape[0]+bck_test.get_indices().shape[0]\n",
      "    \n",
      "    step = (maxcut - mincut)/N\n",
      "    cuts = [mincut + step*i for i in range(0, N+1)]\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    x=cuts\n",
      "    \n",
      "    nb_signals = []\n",
      "    nb_true_signals = []\n",
      "    nb_rels = []\n",
      "    cut_pq = 1\n",
      "    \n",
      "    for i in cuts:\n",
      "        nb_signal=((iron(report.prediction[classifier]) >= i)*1).sum()\n",
      "        nb_true_signal=((iron(report.prediction_sig[classifier]) >= i)*1).sum()\n",
      "        \n",
      "        if nb_signal!=0:\n",
      "            nb_rel=float(nb_true_signal)/float(nb_signal)*100\n",
      "        else:\n",
      "            nb_rel=100\n",
      "        \n",
      "        if cut_pq==1 and nb_rel>=pq:\n",
      "            cut_pq=i\n",
      "        \n",
      "        nb_signals.append(nb_signal)\n",
      "        nb_true_signals.append(nb_true_signal)\n",
      "        nb_rels.append(nb_rel)\n",
      "\n",
      "    \n",
      "    plt.figure(figsize=(5, 3))\n",
      "    plt.subplot(1,1,1)\n",
      "    plt.plot(x, nb_signals, 'b', label = 'nb signal files')\n",
      "    plt.plot(x, nb_true_signals, 'r', label = 'nb true signal files')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.show()\n",
      "    \n",
      "    plt.figure(figsize=(5, 3))\n",
      "    plt.subplot(1,1,1)\n",
      "    plt.plot(x, nb_rels, 'r', label = 'ration of the true signals to signals(%)')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.show()\n",
      "    \n",
      "    return cut_pq\n",
      "    \n",
      "def RSize(report, signal_test, bck_test, classifier='xgboost', mincut=0.01, maxcut=1, N=100, cond=0.9, Flag=False, pq=95):\n",
      "    print \"Total memory can be released is \", signal_test.get_data(['DiskSize']).values.sum()\n",
      "    print \"Total memory is \", signal_test.get_data(['DiskSize']).values.sum()+bck_test.get_data(['DiskSize']).values.sum()\n",
      "    \n",
      "    step = (maxcut - mincut)/N\n",
      "    cuts = [mincut + step*i for i in range(0, N+1)]\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    x=cuts\n",
      "    \n",
      "    sz_signals = []\n",
      "    sz_true_signals = []\n",
      "    sz_rels = []\n",
      "    cut_pq = 1\n",
      "    \n",
      "    nzrs = (signal_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    nzrb = (bck_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    \n",
      "    for i in cuts:\n",
      "        if i>=cond:\n",
      "            sz_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)].values.sum()\\\n",
      "            +bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= i)].values.sum()\n",
      "            \n",
      "            sz_true_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)].values.sum()\n",
      "            \n",
      "            if sz_signal!=0:\n",
      "                sz_rel=float(sz_true_signal)/float(sz_signal)*100.\n",
      "            else:\n",
      "                sz_rel=100\n",
      "                \n",
      "            if cut_pq==1 and sz_rel>=pq:\n",
      "                cut_pq=i\n",
      "        else:\n",
      "            sz_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\\\n",
      "            +bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= i)&nzrb].values.sum()\\\n",
      "            -signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\\\n",
      "            -bck_test.get_data(['LFNSize'])[(iron(report.prediction_bck[classifier]) >= i)&nzrb].values.sum()\n",
      "            \n",
      "            sz_true_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\\\n",
      "            -signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\n",
      "            \n",
      "            if sz_signal!=0:\n",
      "                sz_rel=float(sz_true_signal)/float(sz_signal)*100.\n",
      "            else:\n",
      "                sz_rel=100\n",
      "\n",
      "            if cut_pq==1 and sz_rel>=pq:\n",
      "                cut_pq=i\n",
      "\n",
      "        sz_signals.append(sz_signal)\n",
      "        sz_true_signals.append(sz_true_signal)\n",
      "        sz_rels.append(sz_rel)\n",
      "\n",
      "    \n",
      "    if Flag==True:\n",
      "        plt.figure(figsize=(5, 3))\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(x, sz_signals, 'b', label = 'signal files size')\n",
      "        plt.plot(x, sz_true_signals, 'r', label = 'true signal files size')\n",
      "        plt.legend(loc = 'best')\n",
      "        plt.show()\n",
      "    \n",
      "        plt.figure(figsize=(5, 3))\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(x, sz_rels, 'r')\n",
      "        plt.title('ratio of the true signals to signals(%)')\n",
      "        plt.legend(loc = 'best')\n",
      "        plt.show()\n",
      "    else:\n",
      "        plt.figure(figsize=(5, 3))\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(x, sz_signals, 'b', label = 'released memory')\n",
      "        plt.legend(loc = 'best')\n",
      "        plt.show()\n",
      "        \n",
      "    return cut_pq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#CondSize(report, signal_test, bck_test, classifier='GBC', cut=0.6, peaks=5, imax=26)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cut_pq1 = RSize(report, signal_test, bck_test, classifier='xgboost', mincut=0.1, maxcut=1, N=1000, cond=0, Flag=True)\n",
      "print \"cut_pq is \", cut_pq1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "RSize(report, signal_test, bck_test, classifier='xgboost', mincut=0.01, maxcut=1, N=1000, cond=1.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cut_pq11 = RFiles(report, signal_test, bck_test, classifier='xgboost', mincut=0.001, maxcut=1, N=1000)\n",
      "print \"cut_pq11 is \", cut_pq11"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xgboost2 = xgboost_classifier.ClassifierXGBoost(directory='xgboost2/')\n",
      "xgboost2.set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "xgboost2.num_boost_round = 1500\n",
      "xgboost2.watch = False\n",
      "\n",
      "#trainig classifier\n",
      "xgboost2.fit(signal_test, bck_test)#,\\\n",
      "            #weight_sig=signal_train.get_data(['total_usage']).values,\\\n",
      "            #weight_bck=bck_train.get_data(['total_usage']).values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get prediction on data after classification\n",
      "from cern_utils.predictions_report import PredictionsInfo\n",
      "report2 = PredictionsInfo({'xgboost2': xgboost2}, signal_train, bck_train)\n",
      "report_train2 = PredictionsInfo({'xgboost2': xgboost2}, signal_test, bck_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance2 = xgboost2.get_feature_importance()\n",
      "importance2.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def log_loss(y_true, y_pred):\n",
      "    return log_loss(y_true, y_pred)\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred)  \n",
      "\n",
      "def average_precision(y_true, y_pred, sample_weight):\n",
      "    return average_precision_score(y_true, y_pred)  \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test2 = report2.learning_curve( { 'roc_auc(test)':roc_auc}, steps=100)\n",
      "lc_train2 = report_train2.learning_curve( { 'roc_auc(train)':roc_auc}, steps=100)\n",
      "lc_test2.plots[0].plot()\n",
      "lc_train2.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10, 6))\n",
      "av_test2 = report2.learning_curve( {  'average_precision(test)':average_precision}, steps=100)\n",
      "av_train2 = report_train2.learning_curve( {  'average_precision(train)':average_precision}, steps=100)\n",
      "av_test2.plots[0].plot()\n",
      "av_train2.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10, 6))\n",
      "ll_test2 = report2.learning_curve( { 'log_loss(test)':roc_auc}, steps=100)\n",
      "ll_train2 = report_train2.learning_curve( { 'log_loss(train)':roc_auc}, steps=100)\n",
      "ll_test2.plots[0].plot()\n",
      "ll_train2.plots[0].plot()\n",
      "legend( loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report2.prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train2.prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report2.roc().plot()\n",
      "report_train2.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define metric functions\n",
      "report2.metrics_vs_cut({'precision': precision, 'accuracy': accuracy}).plot(new_plot=True, figsize=(8, 4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10, 6))\n",
      "report2.prediction_pdf(bins = 20, normed = True, plot_type='bar').plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Normed signal\n",
      "%pylab inline\n",
      "from cern_utils import calc_util\n",
      "iron2 = calc_util.classifier_flatten(report2.prediction_sig['xgboost2'])\n",
      "\n",
      "_ = hist(iron2(report2.prediction_sig['xgboost2']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(iron2(report2.prediction_bck['xgboost2']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cut_pq2 = RSize(report2, signal_train, bck_train, classifier='xgboost2', mincut=0.2, maxcut=1, N=1000, cond=0, Flag=True)\n",
      "print \"cut_pq is \", cut_pq2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "RSize(report2, signal_train, bck_train, classifier='xgboost2', mincut=0.01, maxcut=1, N=1000, cond=1.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cut_pq22 = RFiles(report2, signal_train, bck_train, classifier='xgboost2', mincut=0.001, maxcut=1, N=1000)\n",
      "print \"cut_pq is \", cut_pq22"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Selection\n",
      "sel = ((data['Now'] - data['Creation-week']) > 52)&((data['Now'] - data['FirstUsage']) > 52)&((data[53] - data[1]) == 0)\n",
      "check = ((data[sel][104] - data[sel][52]) == 0).values*1\n",
      "memory1 = data[sel].get('DiskSize').values.sum()\n",
      "memory_check = (data[sel].get('DiskSize').values*check).sum()\n",
      "print check.sum()-check.shape[0]\n",
      "print memory1\n",
      "print memory_check"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Classification. Brave\n",
      "iron2 = calc_util.classifier_flatten(report2.prediction_sig['xgboost2'])\n",
      "\n",
      "memory21 = signal_train.get_data(['DiskSize'])[iron2(report2.prediction_sig['xgboost2']) >= cut_pq2].values.sum()\\\n",
      "+bck_train.get_data(['DiskSize'])[iron2(report2.prediction_bck['xgboost2']) >= cut_pq2].values.sum()\\\n",
      "+signal_test.get_data(['DiskSize'])[iron(report.prediction_sig['xgboost']) >= cut_pq1].values.sum()\\\n",
      "+bck_test.get_data(['DiskSize'])[iron(report.prediction_bck['xgboost']) >= cut_pq1].values.sum()\n",
      "\n",
      "print memory21"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Classification. Safe\n",
      "\n",
      "nzrs = (signal_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "nzrb = (bck_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "nzrs2 = (signal_train.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "nzrb2 = (bck_train.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "s_cut = 0.8\n",
      "\n",
      "memory22 = signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig['xgboost']) >= s_cut)&nzrs].values.sum()\\\n",
      "+bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck['xgboost']) >= s_cut)&nzrb].values.sum()\\\n",
      "-signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig['xgboost']) >= s_cut)&nzrs].values.sum()\\\n",
      "-bck_test.get_data(['LFNSize'])[(iron(report.prediction_bck['xgboost']) >= s_cut)&nzrb].values.sum()\\\n",
      "+signal_train.get_data(['DiskSize'])[(iron2(report2.prediction_sig['xgboost2']) >= s_cut)&nzrs2].values.sum()\\\n",
      "+bck_train.get_data(['DiskSize'])[(iron2(report2.prediction_bck['xgboost2']) >= s_cut)&nzrb2].values.sum()\\\n",
      "-signal_train.get_data(['LFNSize'])[(iron2(report2.prediction_sig['xgboost2']) >= s_cut)&nzrs2].values.sum()\\\n",
      "-bck_train.get_data(['LFNSize'])[(iron2(report2.prediction_bck['xgboost2']) >= s_cut)&nzrb2].values.sum()\n",
      "\n",
      "print memory22"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Classification. Combination\n",
      "\n",
      "memory231 = signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig['xgboost']) >= s_cut)&nzrs].values.sum()\\\n",
      "+bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck['xgboost']) >= s_cut)&nzrb].values.sum()\\\n",
      "-signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig['xgboost']) >= s_cut)&nzrs].values.sum()\\\n",
      "-bck_test.get_data(['LFNSize'])[(iron(report.prediction_bck['xgboost']) >= s_cut)&nzrb].values.sum()\\\n",
      "+signal_train.get_data(['DiskSize'])[(iron2(report2.prediction_sig['xgboost2']) >= s_cut)&nzrs2].values.sum()\\\n",
      "+bck_train.get_data(['DiskSize'])[(iron2(report2.prediction_bck['xgboost2']) >= s_cut)&nzrb2].values.sum()\\\n",
      "-signal_train.get_data(['LFNSize'])[(iron2(report2.prediction_sig['xgboost2']) >= s_cut)&nzrs2].values.sum()\\\n",
      "-bck_train.get_data(['LFNSize'])[(iron2(report2.prediction_bck['xgboost2']) >= s_cut)&nzrb2].values.sum()\n",
      "\n",
      "memory232 = signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig['xgboost']) >= cut_pq1)&nzrs].values.sum()\\\n",
      "+bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck['xgboost']) >= cut_pq1)&nzrb].values.sum()\\\n",
      "-signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig['xgboost']) >= cut_pq1)&nzrs].values.sum()\\\n",
      "-bck_test.get_data(['LFNSize'])[(iron(report.prediction_bck['xgboost']) >= cut_pq1)&nzrb].values.sum()\\\n",
      "+signal_train.get_data(['DiskSize'])[(iron2(report2.prediction_sig['xgboost2']) >= cut_pq2)&nzrs2].values.sum()\\\n",
      "+bck_train.get_data(['DiskSize'])[(iron2(report2.prediction_bck['xgboost2']) >= cut_pq2)&nzrb2].values.sum()\\\n",
      "-signal_train.get_data(['LFNSize'])[(iron2(report2.prediction_sig['xgboost2']) >= cut_pq2)&nzrs2].values.sum()\\\n",
      "-bck_train.get_data(['LFNSize'])[(iron2(report2.prediction_bck['xgboost2']) >= cut_pq2)&nzrb2].values.sum()\n",
      "\n",
      "memory233 = signal_test.get_data(['DiskSize'])[iron(report.prediction_sig['xgboost']) >= cut_pq1].values.sum()\\\n",
      "+bck_test.get_data(['DiskSize'])[iron(report.prediction_bck['xgboost']) >= cut_pq1].values.sum()\\\n",
      "+signal_train.get_data(['DiskSize'])[iron2(report2.prediction_sig['xgboost2']) >= cut_pq2].values.sum()\\\n",
      "+bck_train.get_data(['DiskSize'])[iron2(report2.prediction_bck['xgboost2']) >= cut_pq2].values.sum()\n",
      "\n",
      "memory23 = memory231-memory232+memory233\n",
      "print memory23"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Rare usage\n",
      "memory3 = 0#CondSize(report2, signal_train, bck_train, classifier='xgboost2', cut=s_cut, peaks=3, imax=26)\\\n",
      "#+CondSize(report, signal_test, bck_test, classifier='xgboost', cut=s_cut, peaks=3, imax=26)\n",
      "print memory3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Total released memory\n",
      "memory = memory1+memory22+memory3\n",
      "total = signal_train.get_data(['DiskSize']).values.sum()+bck_train.get_data(['DiskSize']).values.sum()+memory1\\\n",
      "+signal_test.get_data(['DiskSize']).values.sum()+bck_test.get_data(['DiskSize']).values.sum()\n",
      "can_released = signal_train.get_data(['DiskSize']).values.sum()+signal_test.get_data(['DiskSize']).values.sum()+memory1\n",
      "\n",
      "print \"memory is \", memory\n",
      "print \"total memory is \", total\n",
      "print \"memory can be released is \", can_released\n",
      "print \"Ratio is \", float(memory)/float(total)*100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Total released memory\n",
      "memory = memory1+memory21+memory3\n",
      "\n",
      "print \"memory is \", memory\n",
      "print \"total memory is \", total\n",
      "print \"memory can be released is \", can_released\n",
      "print \"Ratio is \", float(memory)/float(total)*100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Total released memory\n",
      "memory = memory1+memory23+memory3\n",
      "\n",
      "print \"memory is \", memory\n",
      "print \"total memory is \", total\n",
      "print \"memory can be released is \", can_released\n",
      "print \"Ratio is \", float(memory)/float(total)*100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "ipykee.create_project(\"A._TimeSeriesAnalysis\", internal_path=\"A._TimeSeriesAnalysis\", repository=\"git@github.com:hushchyn-mikhail/CERN_Time_Series.git\")\n",
      "session = ipykee.Session(project_name=\"A._TimeSeriesAnalysis\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit(\"First commit\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.add(report, \"report\")\n",
      "session.add(report2, \"report2\")\n",
      "session.add(report_train, \"report_train\")\n",
      "session.add(report_train2, \"report_train2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit(\"Reports added\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit(\"Reports added\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit(\"Second\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "#ipykee.create_project(\"A._TimeSeriesAnalysis\", internal_path=\"A._TimeSeriesAnalysis\", repository=\"git@github.com:hushchyn-mikhail/CERN_Time_Series.git\")\n",
      "session = ipykee.Session(project_name=\"A._TimeSeriesAnalysis\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit(\"Second\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "#ipykee.create_project(\"A._TimeSeriesAnalysis\", internal_path=\"A._TimeSeriesAnalysis\", repository=\"git@github.com:hushchyn-mikhail/CERN_Time_Series.git\")\n",
      "session = ipykee.Session(project_name=\"A._TimeSeriesAnalysis\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " session.add(report, \"report\")\n",
      "# session.add(report2, \"report2\")\n",
      "# session.add(report_train, \"report_train\")\n",
      "# session.add(report_train2, \"report_train2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit(\"Second\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "#ipykee.create_project(\"A._TimeSeriesAnalysis\", internal_path=\"A._TimeSeriesAnalysis\", repository=\"git@github.com:hushchyn-mikhail/CERN_Time_Series.git\")\n",
      "session = ipykee.Session(project_name=\"A._TimeSeriesAnalysis\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " session.add(report.roc(), \"report.roc()\")\n",
      "# session.add(report2, \"report2\")\n",
      "# session.add(report_train, \"report_train\")\n",
      "# session.add(report_train2, \"report_train2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit(\"Second\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "#ipykee.create_project(\"A._TimeSeriesAnalysis\", internal_path=\"A._TimeSeriesAnalysis\", repository=\"git@github.com:hushchyn-mikhail/CERN_Time_Series.git\")\n",
      "session = ipykee.Session(project_name=\"A._TimeSeriesAnalysis\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.add(report.roc(), \"report.roc()\")\n",
      "session.add(report2.roc(), \"report2.roc()\")\n",
      "session.add(report_train.roc(), \"report_train.roc()\")\n",
      "session.add(report_train2.roc(), \"report_train2.roc()\")\n",
      "\n",
      "session.add(report.prediction_sig['xgboost2'], \"report.prediction_sig['xgboost2']\")\n",
      "session.add(report2.prediction_sig['xgboost2'], \"report2.prediction_sig['xgboost2']\")\n",
      "\n",
      "session.add(report.prediction_bck['xgboost2'], \"report.prediction_bck['xgboost2']\")\n",
      "session.add(report2.prediction_bck['xgboost2'], \"report2.prediction_bck['xgboost2']\")\n",
      "\n",
      "session.add(report.prediction_pdf['xgboost2'], \"report.prediction_pdf['xgboost2']\")\n",
      "session.add(report2.prediction_pdf['xgboost2'], \"report2.prediction_pdf['xgboost2']\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.add(report.roc(), \"report.roc()\")\n",
      "session.add(report2.roc(), \"report2.roc()\")\n",
      "session.add(report_train.roc(), \"report_train.roc()\")\n",
      "session.add(report_train2.roc(), \"report_train2.roc()\")\n",
      "\n",
      "session.add(report.prediction_sig['xgboost'], \"report.prediction_sig['xgboost2']\")\n",
      "session.add(report2.prediction_sig['xgboost2'], \"report2.prediction_sig['xgboost2']\")\n",
      "\n",
      "session.add(report.prediction_bck['xgboost'], \"report.prediction_bck['xgboost2']\")\n",
      "session.add(report2.prediction_bck['xgboost2'], \"report2.prediction_bck['xgboost2']\")\n",
      "\n",
      "session.add(report.prediction_pdf['xgboost'], \"report.prediction_pdf['xgboost2']\")\n",
      "session.add(report2.prediction_pdf['xgboost2'], \"report2.prediction_pdf['xgboost2']\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "#ipykee.create_project(\"A._TimeSeriesAnalysis\", internal_path=\"A._TimeSeriesAnalysis\", repository=\"git@github.com:hushchyn-mikhail/CERN_Time_Series.git\")\n",
      "session = ipykee.Session(project_name=\"A._TimeSeriesAnalysis\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.add(report.roc(), \"report.roc()\")\n",
      "session.add(report2.roc(), \"report2.roc()\")\n",
      "session.add(report_train.roc(), \"report_train.roc()\")\n",
      "session.add(report_train2.roc(), \"report_train2.roc()\")\n",
      "\n",
      "session.add(report.prediction_sig['xgboost'], \"report.prediction_sig['xgboost2']\")\n",
      "session.add(report2.prediction_sig['xgboost2'], \"report2.prediction_sig['xgboost2']\")\n",
      "\n",
      "session.add(report.prediction_bck['xgboost'], \"report.prediction_bck['xgboost2']\")\n",
      "session.add(report2.prediction_bck['xgboost2'], \"report2.prediction_bck['xgboost2']\")\n",
      "\n",
      "session.add(report.prediction_pdf(bins = 20, normed = True, plot_type='bar'), \"report.prediction_pdf()\")\n",
      "session.add(report2.prediction_pdf(bins = 20, normed = True, plot_type='bar'), \"report2.prediction_pdf()\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    }
   ],
   "metadata": {}
  }
 ]
}