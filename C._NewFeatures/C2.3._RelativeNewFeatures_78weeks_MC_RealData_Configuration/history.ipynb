{
 "metadata": {
  "name": "/ipykee/workdir/tmpnRYPA5/C"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%pylab inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#Load original data\n",
      "data = pd.read_excel('/home/mikhail91/Desktop/popularity-728days_my.xls')\n",
      "data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%pylab inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#Load original data\n",
      "data = pd.read_excel('popularity-728days_my.xls')\n",
      "data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Select data\n",
      "selection = ((data['Now'] - data['Creation-week']) > 26)&((data['Now'] - data['FirstUsage']) > 26)&((data[78] - data[1]) != 0)\n",
      "data_sel = data[selection].copy()\n",
      "#data_sel = data.copy()\n",
      "print data_sel.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "periods = range(1,79)\n",
      "\n",
      "#------------------------------------------------------\n",
      "#Get maximum intervals and last weeks with zeros usages\n",
      "def InterMax(data_sel, periods):\n",
      "    #Get binary vector representation of the selected data\n",
      "    data_bv = data_sel.copy()\n",
      "    #Get week's usages\n",
      "    for i in periods:\n",
      "        if i!=1:\n",
      "            data_bv[i] = data_sel[i] - data_sel[i-1]\n",
      "            \n",
      "    #Get binary representation\n",
      "    data_bv[periods] = (data_bv[periods] != 0)*1\n",
      "    \n",
      "    inter_max = []\n",
      "    last_zeros = []\n",
      "    nb_peaks = []\n",
      "    inter_mean = []\n",
      "    inter_std = []\n",
      "    inter_rel = []\n",
      "    \n",
      "    for i in range(0,data_bv.shape[0]):\n",
      "        ds = data_bv[periods].irow(i)\n",
      "        nz = ds.nonzero()[0]\n",
      "        inter = []\n",
      "        \n",
      "        nb_peaks.append(len(nz))\n",
      "        if len(nz)==0:\n",
      "            nz = [0]\n",
      "        if len(nz)<2:\n",
      "            inter = [0]\n",
      "            #nz = [0]\n",
      "        else:\n",
      "            for k in range(0, len(nz)-1):\n",
      "                val = nz[k+1]-nz[k]\n",
      "                inter.append(val)\n",
      "        \n",
      "        inter = np.array(inter)\n",
      "        inter_mean.append(inter.mean())\n",
      "        inter_std.append(inter.std())\n",
      "        if inter.mean()!=0:\n",
      "            inter_rel.append(inter.std()/inter.mean())\n",
      "        else:\n",
      "            inter_rel.append(0)\n",
      "                \n",
      "        last_zeros.append(nz[-1]+data_bv['Now'].values[i]-104-data_bv['Creation-week'].values[i])\n",
      "        inter_max.append(max(inter))\n",
      "    \n",
      "    return np.array(inter_max), np.array(last_zeros), np.array(nb_peaks), np.array(inter_mean), np.array(inter_std), np.array(inter_rel)\n",
      "#------------------------------------------------------\n",
      "def MassCenter(data_sel, periods):\n",
      "    data_bv = data_sel.copy()\n",
      "    p = np.array(periods)\n",
      "    #Get week's usages\n",
      "    for i in periods:\n",
      "        if i!=1:\n",
      "            data_bv[i] = data_sel[i] - data_sel[i-1]\n",
      "    \n",
      "    mass_center = []\n",
      "    mass_center2 = []\n",
      "    mass_moment = []\n",
      "    r_moment = []\n",
      "            \n",
      "    for i in range(0,data_bv.shape[0]):\n",
      "        center = (data_bv[periods].irow(i).values*(p+data_bv['Now'].values[i]-104-data_bv['Creation-week'].values[i])).sum()/data_bv[periods].irow(i).values.sum()\n",
      "        center2 = (data_bv[periods].irow(i).values*np.square((p+data_bv['Now'].values[i]-104-data_bv['Creation-week'].values[i]))).sum()\n",
      "        moment = (data_bv[periods].irow(i).values*np.square((p+data_bv['Now'].values[i]-104-data_bv['Creation-week'].values[i])-center)).sum()\n",
      "        r_m = moment/data_bv[periods].irow(i).values.sum()\n",
      "        mass_center.append(center)\n",
      "        mass_center2.append(center2)\n",
      "        mass_moment.append(moment)\n",
      "        r_moment.append(r_m)\n",
      "    \n",
      "    print data_bv.shape\n",
      "    print data_sel.shape\n",
      "        \n",
      "    return np.array(mass_center), np.array(mass_moment), np.array(r_moment), np.array(mass_center2)\n",
      "#------------------------------------------------------\n",
      "def Binary(data_sel, periods):\n",
      "    data_bv = data_sel.copy()\n",
      "    p = np.array(periods) - periods[0]+1\n",
      "    #Get week's usages\n",
      "    for i in periods:\n",
      "        if i!=1:\n",
      "            data_bv[i] = data_sel[i] - data_sel[i-1]\n",
      "    #Get binary representation\n",
      "    data_bv[p] = (data_bv[periods] != 0)*1\n",
      "    \n",
      "    return data_bv[p]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create a Data Frame for Classifier\n",
      "df = pd.DataFrame()\n",
      "\n",
      "#Add features\n",
      "inter_max, last_zeros, nb_peaks, inter_mean, inter_std, inter_rel = InterMax(data_sel, periods)\n",
      "df['last-zeros'] = last_zeros\n",
      "df['inter_max'] = inter_max\n",
      "df['nb_peaks'] = nb_peaks\n",
      "df['inter_mean'] = inter_mean\n",
      "df['inter_std'] = inter_std\n",
      "df['inter_rel'] = inter_rel\n",
      "\n",
      "mass_center, mass_moment, r_moment, mass_center2 = MassCenter(data_sel, periods)\n",
      "df['mass_center'] = mass_center\n",
      "df['mass_center_sqr'] = mass_center2\n",
      "df['mass_moment'] = mass_moment\n",
      "df['r_moment'] = r_moment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['DiskSize'] = data_sel['DiskSize'].values\n",
      "df['LFNSize'] = data_sel['LFNSize'].values\n",
      "df['Nb Replicas'] = data_sel['Nb Replicas'].values\n",
      "\n",
      "df['LogDiskSize'] = np.log(data_sel['DiskSize'].values+0.00001)\n",
      "df['total_usage'] = data_sel[periods[-1]].values\n",
      "df['mean_usage'] = df['total_usage'].values/(df['nb_peaks'].values+1)\n",
      "\n",
      "df['log_total_usage'] = np.log(data_sel[periods[-1]].values+1)\n",
      "df['log_mean_usage'] = df['total_usage'].values - np.log(df['nb_peaks'].values+1)\n",
      "\n",
      "\"\"\"\n",
      "df['log_mass_center'] = np.log(mass_center+1)\n",
      "df['log_mass_moment'] = np.log(mass_moment+1)\n",
      "df['log_r_moment'] = np.log(r_moment+1)\n",
      "df['log_mass_center_sqr'] = np.log(mass_center2+1)\n",
      "\n",
      "df['log_last-zeros'] = np.log(last_zeros+1)\n",
      "df['log_inter_max'] = np.log(inter_max+1)\n",
      "df['log_nb_peaks'] = np.log(nb_peaks+1)\n",
      "df['log_inter_mean'] = np.log(inter_mean+1)\n",
      "df['log_inter_std'] = np.log(inter_std+1)\n",
      "df['log_inter_rel'] = np.log(inter_rel+1)\n",
      "\n",
      "#df['FileType'] = data_sel['FileType']\n",
      "#df['Configuration'] = data_sel['Configuration']\n",
      "#df['ProcessingPass'] = data_sel['ProcessingPass']\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Configuration\n",
      "configurations = np.unique(data_sel.Configuration.values)\n",
      "print len(configurations)\n",
      "print configurations\n",
      "\n",
      "#Histogramm of the processing passes distribution\n",
      "mapping = dict(zip(configurations, range(0, len(configurations))))\n",
      "co_indexes = data_sel.replace({'Configuration':mapping}).Configuration.values\n",
      "df['ConfigGroups'] = co_indexes\n",
      "\n",
      "plt.hist(co_indexes, bins=len(configurations))\n",
      "plt.title('Indexes of the ConfigGroups')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 0\n",
      "for a in np.unique(df['ConfigGroups'].values):\n",
      "    print df[df['ConfigGroups']==a].shape, a\n",
      "    i=i+1\n",
      "print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Union\n",
      "df_configuration = df['ConfigGroups'].copy()\n",
      "for i in range(0,df_configuration.shape[0]):\n",
      "    if (df_configuration[i]<9) & (df_configuration[i]>2):\n",
      "        df_configuration[i] = 3\n",
      "\n",
      "\n",
      "df['ConfigGroups'] = df_configuration.values\n",
      "np.unique(df_configuration.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 0\n",
      "for a in np.unique(df['ConfigGroups'].values):\n",
      "    print df[df['ConfigGroups']==a].shape, a\n",
      "    i=i+1\n",
      "print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.unique(df['ConfigGroups'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Transform string features to digits\n",
      "cols_str = ['Configuration', 'ProcessingPass', 'FileType', 'Storage']\n",
      "df_str = data_sel.get(cols_str)\n",
      "\n",
      "for col in cols_str:\n",
      "    unique = np.unique(df_str[col])\n",
      "    index = range(0, len(unique))\n",
      "    mapping = dict(zip(unique, index))\n",
      "    df_str = df_str.replace({col:mapping})\n",
      "    \n",
      "df['FileType'] = df_str['FileType'].values\n",
      "df['Configuration'] = df_str['Configuration'].values\n",
      "df['ProcessingPass'] = df_str['ProcessingPass'].values\n",
      "\n",
      "other_vars = [u'Type', u'Creation-week', u'NbLFN', u'LFNSize', u'NbDisk', u'DiskSize', u'NbTape', u'TapeSize',\n",
      "              u'NbArchived', u'ArchivedSize', u'Nb Replicas', u'Nb ArchReps', u'FirstUsage']\n",
      "for i in other_vars:\n",
      "    df[i] = data_sel[i].values\n",
      "df['silence'] = df['FirstUsage']-df[u'Creation-week']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Add Binary Vector\n",
      "bv = Binary(data_sel, periods)\n",
      "p = np.array(periods) - periods[0]+1\n",
      "for i in p:\n",
      "    df[i]=bv[i].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_true = ((data_sel[104] - data_sel[78]) == 0).values*1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Check >0\n",
      "for i in np.unique(df['ConfigGroups'].values):\n",
      "    print 'Group Number is ', i, ' : ', len(y_true[df['ConfigGroups'].values==i]) - y_true[df['ConfigGroups'].values==i].sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in df.columns:\n",
      "    plt.subplot(1,1,1)\n",
      "    plt.hist(df[i][y_true == 1].values, label='signal', color='b', alpha=0.5, bins = 10)\n",
      "    plt.hist(df[i][y_true == 0].values, label='bck', color='r', alpha=0.5, bins = 10)\n",
      "    plt.ylabel('Nb of data sets')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.title(i)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#After additional selection\n",
      "\"\"\"\n",
      "for i in df_s.columns:\n",
      "    plt.subplot(1,1,1)\n",
      "    plt.hist(df_s[i][y_true_s == 1].values, label='1', color='b', alpha=0.5, bins = 20)\n",
      "    plt.hist(df_s[i][y_true_s == 0].values, label='0', color='r', alpha=0.5, bins = 20)\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.title(i)\n",
      "    plt.show()\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "\"\"\"\n",
      "df = df_s\n",
      "y_true = y_true_s\n",
      "df.shape\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "groups = np.unique(df['ConfigGroups'].values)\n",
      "print range(0, len(groups))\n",
      "print groups"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cern_utils import data_storage\n",
      "\"\"\"\n",
      "#whole data\n",
      "one_signal_train, one_signal_test = data_storage.DataStorageDF(df[y_true == 1]).get_train_test(train_size=0.5)\n",
      "one_bck_train, one_bck_test = data_storage.DataStorageDF(df[y_true == 0]).get_train_test(train_size=0.5)\n",
      "\"\"\"\n",
      "#Split Datasets to the MC and Real Data\n",
      "groups = np.unique(df['ConfigGroups'].values)\n",
      "\n",
      "#list of the datastorages\n",
      "signal_data = [0 for i in range(0, len(groups))]\n",
      "bck_data = [0 for i in range(0, len(groups))]\n",
      "signal_train = [0 for i in range(0, len(groups))]\n",
      "signal_test = [0 for i in range(0, len(groups))]\n",
      "bck_train = [0 for i in range(0, len(groups))]\n",
      "bck_test = [0 for i in range(0, len(groups))]\n",
      "\n",
      "#MC: data_sel.Type=0\n",
      "#Real Data: data_sel.Type=1\n",
      "\n",
      "for i in range(0, len(groups)):\n",
      "    signal_data[i] = data_storage.DataStorageDF(df[(y_true == 1)&(df['ConfigGroups'] == groups[i])])\n",
      "    bck_data[i] = data_storage.DataStorageDF(df[(y_true == 0)&(df['ConfigGroups'] == groups[i])])\n",
      "    \n",
      "    signal_train[i], signal_test[i] = signal_data[i].get_train_test(train_size=0.5)\n",
      "    bck_train[i], bck_test[i] = bck_data[i].get_train_test(train_size=0.5)\n",
      "\n",
      "#whole data\n",
      "one_signal_train = signal_train[0]\n",
      "one_signal_test = signal_test[0]\n",
      "one_bck_train = bck_train[0]\n",
      "one_bck_test = bck_test[0]\n",
      "for i in range(1, len(groups)):\n",
      "    print groups[i]\n",
      "    print one_signal_train.get_data().shape\n",
      "    print one_bck_train.get_data().shape\n",
      "    one_signal_train = one_signal_train.union((one_signal_train, signal_train[i]))\n",
      "    one_signal_test = one_signal_test.union((one_signal_test, signal_test[i]))\n",
      "    one_bck_train = one_bck_train.union((one_bck_train, bck_train[i]))\n",
      "    one_bck_test = one_bck_test.union((one_bck_test, bck_test[i]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#select variables for classifier\n",
      "columns = signal_data[0].columns\n",
      "print columns\n",
      "print '****************************************************'\n",
      "\n",
      "variables = ['last-zeros', 'mass_center', 'inter_max', 'nb_peaks', u'inter_mean', u'inter_std', u'inter_rel',\n",
      "             u'mass_moment', u'r_moment',u'FileType',\n",
      "             u'Configuration', u'ProcessingPass']#, u'Nb Replicas', ]\n",
      "    \n",
      "variables = [u'last-zeros', u'inter_max', u'nb_peaks', u'inter_mean', u'inter_std', u'inter_rel', u'mass_center',\n",
      "             u'mass_center_sqr', u'mass_moment', u'r_moment', u'DiskSize', u'LogDiskSize', u'total_usage', u'mean_usage',\n",
      "             u'FileType', u'Configuration', u'ProcessingPass', u'log_total_usage', u'log_mean_usage']+other_vars\n",
      "\n",
      "#variables = signal_data.columns\n",
      "\n",
      "print variables\n",
      "print len(variables)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def log_loss(y_true, y_pred):\n",
      "    return log_loss(y_true, y_pred)\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred)  \n",
      "\n",
      "def average_precision(y_true, y_pred, sample_weight):\n",
      "    return average_precision_score(y_true, y_pred) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"/home/mikhail91/xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from cern_utils import xgboost_classifier\n",
      "from cern_utils.predictions_report import PredictionsInfo\n",
      "%pylab inline\n",
      "from cern_utils import calc_util\n",
      "\n",
      "#list of the classifiers and reports\n",
      "classifier = [0 for i in range(0, len(groups))]\n",
      "report = [0 for i in range(0, len(groups))]\n",
      "report_train = [0 for i in range(0, len(groups))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from cern_utils import xgboost_classifier\n",
      "from cern_utils.predictions_report import PredictionsInfo\n",
      "%pylab inline\n",
      "from cern_utils import calc_util\n",
      "\n",
      "#list of the classifiers and reports\n",
      "classifier = [0 for i in range(0, len(groups))]\n",
      "report = [0 for i in range(0, len(groups))]\n",
      "report_train = [0 for i in range(0, len(groups))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cern_utils import calc_util\n",
      "\n",
      "def CondSize(report, signal_test, bck_test, classifier='xgboost', cut=0.6, peaks=5, imax=26):\n",
      "\n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    \n",
      "    cond_sig = (iron(report.prediction_sig[classifier]) < cut)\\\n",
      "    &(signal_test.get_data(['nb_peaks']).values<=peaks)[:,0]\\\n",
      "    &(signal_test.get_data(['inter_max']).values>=imax)[:,0]\n",
      "    \n",
      "    cond_bck = (iron(report.prediction_bck[classifier]) < cut)\\\n",
      "    &(bck_test.get_data(['nb_peaks']).values<=peaks)[:,0]\\\n",
      "    &(bck_test.get_data(['inter_max']).values>=imax)[:,0]\n",
      "\n",
      "    nzrs = (signal_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    nzrb = (bck_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "\n",
      "    sz_signal=signal_test.get_data(['DiskSize'])[(cond_sig)&nzrs].values.sum()\\\n",
      "    +bck_test.get_data(['DiskSize'])[(cond_bck)&nzrb].values.sum()\\\n",
      "    -signal_test.get_data(['LFNSize'])[(cond_sig)&nzrs].values.sum()\\\n",
      "    -bck_test.get_data(['LFNSize'])[(cond_bck)&nzrb].values.sum()\n",
      "\n",
      "    return sz_signal\n",
      "\n",
      "def RFiles(report, signal_test, bck_test, classifier='xgboost', mincut=0.01, maxcut=1, N=100, pq=95):\n",
      "    print \"Total number of the 'signal' files is \", signal_test.get_indices().shape[0]\n",
      "    print \"Total number of files is \", signal_test.get_indices().shape[0]+bck_test.get_indices().shape[0]\n",
      "    \n",
      "    step = (maxcut - mincut)/N\n",
      "    cuts = [mincut + step*i for i in range(0, N+1)]\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    x=cuts\n",
      "    \n",
      "    nb_signals = []\n",
      "    nb_true_signals = []\n",
      "    nb_rels = []\n",
      "    cut_pq = 1\n",
      "    \n",
      "    for i in cuts:\n",
      "        nb_signal=((iron(report.prediction[classifier]) >= i)*1).sum()\n",
      "        nb_true_signal=((iron(report.prediction_sig[classifier]) >= i)*1).sum()\n",
      "        \n",
      "        if nb_signal!=0:\n",
      "            nb_rel=float(nb_true_signal)/float(nb_signal)*100\n",
      "        else:\n",
      "            nb_rel=100\n",
      "        \n",
      "        if cut_pq==1 and nb_rel>=pq:\n",
      "            cut_pq=i\n",
      "        \n",
      "        nb_signals.append(nb_signal)\n",
      "        nb_true_signals.append(nb_true_signal)\n",
      "        nb_rels.append(nb_rel)\n",
      "\n",
      "    \n",
      "    plt.figure(figsize=(5, 3))\n",
      "    plt.subplot(1,1,1)\n",
      "    plt.plot(x, nb_signals, 'b', label = 'nb signal files')\n",
      "    plt.plot(x, nb_true_signals, 'r', label = 'nb true signal files')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.show()\n",
      "    \n",
      "    plt.figure(figsize=(5, 3))\n",
      "    plt.subplot(1,1,1)\n",
      "    plt.plot(x, nb_rels, 'r', label = 'ratio of the true signals to the signals(%)')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.show()\n",
      "    \n",
      "    return cut_pq\n",
      "    \n",
      "def RSize(report, signal_test, bck_test, classifier='xgboost', mincut=0.01, maxcut=1, N=100, cond=0.9, Flag=False, pq=95, s_pq=90):\n",
      "    print \"Total memory can be released is \", signal_test.get_data(['DiskSize']).values.sum()\n",
      "    print \"Total memory is \", signal_test.get_data(['DiskSize']).values.sum()+bck_test.get_data(['DiskSize']).values.sum()\n",
      "    \n",
      "    step = (maxcut - mincut)/N\n",
      "    cuts = [mincut + step*i for i in range(0, N+1)]\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    x=cuts\n",
      "    \n",
      "    sz_signals = []\n",
      "    sz_true_signals = []\n",
      "    sz_rels = []\n",
      "    cut_pq = 1\n",
      "    s_cut_pq = 1\n",
      "    \n",
      "    nzrs = (signal_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    nzrb = (bck_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    \n",
      "    for i in cuts:\n",
      "        if i>=cond:\n",
      "            sz_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)].values.sum()\\\n",
      "            +bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= i)].values.sum()\n",
      "            \n",
      "            sz_true_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)].values.sum()\n",
      "            \n",
      "            if sz_signal!=0:\n",
      "                sz_rel=float(sz_true_signal)/float(sz_signal)*100.\n",
      "            else:\n",
      "                sz_rel=100\n",
      "                \n",
      "            if cut_pq==1 and sz_rel>=pq:\n",
      "                cut_pq=i\n",
      "            if s_cut_pq==1 and sz_rel>=s_pq:\n",
      "                s_cut_pq=i\n",
      "        else:\n",
      "            sz_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\\\n",
      "            +bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= i)&nzrb].values.sum()\\\n",
      "            -signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\\\n",
      "            -bck_test.get_data(['LFNSize'])[(iron(report.prediction_bck[classifier]) >= i)&nzrb].values.sum()\n",
      "            \n",
      "            sz_true_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\\\n",
      "            -signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\n",
      "            \n",
      "            if sz_signal!=0:\n",
      "                sz_rel=float(sz_true_signal)/float(sz_signal)*100.\n",
      "            else:\n",
      "                sz_rel=100\n",
      "\n",
      "            if cut_pq==1 and sz_rel>=pq:\n",
      "                cut_pq=i\n",
      "            if s_cut_pq==1 and sz_rel>=s_pq:\n",
      "                s_cut_pq=i\n",
      "\n",
      "        sz_signals.append(sz_signal)\n",
      "        sz_true_signals.append(sz_true_signal)\n",
      "        sz_rels.append(sz_rel)\n",
      "\n",
      "    \n",
      "    if Flag==True:\n",
      "        plt.figure(figsize=(5, 3))\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(x, sz_signals, 'b', label = 'signal files size')\n",
      "        plt.plot(x, sz_true_signals, 'r', label = 'true signal files size')\n",
      "        plt.legend(loc = 'best')\n",
      "        plt.show()\n",
      "    \n",
      "        plt.figure(figsize=(5, 3))\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(x, sz_rels, 'r')\n",
      "        plt.title('Ratio(%)')\n",
      "        plt.legend(loc = 'best')\n",
      "        plt.show()\n",
      "    else:\n",
      "        plt.figure(figsize=(5, 3))\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(x, sz_signals, 'b', label = 'released memory')\n",
      "        plt.legend(loc = 'best')\n",
      "        plt.show()\n",
      "        \n",
      "    return cut_pq, s_cut_pq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "#gid = 0\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.02\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier_one = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier_one.set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier_one.num_boost_round = 2500\n",
      "classifier_one.watch = False\n",
      "classifier_one.missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier_one.fit(one_signal_train, one_bck_train)\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report_one = PredictionsInfo({'classifier': classifier_one}, one_signal_test, one_bck_test)\n",
      "report_train_one = PredictionsInfo({'classifier': classifier_one}, one_signal_train, one_bck_train)\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_one.learning_curve( { 'roc_auc(test)':roc_auc}, steps=100)\n",
      "lc_train = report_train_one.learning_curve( { 'roc_auc(train)':roc_auc}, steps=100)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report_one.prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train_one.prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report_one.roc().plot()\n",
      "report_train_one.roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier_one.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#transformed prediction\n",
      "iron = calc_util.classifier_flatten(report_one.prediction_sig['classifier'])\n",
      "_ = hist(iron(report_one.prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(iron(report_one.prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_one, s_cut_one = RSize(report_one, one_signal_test, one_bck_test, classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_one, s_cut_one"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cut = [0 for i in range(0, len(groups))]\n",
      "s_cut = [0 for i in range(0, len(groups))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 0\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 1\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=100)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=100)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#transformed prediction\n",
      "gid = 0\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "_ = hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_1, s_cut_1 = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_1, s_cut_1\n",
      "cut[gid]=cut_1\n",
      "s_cut[gid]=s_cut_1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 1\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#transformed prediction\n",
      "gid = 1\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "_ = hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_2, s_cut_2 = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_2, s_cut_2\n",
      "cut[gid]=cut_2\n",
      "s_cut[gid]=s_cut_2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 2\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 4\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.99\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 5\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 6\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 7\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.3\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 8\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 9\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test datasets\n",
      "gdf_signal_test = pd.DataFrame()\n",
      "gdf_bck_test = pd.DataFrame()\n",
      "\n",
      "for i in range(0, len(report)):\n",
      "    \n",
      "    len_sig = report[i].prediction_sig['classifier'].shape[0]\n",
      "    len_bck = report[i].prediction_bck['classifier'].shape[0]\n",
      "    \n",
      "    df_temp_sig = pd.DataFrame()\n",
      "    df_temp_bck = pd.DataFrame()\n",
      "    \n",
      "    for k in range(0, len(report)):\n",
      "        df_temp_sig[str(k)] = -999*np.ones(report[i].prediction_sig['classifier'].shape[0])\n",
      "        df_temp_bck[str(k)] = -999*np.ones(report[i].prediction_bck['classifier'].shape[0])\n",
      "    \n",
      "    df_temp_sig[str(i)] = report[i].prediction_sig['classifier']\n",
      "    df_temp_bck[str(i)] = report[i].prediction_bck['classifier']\n",
      "    \n",
      "    gdf_signal_test = pd.concat([gdf_signal_test, df_temp_sig], axis=0)\n",
      "    gdf_bck_test = pd.concat([gdf_bck_test, df_temp_bck], axis=0)\n",
      "    \n",
      "for i in ['DiskSize', 'Nb Replicas', 'LFNSize']:\n",
      "    signal_temp = signal_test[0].get_data([i]).values[:,0]\n",
      "    bck_temp = bck_test[0].get_data([i]).values[:,0]\n",
      "    for k in range(1, len(report)):\n",
      "        signal_temp = np.concatenate((signal_temp,signal_test[k].get_data([i]).values[:,0]), axis=0)\n",
      "        bck_temp = np.concatenate((bck_temp,bck_test[k].get_data([i]).values[:,0]), axis=0)\n",
      "    \n",
      "    gdf_signal_test[i] = signal_temp\n",
      "    gdf_bck_test[i] = bck_temp\n",
      "\n",
      "gds_signal_test = data_storage.DataStorageDF(gdf_signal_test)\n",
      "gds_bck_test = data_storage.DataStorageDF(gdf_bck_test)\n",
      "\n",
      "\n",
      "#train datasets\n",
      "gdf_signal_train = pd.DataFrame()\n",
      "gdf_bck_train = pd.DataFrame()\n",
      "\n",
      "for i in range(0, len(report)):\n",
      "    \n",
      "    len_sig = report_train[i].prediction_sig['classifier'].shape[0]\n",
      "    len_bck = report_train[i].prediction_bck['classifier'].shape[0]\n",
      "    \n",
      "    df_temp_sig = pd.DataFrame()\n",
      "    df_temp_bck = pd.DataFrame()\n",
      "    \n",
      "    for k in range(0, len(report)):\n",
      "        df_temp_sig[str(k)] = -999*np.ones(report_train[i].prediction_sig['classifier'].shape[0])\n",
      "        df_temp_bck[str(k)] = -999*np.ones(report_train[i].prediction_bck['classifier'].shape[0])\n",
      "    \n",
      "    df_temp_sig[str(i)] = report_train[i].prediction_sig['classifier']\n",
      "    df_temp_bck[str(i)] = report_train[i].prediction_bck['classifier']\n",
      "    \n",
      "    gdf_signal_train = pd.concat([gdf_signal_train, df_temp_sig], axis=0)\n",
      "    gdf_bck_train = pd.concat([gdf_bck_train, df_temp_bck], axis=0)\n",
      "    \n",
      "for i in ['DiskSize', 'Nb Replicas', 'LFNSize']:\n",
      "    signal_temp = signal_train[0].get_data([i]).values[:,0]\n",
      "    bck_temp = bck_train[0].get_data([i]).values[:,0]\n",
      "    for k in range(1, len(report)):\n",
      "        signal_temp = np.concatenate((signal_temp,signal_train[k].get_data([i]).values[:,0]), axis=0)\n",
      "        bck_temp = np.concatenate((bck_temp,bck_train[k].get_data([i]).values[:,0]), axis=0)\n",
      "    \n",
      "    gdf_signal_train[i] = signal_temp\n",
      "    gdf_bck_train[i] = bck_temp\n",
      "    \n",
      "gds_signal_train = data_storage.DataStorageDF(gdf_signal_train)\n",
      "gds_bck_train = data_storage.DataStorageDF(gdf_bck_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#All groups\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier_all = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier_all.set_params( params = plst)\n",
      "#setup additional parameters\n",
      "classifier_all.num_boost_round = 2500\n",
      "classifier_all.watch = False\n",
      "classifier_all.missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier_all.fit(gds_signal_train, gds_bck_train)\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report_all = PredictionsInfo({'classifier': classifier_all}, gds_signal_test, gds_bck_test)\n",
      "report_train_all = PredictionsInfo({'classifier': classifier_all}, gds_signal_train, gds_bck_train)\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_all.learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train_all.learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report_all.prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train_all.prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report_all.roc().plot()\n",
      "report_train_all.roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier_all.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#transformed prediction\n",
      "iron = calc_util.classifier_flatten(report_all.prediction_sig['classifier'])\n",
      "_ = hist(iron(report_all.prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(iron(report_all.prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_all, s_cut_all = RSize(report_all, gds_signal_test, gds_bck_test, classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_all, s_cut_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_signal_train, new_signal_test = gds_signal_test.get_train_test(train_size=0.5)\n",
      "new_bck_train, new_bck_test = gds_bck_test.get_train_test(train_size=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#All groups\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.025\n",
      "param['max_depth'] = 1\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier_all = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier_all.set_params( params = plst)\n",
      "#setup additional parameters\n",
      "classifier_all.num_boost_round = 2500\n",
      "classifier_all.watch = False\n",
      "classifier_all.missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier_all.fit(new_signal_train, new_bck_train)\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report_all = PredictionsInfo({'classifier': classifier_all}, new_signal_test, new_bck_test)\n",
      "report_train_all = PredictionsInfo({'classifier': classifier_all}, new_signal_train, new_bck_train)\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_all.learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train_all.learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report_all.prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train_all.prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report_all.roc().plot()\n",
      "report_train_all.roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier_all.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#transformed prediction\n",
      "iron = calc_util.classifier_flatten(report_all.prediction_sig['classifier'])\n",
      "_ = hist(iron(report_all.prediction_sig['classifier']),  histtype='bar', bins=10, alpha=0.5, label='signal')\n",
      "_ = hist(iron(report_all.prediction_bck['classifier']),  histtype='bar', bins=10, alpha=0.5, label='bck')\n",
      "legend(loc='best')\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_all, s_cut_all = RSize(report_all, new_signal_test, new_bck_test, classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_all, s_cut_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "#Compare ROC curves\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "gr_names = groups\n",
      "#Compare Whole-MC and Whole_Real Data ROC curves.\n",
      "for i in range(0, len(groups)):\n",
      "    y_true_wh = np.concatenate((np.ones((report_one.prediction_sig['classifier'][(one_signal_test.get_data(['ConfigGroups']).values[:,0]==groups[i])]).shape[0]),\\\n",
      "                                np.zeros((report_one.prediction_bck['classifier'][(one_bck_test.get_data(['ConfigGroups']).values[:,0]==groups[i])]).shape[0])),\\\n",
      "                               axis=0)\n",
      "    y_score_wh = np.concatenate((report_one.prediction_sig['classifier'][(one_signal_test.get_data(['ConfigGroups']).values[:,0]==groups[i])],\\\n",
      "                                report_one.prediction_bck['classifier'][(one_bck_test.get_data(['ConfigGroups']).values[:,0]==groups[i])]),\\\n",
      "                               axis=0)\n",
      "    fpr_wh, tpr_wh, _ = roc_curve(y_true_wh, y_score_wh)\n",
      "    \n",
      "    y_true_q = np.concatenate((np.ones((report[i].prediction_sig['classifier']).shape[0]),\\\n",
      "                                np.zeros((report[i].prediction_bck['classifier']).shape[0])),\\\n",
      "                               axis=0)\n",
      "    y_score_q = np.concatenate((report[i].prediction_sig['classifier'],\\\n",
      "                                report[i].prediction_bck['classifier']),\\\n",
      "                               axis=0)\n",
      "    fpr_q, tpr_q, _ = roc_curve(y_true_q, y_score_q)\n",
      "    \n",
      "    plt.subplot(1,1,1)\n",
      "    print 'Square under the curve for the Whole Data is ', auc(fpr_wh, tpr_wh)\n",
      "    print 'Square under the curve for the ',gr_names[i], 'is ', auc(fpr_q, tpr_q)\n",
      "    plt.plot(fpr_wh, tpr_wh, 'r', label='Whole Data')\n",
      "    plt.plot(fpr_q, tpr_q, 'b', label=gr_names[i])\n",
      "    plt.legend(loc='best')\n",
      "    plt.title('ROC')\n",
      "    plt.show()\n",
      "    \n",
      "#Compare Whole-All_groups ROC curve\n",
      "y_true_wh = np.concatenate((np.ones((report_one.prediction_sig['classifier']).shape[0]),\\\n",
      "                            np.zeros((report_one.prediction_bck['classifier']).shape[0])),\\\n",
      "                            axis=0)\n",
      "y_score_wh = np.concatenate((report_one.prediction_sig['classifier'],\\\n",
      "                            report_one.prediction_bck['classifier']),\\\n",
      "                            axis=0)\n",
      "fpr_wh, tpr_wh, _ = roc_curve(y_true_wh, y_score_wh)\n",
      "    \n",
      "y_true_all = np.concatenate((np.ones((report_all.prediction_sig['classifier']).shape[0]),\\\n",
      "                            np.zeros((report_all.prediction_bck['classifier']).shape[0])),\\\n",
      "                            axis=0)\n",
      "y_score_all = np.concatenate((report_all.prediction_sig['classifier'],\\\n",
      "                            report_all.prediction_bck['classifier']),\\\n",
      "                            axis=0)\n",
      "fpr_all, tpr_all, _ = roc_curve(y_true_all, y_score_all)\n",
      "    \n",
      "plt.subplot(1,1,1)\n",
      "print 'Square under the curve for the Whole Data is ', auc(fpr_wh, tpr_wh)\n",
      "print 'Square under the curve for the all groups is ', auc(fpr_all, tpr_all)\n",
      "plt.plot(fpr_wh, tpr_wh, 'r', label='Whole Data')\n",
      "plt.plot(fpr_all, tpr_all, 'b', label='All groups')\n",
      "plt.legend(loc='best')\n",
      "plt.title('ROC')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def BraveSt(report, classifier, cut, signal, bck):\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    memory = signal.get_data(['DiskSize'])[iron(report.prediction_sig[classifier]) >= cut].values.sum()\\\n",
      "    +bck.get_data(['DiskSize'])[iron(report.prediction_bck[classifier]) >= cut].values.sum()\n",
      "    \n",
      "    return memory\n",
      "\n",
      "def SafeSt(report, classifier, cut, signal, bck):\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    \n",
      "    nzrs = (signal.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    nzrb = (bck.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "\n",
      "    memory = signal.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= cut)&nzrs].values.sum()\\\n",
      "    +bck.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= cut)&nzrb].values.sum()\\\n",
      "    -signal.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= cut)&nzrs].values.sum()\\\n",
      "    -bck.get_data(['LFNSize'])[(iron(report.prediction_bck[classifier]) >= cut)&nzrb].values.sum()\n",
      "    \n",
      "    return memory\n",
      "\n",
      "def CombineSt(report, classifier, s_cut, cut, signal, bck):\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    \n",
      "    nzrs = (signal.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    nzrb = (bck.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    \n",
      "    memory231 = signal.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= s_cut)&nzrs].values.sum()\\\n",
      "    +bck.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= s_cut)&nzrb].values.sum()\\\n",
      "    -signal.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= s_cut)&nzrs].values.sum()\\\n",
      "    -bck.get_data(['LFNSize'])[(iron(report.prediction_bck[classifier]) >= s_cut)&nzrb].values.sum()\n",
      "\n",
      "    memory232 = signal.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= cut)&nzrs].values.sum()\\\n",
      "    +bck.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= cut)&nzrb].values.sum()\\\n",
      "    -signal.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= cut)&nzrs].values.sum()\\\n",
      "    -bck.get_data(['LFNSize'])[(iron(report.prediction_bck[classifier]) >= cut)&nzrb].values.sum()\n",
      "\n",
      "    memory233 = signal.get_data(['DiskSize'])[iron(report.prediction_sig[classifier]) >= cut].values.sum()\\\n",
      "    +bck.get_data(['DiskSize'])[iron(report.prediction_bck[classifier]) >= cut].values.sum()\n",
      "\n",
      "    memory23 = memory231-memory232+memory233\n",
      "    \n",
      "    return memory23\n",
      "\n",
      "\n",
      "#Selection\n",
      "sel = ((data['Now'] - data['Creation-week']) > 26)&((data['Now'] - data['FirstUsage']) > 26)&((data[78] - data[1]) == 0)\n",
      "memory1 = data[sel].get('DiskSize').values.sum()\n",
      "print memory1\n",
      "\n",
      "def Totals(signal, bck):\n",
      "    total = signal.get_data(['DiskSize']).values.sum()+bck.get_data(['DiskSize']).values.sum()\n",
      "    return total\n",
      "    \n",
      "def CanRel(signal, bck):\n",
      "    can_released = signal.get_data(['DiskSize']).values.sum()\n",
      "    return can_released"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Total Size of the Datasets is ', Totals(one_signal_test, one_bck_test)\n",
      "#print 'Total Storage Space could be saved is ', CanRel(one_signal_test, one_bck_test)\n",
      "print 'Memory 1 is ', memory1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "memory_one = CombineSt(report_one, 'classifier', s_cut_one, cut_one, one_signal_test, one_bck_test)\n",
      "memory_gr=0\n",
      "for i in range(0, len(groups)):\n",
      "    memory_gr = memory_gr + CombineSt(report[i], 'classifier', s_cut[i], cut[i], signal_test[i], bck_test[i])\n",
      "memory_all = 2*CombineSt(report_all, 'classifier', s_cut_all, cut_all, new_signal_test, new_bck_test)#\\\n",
      "#+CombineSt(report_train_all, 'classifier', s_cut_all, cut_all, new_signal_train, new_bck_train)\n",
      "\n",
      "print memory_one\n",
      "print memory_gr\n",
      "print memory_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "memory_one = BraveSt(report_one, 'classifier', cut_one, one_signal_test, one_bck_test)\n",
      "memory_gr=0\n",
      "for i in range(0, len(groups)):\n",
      "    memory_gr = memory_gr + BraveSt(report[i], 'classifier', cut[i], signal_test[i], bck_test[i])\n",
      "memory_all = BraveSt(report_all, 'classifier', cut_all, new_signal_test, new_bck_test)\\\n",
      "+BraveSt(report_train_all, 'classifier', cut_all, new_signal_train, new_bck_train)\n",
      "\n",
      "print memory_one\n",
      "print memory_gr\n",
      "print memory_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "memory_one = SafeSt(report_one, 'classifier', s_cut_one, one_signal_test, one_bck_test)\n",
      "memory_gr=0\n",
      "for i in range(0, len(groups)):\n",
      "    memory_gr = memory_gr + SafeSt(report[i], 'classifier', s_cut[i], signal_test[i], bck_test[i])\n",
      "memory_all = SafeSt(report_all, 'classifier', s_cut_all, new_signal_test, new_bck_test)\\\n",
      "+SafeSt(report_train_all, 'classifier', s_cut_all, new_signal_train, new_bck_train)\n",
      "\n",
      "print memory_one\n",
      "print memory_gr\n",
      "print memory_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "session = ipykee.Session(project_name=\"C._NewFeatures\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit(\"Upload by ipykee. Not optimized\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit(\"Upload by ipykee. Not optimized\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 0\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=100)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=100)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 0\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 2\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 1\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=100)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=100)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#transformed prediction\n",
      "gid = 0\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "_ = hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_1, s_cut_1 = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_1, s_cut_1\n",
      "cut[gid]=cut_1\n",
      "s_cut[gid]=s_cut_1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 1\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.4\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 1\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.99\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 1\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 1\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.6\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 1\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.4\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 1\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 1\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 3\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 1\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 1\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#transformed prediction\n",
      "gid = 1\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "_ = hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_2, s_cut_2 = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_2, s_cut_2\n",
      "cut[gid]=cut_2\n",
      "s_cut[gid]=s_cut_2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 2\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 2\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 1\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 2\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.4\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.3\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 200\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 200\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 3\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 3\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 200\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 3\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 3\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 4\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 4\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 1\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 6\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 6\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.99\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 6\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.01\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group ID\n",
      "gid = 8\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.5\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier[gid] = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier[gid].set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "classifier[gid].num_boost_round = 2500\n",
      "classifier[gid].watch = False\n",
      "classifier[gid].missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier[gid].fit(signal_train[gid], bck_train[gid])\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_test[gid], bck_test[gid])\n",
      "report_train[gid] = PredictionsInfo({'classifier': classifier[gid]}, signal_train[gid], bck_train[gid])\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report[gid].learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train[gid].learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report[gid].prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train[gid].prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report[gid].roc().plot()\n",
      "report_train[gid].roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier[gid].get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')\n",
      "\n",
      "\n",
      "plt.subplot(1,1,1)\n",
      "plt.figure()\n",
      "iron = calc_util.classifier_flatten(report[gid].prediction_sig['classifier'])\n",
      "plt.hist(iron(report[gid].prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "plt.hist(iron(report[gid].prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_i, s_cut_i = RSize(report[gid], signal_test[gid], bck_test[gid], classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_i, s_cut_i\n",
      "cut[gid]=cut_i\n",
      "s_cut[gid]=s_cut_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test datasets\n",
      "gdf_signal_test = pd.DataFrame()\n",
      "gdf_bck_test = pd.DataFrame()\n",
      "\n",
      "for i in range(0, len(report)):\n",
      "    \n",
      "    len_sig = report[i].prediction_sig['classifier'].shape[0]\n",
      "    len_bck = report[i].prediction_bck['classifier'].shape[0]\n",
      "    \n",
      "    df_temp_sig = pd.DataFrame()\n",
      "    df_temp_bck = pd.DataFrame()\n",
      "    \n",
      "    for k in range(0, len(report)):\n",
      "        df_temp_sig[str(k)] = -999*np.ones(report[i].prediction_sig['classifier'].shape[0])\n",
      "        df_temp_bck[str(k)] = -999*np.ones(report[i].prediction_bck['classifier'].shape[0])\n",
      "    \n",
      "    df_temp_sig[str(i)] = report[i].prediction_sig['classifier']\n",
      "    df_temp_bck[str(i)] = report[i].prediction_bck['classifier']\n",
      "    \n",
      "    gdf_signal_test = pd.concat([gdf_signal_test, df_temp_sig], axis=0)\n",
      "    gdf_bck_test = pd.concat([gdf_bck_test, df_temp_bck], axis=0)\n",
      "    \n",
      "for i in ['DiskSize', 'Nb Replicas', 'LFNSize']:\n",
      "    signal_temp = signal_test[0].get_data([i]).values[:,0]\n",
      "    bck_temp = bck_test[0].get_data([i]).values[:,0]\n",
      "    for k in range(1, len(report)):\n",
      "        signal_temp = np.concatenate((signal_temp,signal_test[k].get_data([i]).values[:,0]), axis=0)\n",
      "        bck_temp = np.concatenate((bck_temp,bck_test[k].get_data([i]).values[:,0]), axis=0)\n",
      "    \n",
      "    gdf_signal_test[i] = signal_temp\n",
      "    gdf_bck_test[i] = bck_temp\n",
      "\n",
      "gds_signal_test = data_storage.DataStorageDF(gdf_signal_test)\n",
      "gds_bck_test = data_storage.DataStorageDF(gdf_bck_test)\n",
      "\n",
      "\n",
      "#train datasets\n",
      "gdf_signal_train = pd.DataFrame()\n",
      "gdf_bck_train = pd.DataFrame()\n",
      "\n",
      "for i in range(0, len(report)):\n",
      "    \n",
      "    len_sig = report_train[i].prediction_sig['classifier'].shape[0]\n",
      "    len_bck = report_train[i].prediction_bck['classifier'].shape[0]\n",
      "    \n",
      "    df_temp_sig = pd.DataFrame()\n",
      "    df_temp_bck = pd.DataFrame()\n",
      "    \n",
      "    for k in range(0, len(report)):\n",
      "        df_temp_sig[str(k)] = -999*np.ones(report_train[i].prediction_sig['classifier'].shape[0])\n",
      "        df_temp_bck[str(k)] = -999*np.ones(report_train[i].prediction_bck['classifier'].shape[0])\n",
      "    \n",
      "    df_temp_sig[str(i)] = report_train[i].prediction_sig['classifier']\n",
      "    df_temp_bck[str(i)] = report_train[i].prediction_bck['classifier']\n",
      "    \n",
      "    gdf_signal_train = pd.concat([gdf_signal_train, df_temp_sig], axis=0)\n",
      "    gdf_bck_train = pd.concat([gdf_bck_train, df_temp_bck], axis=0)\n",
      "    \n",
      "for i in ['DiskSize', 'Nb Replicas', 'LFNSize']:\n",
      "    signal_temp = signal_train[0].get_data([i]).values[:,0]\n",
      "    bck_temp = bck_train[0].get_data([i]).values[:,0]\n",
      "    for k in range(1, len(report)):\n",
      "        signal_temp = np.concatenate((signal_temp,signal_train[k].get_data([i]).values[:,0]), axis=0)\n",
      "        bck_temp = np.concatenate((bck_temp,bck_train[k].get_data([i]).values[:,0]), axis=0)\n",
      "    \n",
      "    gdf_signal_train[i] = signal_temp\n",
      "    gdf_bck_train[i] = bck_temp\n",
      "    \n",
      "gds_signal_train = data_storage.DataStorageDF(gdf_signal_train)\n",
      "gds_bck_train = data_storage.DataStorageDF(gdf_bck_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#All groups\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.05\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier_all = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier_all.set_params( params = plst)\n",
      "#setup additional parameters\n",
      "classifier_all.num_boost_round = 2500\n",
      "classifier_all.watch = False\n",
      "classifier_all.missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier_all.fit(gds_signal_train, gds_bck_train)\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report_all = PredictionsInfo({'classifier': classifier_all}, gds_signal_test, gds_bck_test)\n",
      "report_train_all = PredictionsInfo({'classifier': classifier_all}, gds_signal_train, gds_bck_train)\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_all.learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train_all.learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report_all.prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train_all.prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report_all.roc().plot()\n",
      "report_train_all.roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier_all.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#transformed prediction\n",
      "iron = calc_util.classifier_flatten(report_all.prediction_sig['classifier'])\n",
      "_ = hist(iron(report_all.prediction_sig['classifier']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(iron(report_all.prediction_bck['classifier']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_all, s_cut_all = RSize(report_all, gds_signal_test, gds_bck_test, classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_all, s_cut_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_signal_train, new_signal_test = gds_signal_test.get_train_test(train_size=0.5)\n",
      "new_bck_train, new_bck_test = gds_bck_test.get_train_test(train_size=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#All groups\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.025\n",
      "param['max_depth'] = 1\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "classifier_all = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "classifier_all.set_params( params = plst)\n",
      "#setup additional parameters\n",
      "classifier_all.num_boost_round = 2500\n",
      "classifier_all.watch = False\n",
      "classifier_all.missing = None\n",
      "\n",
      "#trainig classifier\n",
      "classifier_all.fit(new_signal_train, new_bck_train)\n",
      "\n",
      "print 'Classifier Results'\n",
      "# get prediction on data after classification\n",
      "report_all = PredictionsInfo({'classifier': classifier_all}, new_signal_test, new_bck_test)\n",
      "report_train_all = PredictionsInfo({'classifier': classifier_all}, new_signal_train, new_bck_train)\n",
      "#plotting learning curves\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_all.learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train_all.learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()\n",
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report_all.prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train_all.prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')\n",
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report_all.roc().plot()\n",
      "report_train_all.roc().plot()\n",
      "legend(['test', 'train'], loc='best')\n",
      "#Plot importances of features according to trained model\n",
      "importance = classifier_all.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#transformed prediction\n",
      "iron = calc_util.classifier_flatten(report_all.prediction_sig['classifier'])\n",
      "_ = hist(iron(report_all.prediction_sig['classifier']),  histtype='bar', bins=10, alpha=0.5, label='signal')\n",
      "_ = hist(iron(report_all.prediction_bck['classifier']),  histtype='bar', bins=10, alpha=0.5, label='bck')\n",
      "legend(loc='best')\n",
      "\n",
      "#Storage Space Saving\n",
      "cut_all, s_cut_all = RSize(report_all, new_signal_test, new_bck_test, classifier='classifier', mincut=0.1, maxcut=1, N=100, cond=0, Flag=True)\n",
      "print cut_all, s_cut_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "#Compare ROC curves\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "gr_names = groups\n",
      "#Compare Whole-MC and Whole_Real Data ROC curves.\n",
      "for i in range(0, len(groups)):\n",
      "    y_true_wh = np.concatenate((np.ones((report_one.prediction_sig['classifier'][(one_signal_test.get_data(['ConfigGroups']).values[:,0]==groups[i])]).shape[0]),\\\n",
      "                                np.zeros((report_one.prediction_bck['classifier'][(one_bck_test.get_data(['ConfigGroups']).values[:,0]==groups[i])]).shape[0])),\\\n",
      "                               axis=0)\n",
      "    y_score_wh = np.concatenate((report_one.prediction_sig['classifier'][(one_signal_test.get_data(['ConfigGroups']).values[:,0]==groups[i])],\\\n",
      "                                report_one.prediction_bck['classifier'][(one_bck_test.get_data(['ConfigGroups']).values[:,0]==groups[i])]),\\\n",
      "                               axis=0)\n",
      "    fpr_wh, tpr_wh, _ = roc_curve(y_true_wh, y_score_wh)\n",
      "    \n",
      "    y_true_q = np.concatenate((np.ones((report[i].prediction_sig['classifier']).shape[0]),\\\n",
      "                                np.zeros((report[i].prediction_bck['classifier']).shape[0])),\\\n",
      "                               axis=0)\n",
      "    y_score_q = np.concatenate((report[i].prediction_sig['classifier'],\\\n",
      "                                report[i].prediction_bck['classifier']),\\\n",
      "                               axis=0)\n",
      "    fpr_q, tpr_q, _ = roc_curve(y_true_q, y_score_q)\n",
      "    \n",
      "    plt.subplot(1,1,1)\n",
      "    print 'Square under the curve for the Whole Data is ', auc(fpr_wh, tpr_wh)\n",
      "    print 'Square under the curve for the ',gr_names[i], 'is ', auc(fpr_q, tpr_q)\n",
      "    plt.plot(fpr_wh, tpr_wh, 'r', label='Whole Data')\n",
      "    plt.plot(fpr_q, tpr_q, 'b', label=gr_names[i])\n",
      "    plt.legend(loc='best')\n",
      "    plt.title('ROC')\n",
      "    plt.show()\n",
      "    \n",
      "#Compare Whole-All_groups ROC curve\n",
      "y_true_wh = np.concatenate((np.ones((report_one.prediction_sig['classifier']).shape[0]),\\\n",
      "                            np.zeros((report_one.prediction_bck['classifier']).shape[0])),\\\n",
      "                            axis=0)\n",
      "y_score_wh = np.concatenate((report_one.prediction_sig['classifier'],\\\n",
      "                            report_one.prediction_bck['classifier']),\\\n",
      "                            axis=0)\n",
      "fpr_wh, tpr_wh, _ = roc_curve(y_true_wh, y_score_wh)\n",
      "    \n",
      "y_true_all = np.concatenate((np.ones((report_all.prediction_sig['classifier']).shape[0]),\\\n",
      "                            np.zeros((report_all.prediction_bck['classifier']).shape[0])),\\\n",
      "                            axis=0)\n",
      "y_score_all = np.concatenate((report_all.prediction_sig['classifier'],\\\n",
      "                            report_all.prediction_bck['classifier']),\\\n",
      "                            axis=0)\n",
      "fpr_all, tpr_all, _ = roc_curve(y_true_all, y_score_all)\n",
      "    \n",
      "plt.subplot(1,1,1)\n",
      "print 'Square under the curve for the Whole Data is ', auc(fpr_wh, tpr_wh)\n",
      "print 'Square under the curve for the all groups is ', auc(fpr_all, tpr_all)\n",
      "plt.plot(fpr_wh, tpr_wh, 'r', label='Whole Data')\n",
      "plt.plot(fpr_all, tpr_all, 'b', label='All groups')\n",
      "plt.legend(loc='best')\n",
      "plt.title('ROC')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def BraveSt(report, classifier, cut, signal, bck):\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    memory = signal.get_data(['DiskSize'])[iron(report.prediction_sig[classifier]) >= cut].values.sum()\\\n",
      "    +bck.get_data(['DiskSize'])[iron(report.prediction_bck[classifier]) >= cut].values.sum()\n",
      "    \n",
      "    return memory\n",
      "\n",
      "def SafeSt(report, classifier, cut, signal, bck):\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    \n",
      "    nzrs = (signal.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    nzrb = (bck.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "\n",
      "    memory = signal.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= cut)&nzrs].values.sum()\\\n",
      "    +bck.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= cut)&nzrb].values.sum()\\\n",
      "    -signal.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= cut)&nzrs].values.sum()\\\n",
      "    -bck.get_data(['LFNSize'])[(iron(report.prediction_bck[classifier]) >= cut)&nzrb].values.sum()\n",
      "    \n",
      "    return memory\n",
      "\n",
      "def CombineSt(report, classifier, s_cut, cut, signal, bck):\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    \n",
      "    nzrs = (signal.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    nzrb = (bck.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    \n",
      "    memory231 = signal.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= s_cut)&nzrs].values.sum()\\\n",
      "    +bck.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= s_cut)&nzrb].values.sum()\\\n",
      "    -signal.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= s_cut)&nzrs].values.sum()\\\n",
      "    -bck.get_data(['LFNSize'])[(iron(report.prediction_bck[classifier]) >= s_cut)&nzrb].values.sum()\n",
      "\n",
      "    memory232 = signal.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= cut)&nzrs].values.sum()\\\n",
      "    +bck.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= cut)&nzrb].values.sum()\\\n",
      "    -signal.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= cut)&nzrs].values.sum()\\\n",
      "    -bck.get_data(['LFNSize'])[(iron(report.prediction_bck[classifier]) >= cut)&nzrb].values.sum()\n",
      "\n",
      "    memory233 = signal.get_data(['DiskSize'])[iron(report.prediction_sig[classifier]) >= cut].values.sum()\\\n",
      "    +bck.get_data(['DiskSize'])[iron(report.prediction_bck[classifier]) >= cut].values.sum()\n",
      "\n",
      "    memory23 = memory231-memory232+memory233\n",
      "    \n",
      "    return memory23\n",
      "\n",
      "\n",
      "#Selection\n",
      "sel = ((data['Now'] - data['Creation-week']) > 26)&((data['Now'] - data['FirstUsage']) > 26)&((data[78] - data[1]) == 0)\n",
      "memory1 = data[sel].get('DiskSize').values.sum()\n",
      "print memory1\n",
      "\n",
      "def Totals(signal, bck):\n",
      "    total = signal.get_data(['DiskSize']).values.sum()+bck.get_data(['DiskSize']).values.sum()\n",
      "    return total\n",
      "    \n",
      "def CanRel(signal, bck):\n",
      "    can_released = signal.get_data(['DiskSize']).values.sum()\n",
      "    return can_released"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Total Size of the Datasets is ', Totals(one_signal_test, one_bck_test)\n",
      "#print 'Total Storage Space could be saved is ', CanRel(one_signal_test, one_bck_test)\n",
      "print 'Memory 1 is ', memory1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "memory_one = CombineSt(report_one, 'classifier', s_cut_one, cut_one, one_signal_test, one_bck_test)\n",
      "memory_gr=0\n",
      "for i in range(0, len(groups)):\n",
      "    memory_gr = memory_gr + CombineSt(report[i], 'classifier', s_cut[i], cut[i], signal_test[i], bck_test[i])\n",
      "memory_all = 2*CombineSt(report_all, 'classifier', s_cut_all, cut_all, new_signal_test, new_bck_test)#\\\n",
      "#+CombineSt(report_train_all, 'classifier', s_cut_all, cut_all, new_signal_train, new_bck_train)\n",
      "\n",
      "print memory_one\n",
      "print memory_gr\n",
      "print memory_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "memory_one = BraveSt(report_one, 'classifier', cut_one, one_signal_test, one_bck_test)\n",
      "memory_gr=0\n",
      "for i in range(0, len(groups)):\n",
      "    memory_gr = memory_gr + BraveSt(report[i], 'classifier', cut[i], signal_test[i], bck_test[i])\n",
      "memory_all = BraveSt(report_all, 'classifier', cut_all, new_signal_test, new_bck_test)\\\n",
      "+BraveSt(report_train_all, 'classifier', cut_all, new_signal_train, new_bck_train)\n",
      "\n",
      "print memory_one\n",
      "print memory_gr\n",
      "print memory_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "memory_one = SafeSt(report_one, 'classifier', s_cut_one, one_signal_test, one_bck_test)\n",
      "memory_gr=0\n",
      "for i in range(0, len(groups)):\n",
      "    memory_gr = memory_gr + SafeSt(report[i], 'classifier', s_cut[i], signal_test[i], bck_test[i])\n",
      "memory_all = SafeSt(report_all, 'classifier', s_cut_all, new_signal_test, new_bck_test)\\\n",
      "+SafeSt(report_train_all, 'classifier', s_cut_all, new_signal_train, new_bck_train)\n",
      "\n",
      "print memory_one\n",
      "print memory_gr\n",
      "print memory_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "session = ipykee.Session(project_name=\"C._NewFeatures\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    }
   ],
   "metadata": {}
  }
 ]
}