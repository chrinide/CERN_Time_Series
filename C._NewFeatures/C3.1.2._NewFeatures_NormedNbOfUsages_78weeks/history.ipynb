{
 "metadata": {
  "name": "/ipykee/workdir/tmpNTK8Bb/C"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%pylab inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#Load original data\n",
      "data = pd.read_excel('popularity-728days_my.xls')\n",
      "data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Select data\n",
      "selection = ((data['Now'] - data['Creation-week']) > 26)&((data['Now'] - data['FirstUsage']) > 26)&((data[78] - data[1]) != 0)\n",
      "data_sel = data[selection].copy()\n",
      "#data_sel = data.copy()\n",
      "print data_sel.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "periods = range(1,79)\n",
      "\n",
      "#------------------------------------------------------\n",
      "#Get maximum intervals and last weeks with zeros usages\n",
      "def InterMax(data_sel, periods):\n",
      "    #Get binary vector representation of the selected data\n",
      "    data_bv = data_sel.copy()\n",
      "    #Get week's usages\n",
      "    for i in periods:\n",
      "        if i!=1:\n",
      "            data_bv[i] = data_sel[i] - data_sel[i-1]\n",
      "            \n",
      "    #Get binary representation\n",
      "    data_bv[periods] = (data_bv[periods] != 0)*1\n",
      "    \n",
      "    inter_max = []\n",
      "    last_zeros = []\n",
      "    nb_peaks = []\n",
      "    inter_mean = []\n",
      "    inter_std = []\n",
      "    inter_rel = []\n",
      "    \n",
      "    for i in range(0,data_bv.shape[0]):\n",
      "        ds = data_bv[periods].irow(i)\n",
      "        nz = ds.nonzero()[0]\n",
      "        inter = []\n",
      "        \n",
      "        nb_peaks.append(len(nz))\n",
      "        if len(nz)==0:\n",
      "            nz = [0]\n",
      "        if len(nz)<2:\n",
      "            inter = [0]\n",
      "            #nz = [0]\n",
      "        else:\n",
      "            for k in range(0, len(nz)-1):\n",
      "                val = nz[k+1]-nz[k]\n",
      "                inter.append(val)\n",
      "        \n",
      "        inter = np.array(inter)\n",
      "        inter_mean.append(inter.mean())\n",
      "        inter_std.append(inter.std())\n",
      "        if inter.mean()!=0:\n",
      "            inter_rel.append(inter.std()/inter.mean())\n",
      "        else:\n",
      "            inter_rel.append(0)\n",
      "                \n",
      "        last_zeros.append(periods[-1] - nz[-1] + 1)\n",
      "        inter_max.append(max(inter))\n",
      "    \n",
      "    return np.array(inter_max), np.array(last_zeros), np.array(nb_peaks), np.array(inter_mean), np.array(inter_std), np.array(inter_rel)\n",
      "#------------------------------------------------------\n",
      "def MassCenter(data_sel, periods):\n",
      "    data_bv = data_sel.copy()\n",
      "    p = np.array(periods) - periods[0]+1\n",
      "    #Get week's usages\n",
      "    for i in periods:\n",
      "        if i!=1:\n",
      "            data_bv[i] = data_sel[i] - data_sel[i-1]\n",
      "    max_values = data_bv[periods].max(axis=1)\n",
      "    for i in periods:\n",
      "        data_bv[i] = (data_bv[i]/max_values).values\n",
      "    \n",
      "    mass_center = []\n",
      "    mass_center2 = []\n",
      "    mass_moment = []\n",
      "    r_moment = []\n",
      "            \n",
      "    for i in range(0,data_bv.shape[0]):\n",
      "        center = (data_bv[periods].irow(i).values*p).sum()/data_bv[periods].irow(i).values.sum()\n",
      "        center2 = (data_bv[periods].irow(i).values*np.square(p)).sum()\n",
      "        moment = (data_bv[periods].irow(i).values*np.square(p-center)).sum()\n",
      "        r_m = moment/data_bv[periods].irow(i).values.sum()\n",
      "        mass_center.append(center)\n",
      "        mass_center2.append(center2)\n",
      "        mass_moment.append(moment)\n",
      "        r_moment.append(r_m)\n",
      "    \n",
      "    print data_bv.shape\n",
      "    print data_sel.shape\n",
      "        \n",
      "    return np.array(mass_center), np.array(mass_moment), np.array(r_moment), np.array(mass_center2)\n",
      "#------------------------------------------------------\n",
      "def Binary(data_sel, periods):\n",
      "    data_bv = data_sel.copy()\n",
      "    p = np.array(periods) - periods[0]+1\n",
      "    #Get week's usages\n",
      "    for i in periods:\n",
      "        if i!=1:\n",
      "            data_bv[i] = data_sel[i] - data_sel[i-1]\n",
      "    #Get binary representation\n",
      "    data_bv[p] = (data_bv[periods] != 0)*1\n",
      "    \n",
      "    return data_bv[p]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create a Data Frame for Classifier\n",
      "df = pd.DataFrame()\n",
      "\n",
      "#Add features\n",
      "inter_max, last_zeros, nb_peaks, inter_mean, inter_std, inter_rel = InterMax(data_sel, periods)\n",
      "df['last-zeros'] = last_zeros\n",
      "df['inter_max'] = inter_max\n",
      "df['nb_peaks'] = nb_peaks\n",
      "df['inter_mean'] = inter_mean\n",
      "df['inter_std'] = inter_std\n",
      "df['inter_rel'] = inter_rel\n",
      "\n",
      "mass_center, mass_moment, r_moment, mass_center2 = MassCenter(data_sel, periods)\n",
      "df['mass_center'] = mass_center\n",
      "df['mass_center_sqr'] = mass_center2\n",
      "df['mass_moment'] = mass_moment\n",
      "df['r_moment'] = r_moment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['DiskSize'] = data_sel['DiskSize'].values\n",
      "df['LFNSize'] = data_sel['LFNSize'].values\n",
      "df['Nb Replicas'] = data_sel['Nb Replicas'].values\n",
      "\n",
      "df['LogDiskSize'] = np.log(data_sel['DiskSize'].values+0.00001)\n",
      "df['total_usage'] = data_sel[periods[-1]].values\n",
      "df['mean_usage'] = df['total_usage'].values/(df['nb_peaks'].values+1)\n",
      "\n",
      "df['log_total_usage'] = np.log(data_sel[periods[-1]].values+1)\n",
      "df['log_mean_usage'] = df['total_usage'].values - np.log(df['nb_peaks'].values+1)\n",
      "\n",
      "\"\"\"\n",
      "df['log_mass_center'] = np.log(mass_center+1)\n",
      "df['log_mass_moment'] = np.log(mass_moment+1)\n",
      "df['log_r_moment'] = np.log(r_moment+1)\n",
      "df['log_mass_center_sqr'] = np.log(mass_center2+1)\n",
      "\n",
      "df['log_last-zeros'] = np.log(last_zeros+1)\n",
      "df['log_inter_max'] = np.log(inter_max+1)\n",
      "df['log_nb_peaks'] = np.log(nb_peaks+1)\n",
      "df['log_inter_mean'] = np.log(inter_mean+1)\n",
      "df['log_inter_std'] = np.log(inter_std+1)\n",
      "df['log_inter_rel'] = np.log(inter_rel+1)\n",
      "\"\"\"\n",
      "\n",
      "#df['FileType'] = data_sel['FileType']\n",
      "#df['Configuration'] = data_sel['Configuration']\n",
      "#df['ProcessingPass'] = data_sel['ProcessingPass']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Transform string features to digits\n",
      "cols_str = ['Configuration', 'ProcessingPass', 'FileType', 'Storage']\n",
      "df_str = data_sel.get(cols_str)\n",
      "\n",
      "for col in cols_str:\n",
      "    unique = np.unique(df_str[col])\n",
      "    index = range(0, len(unique))\n",
      "    mapping = dict(zip(unique, index))\n",
      "    df_str = df_str.replace({col:mapping})\n",
      "    \n",
      "df['FileType'] = df_str['FileType'].values\n",
      "df['Configuration'] = df_str['Configuration'].values\n",
      "df['ProcessingPass'] = df_str['ProcessingPass'].values\n",
      "\n",
      "other_vars = [u'Type', u'Creation-week', u'NbLFN', u'LFNSize', u'NbDisk', u'DiskSize', u'NbTape', u'TapeSize',\n",
      "              u'NbArchived', u'ArchivedSize', u'Nb Replicas', u'Nb ArchReps', u'FirstUsage']\n",
      "for i in other_vars:\n",
      "    df[i] = data_sel[i].values\n",
      "df['silence'] = df['FirstUsage']-df[u'Creation-week']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Add Binary Vector\n",
      "\"\"\"\n",
      "bv = Binary(data_sel, periods)\n",
      "p = np.array(periods) - periods[0]+1\n",
      "for i in p:\n",
      "    df[i]=bv[i].values\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get noremd week's usages\n",
      "data_b = data_sel.copy()\n",
      "for i in periods:\n",
      "    if i!=1:\n",
      "        data_b[i] = data_sel[i] - data_sel[i-1]\n",
      "max_values = data_b[periods].max(axis=1)\n",
      "\n",
      "#add weekly usages transformed to [0,1] range of values\n",
      "for i in periods:\n",
      "    df[str(i)] = (data_b[i]/max_values).values\n",
      "#add periods in string form    \n",
      "periods_txt = []\n",
      "for i in periods:\n",
      "    periods_txt.append(str(i))\n",
      "\n",
      "#all weeks were divided into several bins.\n",
      "bins = []\n",
      "for i in range(0, periods[-1]//13):\n",
      "    cur_bin = data_b[range(i*13+1, (i+1)*13+1)]\n",
      "    df[\"bin\"+str(i)] = cur_bin.mean(axis=1).values\n",
      "    bins.append(\"bin\"+str(i))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_true = ((data_sel[104] - data_sel[78]) == 0).values*1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in df.columns:\n",
      "    plt.subplot(1,1,1)\n",
      "    plt.hist(df[i][y_true == 1].values, label='signal', color='b', alpha=0.5, bins = 10)\n",
      "    plt.hist(df[i][y_true == 0].values, label='bck', color='r', alpha=0.5, bins = 10)\n",
      "    plt.ylabel('Nb of data sets')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.title(i)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#After additional selection\n",
      "\"\"\"\n",
      "for i in df_s.columns:\n",
      "    plt.subplot(1,1,1)\n",
      "    plt.hist(df_s[i][y_true_s == 1].values, label='1', color='b', alpha=0.5, bins = 20)\n",
      "    plt.hist(df_s[i][y_true_s == 0].values, label='0', color='r', alpha=0.5, bins = 20)\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.title(i)\n",
      "    plt.show()\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "\"\"\"\n",
      "df = df_s\n",
      "y_true = y_true_s\n",
      "df.shape\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Preparing signal and background data for classifier\n",
      "from cern_utils import data_storage\n",
      "\n",
      "#Load signal and background data\n",
      "signal_data = data_storage.DataStorageDF(df[y_true == 1])\n",
      "bck_data = data_storage.DataStorageDF(df[y_true == 0])\n",
      "# Get train and test data\n",
      "signal_train, signal_test = signal_data.get_train_test(train_size=0.5)\n",
      "bck_train, bck_test = bck_data.get_train_test(train_size=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#select variables for classifier\n",
      "columns = signal_data.columns\n",
      "print columns\n",
      "print '****************************************************'\n",
      "\n",
      "variables = ['last-zeros', 'mass_center', 'inter_max', 'nb_peaks', u'inter_mean', u'inter_std', u'inter_rel',\n",
      "             u'mass_moment', u'r_moment',u'FileType',\n",
      "             u'Configuration', u'ProcessingPass']#, u'Nb Replicas', ]\n",
      "    \n",
      "variables = [u'last-zeros', u'inter_max', u'nb_peaks', u'inter_mean', u'inter_std', u'inter_rel', u'mass_center',\n",
      "             u'mass_center_sqr', u'mass_moment', u'r_moment', u'DiskSize', u'LogDiskSize', u'total_usage', u'mean_usage',\n",
      "             u'FileType', u'Configuration', u'ProcessingPass', u'log_total_usage', u'log_mean_usage']+other_vars+bins\n",
      "\n",
      "#variables = signal_data.columns\n",
      "\n",
      "print variables\n",
      "print len(variables)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"/home/mikhail91/xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from cern_utils import xgboost_classifier\n",
      "\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.02\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "xgboost = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "xgboost.set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "xgboost.num_boost_round = 2500\n",
      "xgboost.watch = False\n",
      "\n",
      "#trainig classifier\n",
      "xgboost.fit(signal_train, bck_train)#,\\\n",
      "            #weight_sig=signal_train.get_data(['total_usage']).values,\\\n",
      "            #weight_bck=bck_train.get_data(['total_usage']).values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from cern_utils import xgboost_classifier\n",
      "\n",
      "\n",
      "# setup parameters for xgboost\n",
      "param = {}\n",
      "param['objective'] = 'binary:logitraw'\n",
      "param['scale_pos_weight'] = 1\n",
      "param['eta'] = 0.02\n",
      "param['max_depth'] = 6\n",
      "param['eval_metric'] = 'map'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "param['min_child_weight'] = 1\n",
      "param['subsample'] = 0.8\n",
      "param['colsample_bytree'] = 1\n",
      "param['base_score'] = 0.5\n",
      "#param['num_feature'] = 10\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items()) + [('eval_metric', 'map'), ('eval_metric', 'auc')]\n",
      "\n",
      "xgboost = xgboost_classifier.ClassifierXGBoost(directory='xgboost/')\n",
      "xgboost.set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "xgboost.num_boost_round = 2500\n",
      "xgboost.watch = False\n",
      "\n",
      "#trainig classifier\n",
      "xgboost.fit(signal_train, bck_train)#,\\\n",
      "            #weight_sig=signal_train.get_data(['total_usage']).values,\\\n",
      "            #weight_bck=bck_train.get_data(['total_usage']).values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get prediction on data after classification\n",
      "from cern_utils.predictions_report import PredictionsInfo\n",
      "report = PredictionsInfo({'xgboost': xgboost}, signal_test, bck_test)\n",
      "report_train = PredictionsInfo({'xgboost': xgboost}, signal_train, bck_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = xgboost.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def log_loss(y_true, y_pred):\n",
      "    return log_loss(y_true, y_pred)\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred)  \n",
      "\n",
      "def average_precision(y_true, y_pred, sample_weight):\n",
      "    return average_precision_score(y_true, y_pred)  \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report.learning_curve( { 'roc_auc(test)':roc_auc}, steps=100)\n",
      "lc_train = report_train.learning_curve( { 'roc_auc(train)':roc_auc}, steps=100)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10, 6))\n",
      "av_test = report.learning_curve( {  'average_precision(test)':average_precision}, steps=100)\n",
      "av_train = report_train.learning_curve( {  'average_precision(train)':average_precision}, steps=100)\n",
      "av_test.plots[0].plot()\n",
      "av_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10, 6))\n",
      "ll_test = report.learning_curve( { 'log_loss(test)':roc_auc}, steps=100)\n",
      "ll_train = report_train.learning_curve( { 'log_loss(train)':roc_auc}, steps=100)\n",
      "ll_test.plots[0].plot()\n",
      "ll_train.plots[0].plot()\n",
      "legend( loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report.prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train.prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Correlation matrix\n",
      "#report.features_correlation_matrix().plot(show_legend=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Features histogramms\n",
      "#hist_var = variables[:]\n",
      "#hist_var.remove(u'NbTape')\n",
      "#hist_var.remove(u'TapeSize')\n",
      "#report.features_pdf(features=hist_var, bins = 10).plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report.roc().plot()\n",
      "report_train.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define metric functions\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.metrics import precision_score\n",
      "\n",
      "\n",
      "import numpy\n",
      "\n",
      "\n",
      "def accuracy(s, b, t_s, t_b, s_NORM=1., b_NORM = 1.): \n",
      "\n",
      "    return (s + t_b - b)/(t_s + t_b)\n",
      "\n",
      "def precision(s, b, t_s, t_b, s_NORM=1., b_NORM = 1.):\n",
      "    return 1- b/t_b\n",
      "\n",
      "report.metrics_vs_cut({'precision': precision, 'accuracy': accuracy}).plot(new_plot=True, figsize=(8, 4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10, 6))\n",
      "report.prediction_pdf(bins = 20, normed = True, plot_type='bar').plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Normed signal\n",
      "%pylab inline\n",
      "from cern_utils import calc_util\n",
      "iron = calc_util.classifier_flatten(report.prediction_sig['xgboost'])\n",
      "\n",
      "_ = hist(iron(report.prediction_sig['xgboost']),  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(iron(report.prediction_bck['xgboost']),  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot signal_test series for an interval of antipopularity values\n",
      "series = signal_test.get_data()[periods_txt]\n",
      "series = series[iron(report.prediction_sig['xgboost']) > 0.95]\n",
      "print \"Number of series is \", series.shape[0]\n",
      "for i in range(0, series.shape[0]):\n",
      "    cur_serie = series.irow(i)\n",
      "    plt.bar(periods, cur_serie.values, width=1, bottom=0, color='b', edgecolor='b', alpha=0.1)\n",
      "plt.xlim(1,78)\n",
      "plt.xlabel('Weeks')\n",
      "plt.ylabel('Nb of usages')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot signal_test series for an interval of antipopularity values\n",
      "series = signal_test.get_data()[periods_txt]\n",
      "series = series[iron(report.prediction_sig['xgboost']) > 0.85]\n",
      "print \"Number of series is \", series.shape[0]\n",
      "for i in range(0, series.shape[0]):\n",
      "    cur_serie = series.irow(i)\n",
      "    plt.bar(periods, cur_serie.values, width=1, bottom=0, color='b', edgecolor='b', alpha=0.1)\n",
      "plt.xlim(1,78)\n",
      "plt.xlabel('Weeks')\n",
      "plt.ylabel('Nb of usages')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot signal_test series for an interval of antipopularity values\n",
      "series = signal_test.get_data()[periods_txt]\n",
      "series = series[(iron(report.prediction_sig['xgboost']) > 0.4)&(iron(report.prediction_sig['xgboost']) < 0.8)]\n",
      "print \"Number of series is \", series.shape[0]\n",
      "for i in range(0, series.shape[0]):\n",
      "    cur_serie = series.irow(i)\n",
      "    plt.bar(periods, cur_serie.values, width=1, bottom=0, color='b', edgecolor='b', alpha=0.02)\n",
      "plt.xlim(1,78)\n",
      "plt.xlabel('Weeks')\n",
      "plt.ylabel('Nb of usages')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cern_utils import calc_util\n",
      "\n",
      "def CondSize(report, signal_test, bck_test, classifier='xgboost', cut=0.6, peaks=5, imax=26):\n",
      "\n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    \n",
      "    cond_sig = (iron(report.prediction_sig[classifier]) < cut)\\\n",
      "    &(signal_test.get_data(['nb_peaks']).values<=peaks)[:,0]\\\n",
      "    &(signal_test.get_data(['inter_max']).values>=imax)[:,0]\n",
      "    \n",
      "    cond_bck = (iron(report.prediction_bck[classifier]) < cut)\\\n",
      "    &(bck_test.get_data(['nb_peaks']).values<=peaks)[:,0]\\\n",
      "    &(bck_test.get_data(['inter_max']).values>=imax)[:,0]\n",
      "\n",
      "    nzrs = (signal_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    nzrb = (bck_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "\n",
      "    sz_signal=signal_test.get_data(['DiskSize'])[(cond_sig)&nzrs].values.sum()\\\n",
      "    +bck_test.get_data(['DiskSize'])[(cond_bck)&nzrb].values.sum()\\\n",
      "    -signal_test.get_data(['LFNSize'])[(cond_sig)&nzrs].values.sum()\\\n",
      "    -bck_test.get_data(['LFNSize'])[(cond_bck)&nzrb].values.sum()\n",
      "\n",
      "    return sz_signal\n",
      "\n",
      "def RFiles(report, signal_test, bck_test, classifier='xgboost', mincut=0.01, maxcut=1, N=100, pq=95):\n",
      "    print \"Total number of the 'signal' files is \", signal_test.get_indices().shape[0]\n",
      "    print \"Total number of files is \", signal_test.get_indices().shape[0]+bck_test.get_indices().shape[0]\n",
      "    \n",
      "    step = (maxcut - mincut)/N\n",
      "    cuts = [mincut + step*i for i in range(0, N+1)]\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    x=cuts\n",
      "    \n",
      "    nb_signals = []\n",
      "    nb_true_signals = []\n",
      "    nb_rels = []\n",
      "    cut_pq = 1\n",
      "    \n",
      "    for i in cuts:\n",
      "        nb_signal=((iron(report.prediction[classifier]) >= i)*1).sum()\n",
      "        nb_true_signal=((iron(report.prediction_sig[classifier]) >= i)*1).sum()\n",
      "        \n",
      "        if nb_signal!=0:\n",
      "            nb_rel=float(nb_true_signal)/float(nb_signal)*100\n",
      "        else:\n",
      "            nb_rel=100\n",
      "        \n",
      "        if cut_pq==1 and nb_rel>=pq:\n",
      "            cut_pq=i\n",
      "        \n",
      "        nb_signals.append(nb_signal)\n",
      "        nb_true_signals.append(nb_true_signal)\n",
      "        nb_rels.append(nb_rel)\n",
      "\n",
      "    \n",
      "    plt.figure(figsize=(5, 3))\n",
      "    plt.subplot(1,1,1)\n",
      "    plt.plot(x, nb_signals, 'b', label = 'nb signal files')\n",
      "    plt.plot(x, nb_true_signals, 'r', label = 'nb true signal files')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.show()\n",
      "    \n",
      "    plt.figure(figsize=(5, 3))\n",
      "    plt.subplot(1,1,1)\n",
      "    plt.plot(x, nb_rels, 'r', label = 'ratio of the true signals to the signals(%)')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.show()\n",
      "    \n",
      "    return cut_pq\n",
      "    \n",
      "def RSize(report, signal_test, bck_test, classifier='xgboost', mincut=0.01, maxcut=1, N=100, cond=0.9, Flag=False, pq=95):\n",
      "    print \"Total memory can be released is \", signal_test.get_data(['DiskSize']).values.sum()\n",
      "    print \"Total memory is \", signal_test.get_data(['DiskSize']).values.sum()+bck_test.get_data(['DiskSize']).values.sum()\n",
      "    \n",
      "    step = (maxcut - mincut)/N\n",
      "    cuts = [mincut + step*i for i in range(0, N+1)]\n",
      "    \n",
      "    iron = calc_util.classifier_flatten(report.prediction_sig[classifier])\n",
      "    x=cuts\n",
      "    \n",
      "    sz_signals = []\n",
      "    sz_true_signals = []\n",
      "    sz_rels = []\n",
      "    cut_pq = 1\n",
      "    \n",
      "    nzrs = (signal_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    nzrb = (bck_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "    \n",
      "    for i in cuts:\n",
      "        if i>=cond:\n",
      "            sz_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)].values.sum()\\\n",
      "            +bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= i)].values.sum()\n",
      "            \n",
      "            sz_true_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)].values.sum()\n",
      "            \n",
      "            if sz_signal!=0:\n",
      "                sz_rel=float(sz_true_signal)/float(sz_signal)*100.\n",
      "            else:\n",
      "                sz_rel=100\n",
      "                \n",
      "            if cut_pq==1 and sz_rel>=pq:\n",
      "                cut_pq=i\n",
      "        else:\n",
      "            sz_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\\\n",
      "            +bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck[classifier]) >= i)&nzrb].values.sum()\\\n",
      "            -signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\\\n",
      "            -bck_test.get_data(['LFNSize'])[(iron(report.prediction_bck[classifier]) >= i)&nzrb].values.sum()\n",
      "            \n",
      "            sz_true_signal=signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\\\n",
      "            -signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig[classifier]) >= i)&nzrs].values.sum()\n",
      "            \n",
      "            if sz_signal!=0:\n",
      "                sz_rel=float(sz_true_signal)/float(sz_signal)*100.\n",
      "            else:\n",
      "                sz_rel=100\n",
      "\n",
      "            if cut_pq==1 and sz_rel>=pq:\n",
      "                cut_pq=i\n",
      "\n",
      "        sz_signals.append(sz_signal)\n",
      "        sz_true_signals.append(sz_true_signal)\n",
      "        sz_rels.append(sz_rel)\n",
      "\n",
      "    \n",
      "    if Flag==True:\n",
      "        plt.figure(figsize=(5, 3))\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(x, sz_signals, 'b', label = 'signal files size')\n",
      "        plt.plot(x, sz_true_signals, 'r', label = 'true signal files size')\n",
      "        plt.legend(loc = 'best')\n",
      "        plt.show()\n",
      "    \n",
      "        plt.figure(figsize=(5, 3))\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(x, sz_rels, 'r')\n",
      "        plt.title('Ratio(%)')\n",
      "        plt.legend(loc = 'best')\n",
      "        plt.show()\n",
      "    else:\n",
      "        plt.figure(figsize=(5, 3))\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(x, sz_signals, 'b', label = 'released memory')\n",
      "        plt.legend(loc = 'best')\n",
      "        plt.show()\n",
      "        \n",
      "    return cut_pq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CondSize(report, signal_test, bck_test, classifier='xgboost', cut=0.6, peaks=5, imax=26)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cut_pq1 = RSize(report, signal_test, bck_test, classifier='xgboost', mincut=0.1, maxcut=1, N=1000, cond=0, Flag=True)\n",
      "print \"cut_pq is \", cut_pq1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "RSize(report, signal_test, bck_test, classifier='xgboost', mincut=0.01, maxcut=1, N=1000, cond=1.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cut_pq11 = RFiles(report, signal_test, bck_test, classifier='xgboost', mincut=0.001, maxcut=1, N=1000)\n",
      "print \"cut_pq11 is \", cut_pq11"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xgboost2 = xgboost_classifier.ClassifierXGBoost(directory='xgboost2/')\n",
      "xgboost2.set_params(features = variables, params = plst)\n",
      "#setup additional parameters\n",
      "xgboost2.num_boost_round = 1500\n",
      "xgboost2.watch = False\n",
      "\n",
      "#trainig classifier\n",
      "xgboost2.fit(signal_test, bck_test)#,\\\n",
      "            #weight_sig=signal_train.get_data(['total_usage']).values,\\\n",
      "            #weight_bck=bck_train.get_data(['total_usage']).values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get prediction on data after classification\n",
      "from cern_utils.predictions_report import PredictionsInfo\n",
      "report2 = PredictionsInfo({'xgboost2': xgboost2}, signal_train, bck_train)\n",
      "report_train2 = PredictionsInfo({'xgboost2': xgboost2}, signal_test, bck_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance2 = xgboost2.get_feature_importance()\n",
      "importance2.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def log_loss(y_true, y_pred):\n",
      "    return log_loss(y_true, y_pred)\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred)  \n",
      "\n",
      "def average_precision(y_true, y_pred, sample_weight):\n",
      "    return average_precision_score(y_true, y_pred)  \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test2 = report2.learning_curve( { 'roc_auc(test)':roc_auc}, steps=100)\n",
      "lc_train2 = report_train2.learning_curve( { 'roc_auc(train)':roc_auc}, steps=100)\n",
      "lc_test2.plots[0].plot()\n",
      "lc_train2.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10, 6))\n",
      "av_test2 = report2.learning_curve( {  'average_precision(test)':average_precision}, steps=100)\n",
      "av_train2 = report_train2.learning_curve( {  'average_precision(train)':average_precision}, steps=100)\n",
      "av_test2.plots[0].plot()\n",
      "av_train2.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10, 6))\n",
      "ll_test2 = report2.learning_curve( { 'log_loss(test)':roc_auc}, steps=100)\n",
      "ll_train2 = report_train2.learning_curve( { 'log_loss(train)':roc_auc}, steps=100)\n",
      "ll_test2.plots[0].plot()\n",
      "ll_train2.plots[0].plot()\n",
      "legend( loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get prediction on data after classification\n",
      "figure(figsize=(10, 6))\n",
      "report2.prediction_pdf(bins = 20, normed = True, plot_type='bar', class_type='both').plot()\n",
      "report_train2.prediction_pdf(bins = 20, normed = True, class_type='both').plot()\n",
      "xlim(0, 1)\n",
      "legend(['bck(test)', 'sig(test)', 'bck(train)', 'sig(train)'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report2.roc().plot()\n",
      "report_train2.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define metric functions\n",
      "report2.metrics_vs_cut({'precision': precision, 'accuracy': accuracy}).plot(new_plot=True, figsize=(8, 4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10, 6))\n",
      "report2.prediction_pdf(bins = 10, normed = False, plot_type='bar').plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Normed signal\n",
      "%pylab inline\n",
      "from cern_utils import calc_util\n",
      "iron2 = calc_util.classifier_flatten(report2.prediction_sig['xgboost2'])\n",
      "\n",
      "_ = hist(iron2(report2.prediction_sig['xgboost2']),  histtype='bar', bins=10, alpha=0.5, label='signal', color='b')\n",
      "_ = hist(iron2(report2.prediction_bck['xgboost2']),  histtype='bar', bins=10, alpha=0.5, label='bck', color='r')\n",
      "legend(loc='best', fontsize='xx-large')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Normed signal\n",
      "%pylab inline\n",
      "from cern_utils import calc_util\n",
      "iron2 = calc_util.classifier_flatten(report2.prediction_sig['xgboost2'])\n",
      "\n",
      "_ = hist(report2.prediction_sig['xgboost2'],  histtype='bar', bins=10, alpha=0.5, label='signal', color='b')\n",
      "_ = hist(report2.prediction_bck['xgboost2'],  histtype='bar', bins=10, alpha=0.5, label='bck', color='r')\n",
      "legend(loc='best',fontsize='xx-large')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cut_pq2 = RSize(report2, signal_train, bck_train, classifier='xgboost2', mincut=0.01, maxcut=1, N=1000, cond=0, Flag=True)\n",
      "print \"cut_pq is \", cut_pq2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CondSize(report2, signal_train, bck_train, classifier='xgboost2', cut=0.6, peaks=5, imax=26)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "RSize(report2, signal_train, bck_train, classifier='xgboost2', mincut=0.01, maxcut=1, N=1000, cond=1.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cut_pq22 = RFiles(report2, signal_train, bck_train, classifier='xgboost2', mincut=0.001, maxcut=1, N=1000)\n",
      "print \"cut_pq is \", cut_pq22"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Selection\n",
      "sel = ((data['Now'] - data['Creation-week']) > 26)&((data['Now'] - data['FirstUsage']) > 26)&((data[78] - data[1]) == 0)\n",
      "check = ((data[sel][104] - data[sel][52]) == 0).values*1\n",
      "memory1 = data[sel].get('DiskSize').values.sum()\n",
      "memory_check = (data[sel].get('DiskSize').values*check).sum()\n",
      "print check.sum()-check.shape[0]\n",
      "print memory1\n",
      "print memory_check"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Classification. Brave\n",
      "iron2 = calc_util.classifier_flatten(report2.prediction_sig['xgboost2'])\n",
      "\n",
      "memory21 = signal_train.get_data(['DiskSize'])[iron2(report2.prediction_sig['xgboost2']) >= cut_pq2].values.sum()\\\n",
      "+bck_train.get_data(['DiskSize'])[iron2(report2.prediction_bck['xgboost2']) >= cut_pq2].values.sum()\\\n",
      "+signal_test.get_data(['DiskSize'])[iron(report.prediction_sig['xgboost']) >= cut_pq1].values.sum()\\\n",
      "+bck_test.get_data(['DiskSize'])[iron(report.prediction_bck['xgboost']) >= cut_pq1].values.sum()\n",
      "\n",
      "print memory21"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Classification. Safe\n",
      "\n",
      "nzrs = (signal_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "nzrb = (bck_test.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "nzrs2 = (signal_train.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "nzrb2 = (bck_train.get_data(['Nb Replicas']).values >= 1)[:,0]\n",
      "s_cut = 0.2\n",
      "\n",
      "memory22 = signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig['xgboost']) >= s_cut)&nzrs].values.sum()\\\n",
      "+bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck['xgboost']) >= s_cut)&nzrb].values.sum()\\\n",
      "-signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig['xgboost']) >= s_cut)&nzrs].values.sum()\\\n",
      "-bck_test.get_data(['LFNSize'])[(iron(report.prediction_bck['xgboost']) >= s_cut)&nzrb].values.sum()\\\n",
      "+signal_train.get_data(['DiskSize'])[(iron2(report2.prediction_sig['xgboost2']) >= s_cut)&nzrs2].values.sum()\\\n",
      "+bck_train.get_data(['DiskSize'])[(iron2(report2.prediction_bck['xgboost2']) >= s_cut)&nzrb2].values.sum()\\\n",
      "-signal_train.get_data(['LFNSize'])[(iron2(report2.prediction_sig['xgboost2']) >= s_cut)&nzrs2].values.sum()\\\n",
      "-bck_train.get_data(['LFNSize'])[(iron2(report2.prediction_bck['xgboost2']) >= s_cut)&nzrb2].values.sum()\n",
      "\n",
      "print memory22"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Classification. Combination\n",
      "\n",
      "memory231 = signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig['xgboost']) >= s_cut)&nzrs].values.sum()\\\n",
      "+bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck['xgboost']) >= s_cut)&nzrb].values.sum()\\\n",
      "-signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig['xgboost']) >= s_cut)&nzrs].values.sum()\\\n",
      "-bck_test.get_data(['LFNSize'])[(iron(report.prediction_bck['xgboost']) >= s_cut)&nzrb].values.sum()\\\n",
      "+signal_train.get_data(['DiskSize'])[(iron2(report2.prediction_sig['xgboost2']) >= s_cut)&nzrs2].values.sum()\\\n",
      "+bck_train.get_data(['DiskSize'])[(iron2(report2.prediction_bck['xgboost2']) >= s_cut)&nzrb2].values.sum()\\\n",
      "-signal_train.get_data(['LFNSize'])[(iron2(report2.prediction_sig['xgboost2']) >= s_cut)&nzrs2].values.sum()\\\n",
      "-bck_train.get_data(['LFNSize'])[(iron2(report2.prediction_bck['xgboost2']) >= s_cut)&nzrb2].values.sum()\n",
      "\n",
      "memory232 = signal_test.get_data(['DiskSize'])[(iron(report.prediction_sig['xgboost']) >= cut_pq1)&nzrs].values.sum()\\\n",
      "+bck_test.get_data(['DiskSize'])[(iron(report.prediction_bck['xgboost']) >= cut_pq1)&nzrb].values.sum()\\\n",
      "-signal_test.get_data(['LFNSize'])[(iron(report.prediction_sig['xgboost']) >= cut_pq1)&nzrs].values.sum()\\\n",
      "-bck_test.get_data(['LFNSize'])[(iron(report.prediction_bck['xgboost']) >= cut_pq1)&nzrb].values.sum()\\\n",
      "+signal_train.get_data(['DiskSize'])[(iron2(report2.prediction_sig['xgboost2']) >= cut_pq2)&nzrs2].values.sum()\\\n",
      "+bck_train.get_data(['DiskSize'])[(iron2(report2.prediction_bck['xgboost2']) >= cut_pq2)&nzrb2].values.sum()\\\n",
      "-signal_train.get_data(['LFNSize'])[(iron2(report2.prediction_sig['xgboost2']) >= cut_pq2)&nzrs2].values.sum()\\\n",
      "-bck_train.get_data(['LFNSize'])[(iron2(report2.prediction_bck['xgboost2']) >= cut_pq2)&nzrb2].values.sum()\n",
      "\n",
      "memory233 = signal_test.get_data(['DiskSize'])[iron(report.prediction_sig['xgboost']) >= cut_pq1].values.sum()\\\n",
      "+bck_test.get_data(['DiskSize'])[iron(report.prediction_bck['xgboost']) >= cut_pq1].values.sum()\\\n",
      "+signal_train.get_data(['DiskSize'])[iron2(report2.prediction_sig['xgboost2']) >= cut_pq2].values.sum()\\\n",
      "+bck_train.get_data(['DiskSize'])[iron2(report2.prediction_bck['xgboost2']) >= cut_pq2].values.sum()\n",
      "\n",
      "memory23 = memory231-memory232+memory233\n",
      "print memory23"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Rare usage\n",
      "memory3 = CondSize(report2, signal_train, bck_train, classifier='xgboost2', cut=s_cut, peaks=3, imax=26)\\\n",
      "+CondSize(report, signal_test, bck_test, classifier='xgboost', cut=s_cut, peaks=3, imax=26)\n",
      "print memory3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Total released memory\n",
      "memory = memory1+memory22+memory3\n",
      "total = signal_train.get_data(['DiskSize']).values.sum()+bck_train.get_data(['DiskSize']).values.sum()+memory1\\\n",
      "+signal_test.get_data(['DiskSize']).values.sum()+bck_test.get_data(['DiskSize']).values.sum()\n",
      "can_released = signal_train.get_data(['DiskSize']).values.sum()+signal_test.get_data(['DiskSize']).values.sum()+memory1\n",
      "\n",
      "print \"memory is \", memory\n",
      "print \"total memory is \", total\n",
      "print \"memory can be released is \", can_released\n",
      "print \"Ratio is \", float(memory)/float(total)*100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Total released memory\n",
      "memory = memory1+memory21+memory3\n",
      "\n",
      "print \"memory is \", memory\n",
      "print \"total memory is \", total\n",
      "print \"memory can be released is \", can_released\n",
      "print \"Ratio is \", float(memory)/float(total)*100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Total released memory\n",
      "memory = memory1+memory23+memory3\n",
      "\n",
      "print \"memory is \", memory\n",
      "print \"total memory is \", total\n",
      "print \"memory can be released is \", can_released\n",
      "print \"Ratio is \", float(memory)/float(total)*100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "session = ipykee.Session(project_name=\"C._NewFeatures\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#session.commit(\"Classifier was trained. Bins of Nb os usages were added. Not optimized.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    }
   ],
   "metadata": {}
  }
 ]
}