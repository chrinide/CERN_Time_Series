{
 "metadata": {
  "name": "/ipykee/workdir/tmpiO2eNt/D"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython import parallel\n",
      "clients = parallel.Client(profile='ssh-ipy2.0')\n",
      "clients.block = True  # use synchronous computations\n",
      "print clients.ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from IPython import parallel\n",
      "# clients = parallel.Client(profile='ssh-ipy2.0')\n",
      "# clients.block = True  # use synchronous computations\n",
      "# print clients.ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#Load original data\n",
      "data = pd.read_csv('popularity-728days_my.csv')\n",
      "\n",
      "head = list(data.columns[:21]) + range(1,105)\n",
      "data = pd.DataFrame(columns=head, data=data.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "#Select data\n",
      "selection = ((data['Now'] - data['Creation-week']) > 26)&((data['Now'] - data['FirstUsage']) > 26)&((data[78] - data[1]) != 0)\n",
      "data_sel = data[selection].copy()\n",
      "#data_sel = data.copy()\n",
      "print data_sel.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#Load original data\n",
      "data = pd.read_csv('popularity-728days_my.csv')\n",
      "\n",
      "head = list(data.columns[:21]) + range(1,105)\n",
      "data = pd.DataFrame(columns=head, data=data.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "#Select data\n",
      "selection = ((data['Now'] - data['Creation-week']) > 26)&((data['Now'] - data['FirstUsage']) > 26)&((data[78] - data[1]) != 0)\n",
      "data_sel = data[selection].copy()\n",
      "#data_sel = data.copy()\n",
      "print data_sel.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "periods = range(1,105)\n",
      "\n",
      "#------------------------------------------------------\n",
      "#Get maximum intervals and last weeks with zeros usages\n",
      "def InterMax(data_sel, periods):\n",
      "    #Get binary vector representation of the selected data\n",
      "    data_bv = data_sel.copy()\n",
      "    #Get week's usages\n",
      "    for i in periods:\n",
      "        if i!=1:\n",
      "            data_bv[i] = data_sel[i] - data_sel[i-1]\n",
      "            \n",
      "    #Get binary representation\n",
      "    data_bv[periods] = (data_bv[periods] != 0)*1\n",
      "    \n",
      "    inter_max = []\n",
      "    last_zeros = []\n",
      "    nb_peaks = []\n",
      "    inter_mean = []\n",
      "    inter_std = []\n",
      "    inter_rel = []\n",
      "    \n",
      "    for i in range(0,data_bv.shape[0]):\n",
      "        ds = data_bv[periods].irow(i)\n",
      "        nz = ds.nonzero()[0]\n",
      "        inter = []\n",
      "        \n",
      "        nb_peaks.append(len(nz))\n",
      "        if len(nz)==0:\n",
      "            nz = [0]\n",
      "        if len(nz)<2:\n",
      "            inter = [0]\n",
      "            #nz = [0]\n",
      "        else:\n",
      "            for k in range(0, len(nz)-1):\n",
      "                val = nz[k+1]-nz[k]\n",
      "                inter.append(val)\n",
      "        \n",
      "        inter = np.array(inter)\n",
      "        inter_mean.append(inter.mean())\n",
      "        inter_std.append(inter.std())\n",
      "        if inter.mean()!=0:\n",
      "            inter_rel.append(inter.std()/inter.mean())\n",
      "        else:\n",
      "            inter_rel.append(0)\n",
      "                \n",
      "        last_zeros.append(periods[-1] - nz[-1] + 1)\n",
      "        inter_max.append(max(inter))\n",
      "    \n",
      "    return np.array(inter_max), np.array(last_zeros), np.array(nb_peaks), np.array(inter_mean), np.array(inter_std), np.array(inter_rel)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "#Add features\n",
      "inter_max, last_zeros, nb_peaks, inter_mean, inter_std, inter_rel = InterMax(data_sel, periods)\n",
      "data_sel['last-zeros'] = last_zeros\n",
      "data_sel['inter_max'] = inter_max\n",
      "data_sel['nb_peaks'] = nb_peaks\n",
      "data_sel['inter_mean'] = inter_mean\n",
      "data_sel['inter_std'] = inter_std\n",
      "data_sel['inter_rel'] = inter_rel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "data = data_sel[data_sel['nb_peaks']>=0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "data_weeks = data[range(1,105)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "df_time_series = data_weeks.copy()\n",
      "for i in range(1,105):\n",
      "    if i!=1:\n",
      "        df_time_series[i] = data_weeks[i]-data_weeks[i-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "param1 = 13\n",
      "df_ts_rolling_sum = pd.rolling_sum(df_time_series, window=param1,axis=1)[range(param1,105)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "ws = 13#window_size\n",
      "fh = 13#forecast horizont\n",
      "param2 = 105-param1\n",
      "\n",
      "def N_M_Transformation(time_serie, ws, fh):\n",
      "    x_cols = ['x'+str(i) for i in range(1,ws+1)]#columns names\n",
      "    time_serie_table = pd.DataFrame(columns=x_cols+['y'])\n",
      "    time_serie_4predict = pd.DataFrame(columns=x_cols)\n",
      "    #Data for train and test\n",
      "    for row_num in range(0, param2-fh-ws):\n",
      "        time_serie_table.loc[row_num] = list(time_serie.icol(range(row_num+1, row_num+ws+1)).values[0])\\\n",
      "        +list(time_serie.icol([row_num+ws+fh]).values[0])#y variable \n",
      "    #Data for prediction\n",
      "    for row_num in range(param2-fh-ws,param2-ws):\n",
      "        time_serie_4predict.loc[row_num-(param2-fh-ws)] = list(time_serie.icol(range(row_num+1, row_num+ws+1)).values[0]) \n",
      "        #print row_num\n",
      "\n",
      "    return time_serie_table, time_serie_4predict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "param3 = param2-fh-ws\n",
      "print param3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# %%px\n",
      "# results = pd.DataFrame(columns=[\"Index\",\"Error_train\",\"Error_valid\", \"Error_test\"]+range(0,param3))\n",
      "# results.to_csv('/mnt/w76/notebook/datasets/mikhail/ann_res.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ANN(rows_range):\n",
      "    \n",
      "    import neurolab as nl\n",
      "    keys = [str(i) for i in range(1,param3+1)]\n",
      "    results = pd.DataFrame(columns=[\"Index\",\"Error_train\",\"Error_valid\", \"Error_test\"]+keys)\n",
      "\n",
      "    param4 = fh+10\n",
      "    f = nl.trans.TanSig()\n",
      "\n",
      "    for row in rows_range:\n",
      "        print row\n",
      "        #Take a row and transfrom it\n",
      "        ts_train = df_ts_rolling_sum.irow([row])\n",
      "        time_serie_table, time_serie_4predict = N_M_Transformation(ts_train, ws, fh)\n",
      "        #Transform the row's values to the [0,1] values\n",
      "        time_serie_table = time_serie_table/(1.0*time_serie_table.max())\n",
      "        time_serie_4predict = time_serie_4predict/(1.0*time_serie_4predict.max())\n",
      "        x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "        #Get train data\n",
      "        x_train = time_serie_table[x_cols].irow(range(0,param3-param4)).values\n",
      "        y_train = time_serie_table['y'].irow(range(0,param3-param4)).values\n",
      "        size = len(y_train)\n",
      "        y_train = y_train.reshape(len(y_train),1)\n",
      "        #Get validation data\n",
      "        x_valid = time_serie_table[x_cols].irow(range(param3-param4,param3-fh)).values\n",
      "        y_valid = time_serie_table['y'].irow(range(param3-param4,param3-fh)).values\n",
      "        y_valid = y_valid.reshape(len(y_valid),1)\n",
      "        #Get test data\n",
      "        x_test = time_serie_table[x_cols].irow(range(param3-fh,param3)).values\n",
      "        y_test = time_serie_table['y'].irow(range(param3-fh,param3)).values\n",
      "        y_test = y_test.reshape(len(y_test),1)\n",
      "        # Create network with 2 layers and random initialized\n",
      "        init = []\n",
      "        for i in range(0, x_train.shape[1]):\n",
      "            init.append([0,1])\n",
      "        min_error = 10\n",
      "        for k in range(0,10):\n",
      "            cur_net = nl.net.newff(init,[5,1],transf=[f, f])\n",
      "            for l in cur_net.layers:\n",
      "                l.initf = nl.init.init_rand(l, min=-0.5, max=0.5, init_prop='w')\n",
      "            # new initialization\n",
      "            cur_net.init()\n",
      "            if k==0:\n",
      "                net=cur_net\n",
      "                error = 10\n",
      "\n",
      "            # Train network\n",
      "            cur_net.trainf = nl.train.train_bfgs\n",
      "            cur_error = cur_net.train(x_train, f(y_train), epochs=300, show=0, goal=0.00000000001)\n",
      "\n",
      "            out_train = cur_net.sim(x_train)\n",
      "            out_valid = cur_net.sim(x_valid)\n",
      "\n",
      "            tar_out_valid = np.concatenate((y_valid, out_valid), axis=1)\n",
      "            tar_out_train = np.concatenate((y_train, out_train), axis=1)\n",
      "            tar_out = np.concatenate((tar_out_train, tar_out_valid), axis=0)\n",
      "            max_abs = np.abs(tar_out[:,0]-tar_out[:,1])\n",
      "            maef = nl.error.MAE()\n",
      "            saef = nl.error.SAE()\n",
      "            msef = nl.error.MSE()\n",
      "            #check_error = maef(tar_out_valid)\n",
      "            #check_error = msef(tar_out)\n",
      "            #check_error = saef(tar_out)\n",
      "            #check_error = cur_error[-1]\n",
      "            check_error = max_abs.max()\n",
      "\n",
      "            print check_error\n",
      "            if check_error<min_error:\n",
      "                min_error = check_error\n",
      "                net = cur_net\n",
      "                error = cur_error\n",
      "\n",
      "\n",
      "        # Simulate network\n",
      "        print 'min_error', min_error\n",
      "        out_train = net.sim(x_train)\n",
      "\n",
      "        # Plot result\n",
      "#         plt.subplot(1,1,1)\n",
      "#         plt.plot(error)\n",
      "#         plt.xlabel('Epoch number')\n",
      "#         plt.ylabel('error (default SSE)')\n",
      "#         plt.show()\n",
      "\n",
      "        out_valid = net.sim(x_valid)\n",
      "        out_test = net.sim(x_test)\n",
      "#         plt.subplot(1,1,1)\n",
      "#         plt.plot(f(np.concatenate((y_train,y_valid, y_test),axis=0)))\n",
      "#         plt.plot(np.concatenate((out_train,out_valid,out_test),axis=0))\n",
      "#         plt.show()\n",
      "\n",
      "\n",
      "        #Get results\n",
      "        index = ts_train.index[0]\n",
      "        error_train = maef(tar_out_train)\n",
      "        error_valid = maef(tar_out_valid)\n",
      "        tar_out_test = np.concatenate((y_test, out_test), axis=1)\n",
      "        error_test = maef(tar_out_test)\n",
      "        values = list(np.concatenate((out_train,out_valid,out_test)))\n",
      "        values = np.reshape(values,(len(values),))\n",
      "        data_dict = {\"Index\":[index],\"Error_train\":[error_train],\"Error_valid\":[error_valid], \"Error_test\":[error_test]}\n",
      "        for i in range(1,param3+1):\n",
      "            data_dict[str(i)] = [values[i-1]]\n",
      "        new_row = pd.DataFrame(data=data_dict)\n",
      "        results = results.append(new_row)\n",
      "        \n",
      "    #results.to_csv('/mnt/w76/notebook/datasets/mikhail/ann_res.csv',mode='a',header=False)\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('ann_res.csv')\n",
      "results.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=1)*(results['Error_train']<=1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_ts_rolling_sum.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_values = df_ts_rolling_sum.max(axis=1)\n",
      "df_ts_rolling_sum_std = df_ts_rolling_sum.copy()\n",
      "for col in df_ts_rolling_sum.columns:\n",
      "    df_ts_rolling_sum_std[col] = df_ts_rolling_sum[col]/max_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print N//3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]\n",
      "cols = range(105-66,105)\n",
      "a=0\n",
      "b=60\n",
      "N=b-a\n",
      "figure(figsize=(15, 5*(N//3+1)))\n",
      "for row in range(a,b):\n",
      "    subplot(N//3+1,3,row)\n",
      "    plt.plot(non_nan_res[val_cols].irow([row]).values[0], color='r', label='predict')\n",
      "    index = int(non_nan_res.irow([row])['Index'].values)\n",
      "    plt.plot(df_ts_rolling_sum_std[cols].xs(index), color='b', label='real')\n",
      "    plt.plot([param3-fh,param3-fh], [-1,1], color='black')\n",
      "    plt.plot([param3-fh-10,param3-fh-10], [-1,1], color='black')\n",
      "    plt.title('Index is '+str(index))\n",
      "    plt.legend(loc='best')\n",
      "    #plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print error hists\n",
      "figure(figsize=(15, 5))\n",
      "subplot(121)\n",
      "plt.hist(non_nan_res['Error_test'].values, color='r', bins=20, label='test', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_train'].values, color='b', bins=20, label='train', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_valid'].values, color='g', bins=20, label='valid', alpha=1, histtype='step')\n",
      "plt.title('Errors')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for the last point\n",
      "subplot(122)\n",
      "plt.hist(non_nan_res['66'].values, bins=50, label='last point')\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_last=[]\n",
      "for i in non_nan_res['Index']:\n",
      "    i=int(i)\n",
      "    cur_serie = df_ts_rolling_sum.xs(i).values\n",
      "    y_last.append(cur_serie[104-fh]/(1.0*cur_serie.max()))\n",
      "y_last = np.array(y_last)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "#print predict value for the last point\n",
      "subplot(2,2,1)\n",
      "values = non_nan_res['66'].values\n",
      "plt.hist(values[y_last==0], bins=50, label='y_last=0', alpha=1)\n",
      "plt.hist(values[y_last!=0], bins=50, label='y_last!=0', alpha=1)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,2)\n",
      "values = non_nan_res['Error_test'].values\n",
      "plt.hist(values[y_last==0], bins=50, label='y_last=0', alpha=1)\n",
      "plt.hist(values[y_last!=0], bins=50, label='y_last!=0', alpha=1)\n",
      "plt.title('Error_test')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,3)\n",
      "values = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "plt.hist(values[y_last==0], bins=50, label='y_last=0', alpha=1)\n",
      "plt.hist(values[y_last!=0], bins=50, label='y_last!=0', alpha=1)\n",
      "plt.title('Relative test error')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,4)\n",
      "values = non_nan_res['Error_valid'].values\n",
      "plt.hist(values[y_last==0], bins=50, label='y_last=0', alpha=1)\n",
      "plt.hist(values[y_last!=0], bins=50, label='y_last!=0', alpha=1)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "#y_score = (1.0 + non_nan_res['66'].values)/2.0\n",
      "y_score = values = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr, tpr)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get variables\n",
      "# import ipykee\n",
      "# keeper = ipykee.Keeper(\"C._NewFeatures\")\n",
      "# session = keeper[\"C2.1.1._RelativeNewFeatures_78weeks\"]\n",
      "# vars_c21 = session.get_variables(\"master\")\n",
      "#variables.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "#ipykee.create_project(project_name=\"D._UsageForecast\", repository=\"git@github.com:hushchyn-mikhail/CERN_Time_Series.git\")\n",
      "session = ipykee.Session(project_name=\"D._UsageForecast\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ANN(rows_range):\n",
      "    \n",
      "    import neurolab as nl\n",
      "    keys = [str(i) for i in range(1,param3+1)]\n",
      "    results = pd.DataFrame(columns=[\"Index\",\"Error_train\",\"Error_valid\", \"Error_test\"]+keys)\n",
      "\n",
      "    param4 = fh+10\n",
      "    f = nl.trans.TanSig()\n",
      "\n",
      "    for row in rows_range:\n",
      "        print row\n",
      "        #Take a row and transfrom it\n",
      "        ts_train = df_ts_rolling_sum.irow([row])\n",
      "        time_serie_table, time_serie_4predict = N_M_Transformation(ts_train, ws, fh)\n",
      "        #Transform the row's values to the [0,1] values\n",
      "        time_serie_table = time_serie_table/(1.0*time_serie_table.max())\n",
      "        time_serie_4predict = time_serie_4predict/(1.0*time_serie_4predict.max())\n",
      "        x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "        #Get train data\n",
      "        x_train = time_serie_table[x_cols].irow(range(0,param3-param4)).values\n",
      "        y_train = time_serie_table['y'].irow(range(0,param3-param4)).values\n",
      "        size = len(y_train)\n",
      "        y_train = y_train.reshape(len(y_train),1)\n",
      "        #Get validation data\n",
      "        x_valid = time_serie_table[x_cols].irow(range(param3-param4,param3-fh)).values\n",
      "        y_valid = time_serie_table['y'].irow(range(param3-param4,param3-fh)).values\n",
      "        y_valid = y_valid.reshape(len(y_valid),1)\n",
      "        #Get test data\n",
      "        x_test = time_serie_table[x_cols].irow(range(param3-fh,param3)).values\n",
      "        y_test = time_serie_table['y'].irow(range(param3-fh,param3)).values\n",
      "        y_test = y_test.reshape(len(y_test),1)\n",
      "        # Create network with 2 layers and random initialized\n",
      "        init = []\n",
      "        for i in range(0, x_train.shape[1]):\n",
      "            init.append([0,1])\n",
      "        min_error = 10\n",
      "        for k in range(0,10):\n",
      "            cur_net = nl.net.newff(init,[5,1],transf=[f, f])\n",
      "            for l in cur_net.layers:\n",
      "                l.initf = nl.init.init_rand(l, min=-0.5, max=0.5, init_prop='w')\n",
      "            # new initialization\n",
      "            cur_net.init()\n",
      "            if k==0:\n",
      "                net=cur_net\n",
      "                error = 10\n",
      "\n",
      "            # Train network\n",
      "            cur_net.trainf = nl.train.train_bfgs\n",
      "            cur_error = cur_net.train(x_train, y_train, epochs=300, show=0, goal=0.00000000001)\n",
      "\n",
      "            out_train = cur_net.sim(x_train)\n",
      "            out_valid = cur_net.sim(x_valid)\n",
      "\n",
      "            tar_out_valid = np.concatenate((y_valid, out_valid), axis=1)\n",
      "            tar_out_train = np.concatenate((y_train, out_train), axis=1)\n",
      "            tar_out = np.concatenate((tar_out_train, tar_out_valid), axis=0)\n",
      "            max_abs = np.abs(tar_out[:,0]-tar_out[:,1])\n",
      "            maef = nl.error.MAE()\n",
      "            saef = nl.error.SAE()\n",
      "            msef = nl.error.MSE()\n",
      "            #check_error = maef(tar_out_valid)\n",
      "            #check_error = msef(tar_out)\n",
      "            #check_error = saef(tar_out)\n",
      "            #check_error = cur_error[-1]\n",
      "            check_error = max_abs.max()\n",
      "\n",
      "            print check_error\n",
      "            if check_error<min_error:\n",
      "                min_error = check_error\n",
      "                net = cur_net\n",
      "                error = cur_error\n",
      "\n",
      "\n",
      "        # Simulate network\n",
      "        print 'min_error', min_error\n",
      "        out_train = net.sim(x_train)\n",
      "\n",
      "        # Plot result\n",
      "#         plt.subplot(1,1,1)\n",
      "#         plt.plot(error)\n",
      "#         plt.xlabel('Epoch number')\n",
      "#         plt.ylabel('error (default SSE)')\n",
      "#         plt.show()\n",
      "\n",
      "        out_valid = net.sim(x_valid)\n",
      "        out_test = net.sim(x_test)\n",
      "#         plt.subplot(1,1,1)\n",
      "#         plt.plot(np.concatenate((y_train,y_valid, y_test),axis=0))\n",
      "#         plt.plot(np.concatenate((out_train,out_valid,out_test),axis=0))\n",
      "#         plt.show()\n",
      "\n",
      "\n",
      "        #Get results\n",
      "        index = ts_train.index[0]\n",
      "        error_train = maef(tar_out_train)\n",
      "        error_valid = maef(tar_out_valid)\n",
      "        tar_out_test = np.concatenate((y_test, out_test), axis=1)\n",
      "        error_test = maef(tar_out_test)\n",
      "        values = list(np.concatenate((out_train,out_valid,out_test)))\n",
      "        values = np.reshape(values,(len(values),))\n",
      "        data_dict = {\"Index\":[index],\"Error_train\":[error_train],\"Error_valid\":[error_valid], \"Error_test\":[error_test]}\n",
      "        for i in range(1,param3+1):\n",
      "            data_dict[str(i)] = [values[i-1]]\n",
      "        new_row = pd.DataFrame(data=data_dict)\n",
      "        results = results.append(new_row)\n",
      "        \n",
      "    #results.to_csv('/mnt/w76/notebook/datasets/mikhail/ann_res.csv',mode='a',header=False)\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    }
   ],
   "metadata": {}
  }
 ]
}