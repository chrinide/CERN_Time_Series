{
 "metadata": {
  "name": "/ipykee/workdir/tmpLB1vYS/D"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from IPython import parallel\n",
      "# clients = parallel.Client()\n",
      "# clients.block = True  # use synchronous computations\n",
      "# print clients.ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#Load original data\n",
      "data = pd.read_csv('popularity-728days_my.csv')\n",
      "\n",
      "head = list(data.columns[:21]) + range(1,105)\n",
      "data = pd.DataFrame(columns=head, data=data.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#Load original data\n",
      "data = pd.read_csv('popularity-728days_my.csv')\n",
      "\n",
      "head = list(data.columns[:21]) + range(1,105)\n",
      "data = pd.DataFrame(columns=head, data=data.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "#Select data\n",
      "selection = ((data['Now'] - data['Creation-week']) > 26)&((data['Now'] - data['FirstUsage']) > 26)&((data[78] - data[1]) != 0)\n",
      "data_sel = data[selection].copy()\n",
      "#data_sel = data.copy()\n",
      "print data_sel.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "periods = range(1,105)\n",
      "\n",
      "#------------------------------------------------------\n",
      "#Get maximum intervals and last weeks with zeros usages\n",
      "def InterMax(data_sel, periods):\n",
      "    #Get binary vector representation of the selected data\n",
      "    data_bv = data_sel.copy()\n",
      "    #Get week's usages\n",
      "    for i in periods:\n",
      "        if i!=1:\n",
      "            data_bv[i] = data_sel[i] - data_sel[i-1]\n",
      "            \n",
      "    #Get binary representation\n",
      "    data_bv[periods] = (data_bv[periods] != 0)*1\n",
      "    \n",
      "    inter_max = []\n",
      "    last_zeros = []\n",
      "    nb_peaks = []\n",
      "    inter_mean = []\n",
      "    inter_std = []\n",
      "    inter_rel = []\n",
      "    \n",
      "    for i in range(0,data_bv.shape[0]):\n",
      "        ds = data_bv[periods].irow(i)\n",
      "        nz = ds.nonzero()[0]\n",
      "        inter = []\n",
      "        \n",
      "        nb_peaks.append(len(nz))\n",
      "        if len(nz)==0:\n",
      "            nz = [0]\n",
      "        if len(nz)<2:\n",
      "            inter = [0]\n",
      "            #nz = [0]\n",
      "        else:\n",
      "            for k in range(0, len(nz)-1):\n",
      "                val = nz[k+1]-nz[k]\n",
      "                inter.append(val)\n",
      "        \n",
      "        inter = np.array(inter)\n",
      "        inter_mean.append(inter.mean())\n",
      "        inter_std.append(inter.std())\n",
      "        if inter.mean()!=0:\n",
      "            inter_rel.append(inter.std()/inter.mean())\n",
      "        else:\n",
      "            inter_rel.append(0)\n",
      "                \n",
      "        last_zeros.append(periods[-1] - nz[-1] + 1)\n",
      "        inter_max.append(max(inter))\n",
      "    \n",
      "    return np.array(inter_max), np.array(last_zeros), np.array(nb_peaks), np.array(inter_mean), np.array(inter_std), np.array(inter_rel)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "#Add features\n",
      "inter_max, last_zeros, nb_peaks, inter_mean, inter_std, inter_rel = InterMax(data_sel, periods)\n",
      "data_sel['last-zeros'] = last_zeros\n",
      "data_sel['inter_max'] = inter_max\n",
      "data_sel['nb_peaks'] = nb_peaks\n",
      "data_sel['inter_mean'] = inter_mean\n",
      "data_sel['inter_std'] = inter_std\n",
      "data_sel['inter_rel'] = inter_rel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "data = data_sel[data_sel['nb_peaks']>=0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "data_weeks = data[range(1,105)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "df_time_series = data_weeks.copy()\n",
      "for i in range(1,105):\n",
      "    if i!=1:\n",
      "        df_time_series[i] = data_weeks[i]-data_weeks[i-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "param1 = 13\n",
      "df_ts_rolling_sum = pd.rolling_sum(df_time_series, window=param1,axis=1)[range(param1,105)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "ws = 13#window_size\n",
      "fh = 13#forecast horizont\n",
      "param2 = 105-param1\n",
      "\n",
      "def N_M_Transformation(time_serie, ws, fh):\n",
      "    x_cols = ['x'+str(i) for i in range(1,ws+1)]#columns names\n",
      "    time_serie_table = pd.DataFrame(columns=x_cols+['y'])\n",
      "    time_serie_4predict = pd.DataFrame(columns=x_cols)\n",
      "    #Data for train and test\n",
      "    for row_num in range(0, param2-fh-ws):\n",
      "        time_serie_table.loc[row_num] = list(time_serie.icol(range(row_num+1, row_num+ws+1)).values[0])\\\n",
      "        +list(time_serie.icol([row_num+ws+fh]).values[0])#y variable \n",
      "    #Data for prediction\n",
      "    for row_num in range(param2-fh-ws,param2-ws):\n",
      "        time_serie_4predict.loc[row_num-(param2-fh-ws)] = list(time_serie.icol(range(row_num+1, row_num+ws+1)).values[0]) \n",
      "        #print row_num\n",
      "\n",
      "    return time_serie_table, time_serie_4predict\n",
      "\n",
      "def N_M_Transformation_Bolean(time_serie, ws, fh):\n",
      "    x_cols = ['x'+str(i) for i in range(1,ws+1)]#columns names\n",
      "    time_serie_table = pd.DataFrame(columns=x_cols+['y'])\n",
      "    time_serie_4predict = pd.DataFrame(columns=x_cols)\n",
      "    #Data for train and test\n",
      "    for row_num in range(0, param2-fh-ws):\n",
      "        time_serie_table.loc[row_num] = list(time_serie.icol(range(row_num+1, row_num+ws+1)).values[0])\\\n",
      "        +list((time_serie.icol([row_num+ws+fh]).values[0]>0)*1)#y variable \n",
      "    #Data for prediction\n",
      "    for row_num in range(param2-fh-ws,param2-ws):\n",
      "        time_serie_4predict.loc[row_num-(param2-fh-ws)] = list(time_serie.icol(range(row_num+1, row_num+ws+1)).values[0]) \n",
      "        #print row_num\n",
      "\n",
      "    return time_serie_table, time_serie_4predict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ts_train = df_ts_rolling_sum.irow([46])\n",
      "x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "max_value = ts_train.max(axis=1).values[0]\n",
      "time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "time_serie_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "param3 = param2-fh-ws\n",
      "print param3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# %%px\n",
      "# results = pd.DataFrame(columns=[\"Index\",\"Error_train\",\"Error_valid\", \"Error_test\"]+range(0,param3))\n",
      "# results.to_csv('/mnt/w76/notebook/datasets/mikhail/ann_res.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"../notebooks/xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from rep.classifiers import XGBoostClassifier\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "from rep.classifiers import SklearnClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "# Using gradient boosting with default settings\n",
      "xgboost = SklearnClassifier(GradientBoostingClassifier())\n",
      "\n",
      "#xgboost = XGBoostClassifier(objective='binary:logitraw', eta=0.2, max_depth=6, subsample=0.8, n_estimators=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ANN(rows_range):\n",
      "    \n",
      "    keys = [str(i) for i in range(1,param3+1)]\n",
      "    results = pd.DataFrame(columns=[\"Index\",\"Error_train\",\"Error_valid\", \"Error_test\"]+keys)\n",
      "\n",
      "    param4 = fh+10\n",
      "\n",
      "    for row in rows_range:\n",
      "        if row%500==0:\n",
      "            print row\n",
      "        #Take a row and transfrom it\n",
      "        ts_train = df_ts_rolling_sum.irow([row])\n",
      "        max_value = ts_train.max(axis=1).values[0]\n",
      "        time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "        #Transform the row's values to the [0,1] values\n",
      "        time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "        time_serie_table = time_serie_table/(1.0*max_value)\n",
      "        time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "        time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "        x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "        #Get train data\n",
      "        train = time_serie_table.irow(range(0,param3-param4))\n",
      "        #train = train.drop_duplicates(x_cols)\n",
      "        x_train = train[x_cols]\n",
      "        x_train = x_train.astype('float64')\n",
      "        y_train = train['y'].values\n",
      "        #Get validation data\n",
      "        x_valid = time_serie_table[x_cols].irow(range(param3-param4,param3-fh))\n",
      "        x_valid = x_valid.astype('float64')\n",
      "        y_valid = time_serie_table['y'].irow(range(param3-param4,param3-fh)).values\n",
      "        #Get test data\n",
      "        x_test = time_serie_table[x_cols].irow(range(param3-fh,param3))\n",
      "        x_test = x_test.astype('float64')\n",
      "        y_test = time_serie_table['y'].irow(range(param3-fh,param3)).values\n",
      "        # Create network with 2 layers and random initialized\n",
      "        if y_train.sum()==0 or y_train.sum()==len(y_train):\n",
      "            continue\n",
      "        \n",
      "        xgboost.fit(x_train, y_train)\n",
      "\n",
      "        # Simulate network\n",
      "        out_train = xgboost.predict_proba(x_train)[:,1]\n",
      "        out_valid = xgboost.predict_proba(x_valid)[:,1]\n",
      "        out_test = xgboost.predict_proba(x_test)[:,1]\n",
      "\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(np.concatenate((y_train,y_valid, y_test),axis=0), color='b')\n",
      "        plt.plot(np.concatenate((out_train,out_valid,out_test),axis=0), color='r')\n",
      "        plt.ylim(-1,1.5)\n",
      "        plt.show()\n",
      "\n",
      "\n",
      "        #Get results\n",
      "        index = ts_train.index[0]\n",
      "        error_train = mean_absolute_error(y_train, out_train)\n",
      "        error_valid = mean_absolute_error(y_valid, out_valid)\n",
      "        error_test = mean_absolute_error(y_test, out_test)\n",
      "        values = list(np.concatenate((out_train,out_valid,out_test)))\n",
      "        values = np.reshape(values,(len(values),))\n",
      "        data_dict = {\"Index\":[index],\"Error_train\":[error_train],\"Error_valid\":[error_valid], \"Error_test\":[error_test]}\n",
      "        for i in range(1,param3+1):\n",
      "            data_dict[str(i)] = [values[i-1]]\n",
      "        new_row = pd.DataFrame(data=data_dict)\n",
      "        results = results.append(new_row)\n",
      "        \n",
      "    #results.to_csv('/mnt/w76/notebook/datasets/mikhail/ann_res.csv',mode='a',header=False)\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ANN(rows_range):\n",
      "    \n",
      "    keys = [str(i) for i in range(1,param3+1)]\n",
      "    results = pd.DataFrame(columns=[\"Index\",\"Error_train\",\"Error_valid\", \"Error_test\"]+keys)\n",
      "\n",
      "    param4 = fh+10\n",
      "\n",
      "    for row in rows_range:\n",
      "        if row%500==0:\n",
      "            print row\n",
      "        #Take a row and transfrom it\n",
      "        ts_train = df_ts_rolling_sum.irow([row])\n",
      "        max_value = ts_train.max(axis=1).values[0]\n",
      "        time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "        #Transform the row's values to the [0,1] values\n",
      "        time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "        time_serie_table = time_serie_table/(1.0*max_value)\n",
      "        time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "        time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "        x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "        #Get train data\n",
      "        train = time_serie_table.irow(range(0,param3-param4))\n",
      "        #train = train.drop_duplicates(x_cols)\n",
      "        x_train = train[x_cols]\n",
      "        x_train = x_train.astype('float64')\n",
      "        y_train = train['y'].values\n",
      "        #Get validation data\n",
      "        x_valid = time_serie_table[x_cols].irow(range(param3-param4,param3-fh))\n",
      "        x_valid = x_valid.astype('float64')\n",
      "        y_valid = time_serie_table['y'].irow(range(param3-param4,param3-fh)).values\n",
      "        #Get test data\n",
      "        x_test = time_serie_table[x_cols].irow(range(param3-fh,param3))\n",
      "        x_test = x_test.astype('float64')\n",
      "        y_test = time_serie_table['y'].irow(range(param3-fh,param3)).values\n",
      "        # Create network with 2 layers and random initialized\n",
      "        if y_train.sum()==0 or y_train.sum()==len(y_train):\n",
      "            continue\n",
      "        if y_train.sum()==0:\n",
      "            out_train = y_train\n",
      "            out_valid = y_valid*0\n",
      "            out_test = y_test*0\n",
      "        elif y_train.sum()==len(y_train):\n",
      "            out_train = y_train\n",
      "            out_valid = y_valid*0+1\n",
      "            out_test = y_test*0+1\n",
      "        else :\n",
      "        \n",
      "            xgboost.fit(x_train, y_train)\n",
      "\n",
      "            # Simulate network\n",
      "            out_train = xgboost.predict_proba(x_train)[:,1]\n",
      "            out_valid = xgboost.predict_proba(x_valid)[:,1]\n",
      "            out_test = xgboost.predict_proba(x_test)[:,1]\n",
      "\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(np.concatenate((y_train,y_valid, y_test),axis=0), color='b')\n",
      "        plt.plot(np.concatenate((out_train,out_valid,out_test),axis=0), color='r')\n",
      "        plt.ylim(-1,1.5)\n",
      "        plt.show()\n",
      "\n",
      "\n",
      "        #Get results\n",
      "        index = ts_train.index[0]\n",
      "        error_train = mean_absolute_error(y_train, out_train)\n",
      "        error_valid = mean_absolute_error(y_valid, out_valid)\n",
      "        error_test = mean_absolute_error(y_test, out_test)\n",
      "        values = list(np.concatenate((out_train,out_valid,out_test)))\n",
      "        values = np.reshape(values,(len(values),))\n",
      "        data_dict = {\"Index\":[index],\"Error_train\":[error_train],\"Error_valid\":[error_valid], \"Error_test\":[error_test]}\n",
      "        for i in range(1,param3+1):\n",
      "            data_dict[str(i)] = [values[i-1]]\n",
      "        new_row = pd.DataFrame(data=data_dict)\n",
      "        results = results.append(new_row)\n",
      "        \n",
      "    #results.to_csv('/mnt/w76/notebook/datasets/mikhail/ann_res.csv',mode='a',header=False)\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = range(0,100)#5704\n",
      "# step = len(rows)/int(engines)\n",
      "# inputs = []\n",
      "# for i in range(0,engines-1):\n",
      "#     inp = rows[step*i:step*(i+1)]\n",
      "#     inputs.append(inp)\n",
      "# inp = rows[step*(i+1):]\n",
      "# inputs.append(inp)\n",
      "# len(inputs[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "# view = clients.load_balanced_view()\n",
      "# %time res = view.map(ANN, inputs)\n",
      "results = ANN(rows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = range(0,5704)#5704\n",
      "# step = len(rows)/int(engines)\n",
      "# inputs = []\n",
      "# for i in range(0,engines-1):\n",
      "#     inp = rows[step*i:step*(i+1)]\n",
      "#     inputs.append(inp)\n",
      "# inp = rows[step*(i+1):]\n",
      "# inputs.append(inp)\n",
      "# len(inputs[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "# view = clients.load_balanced_view()\n",
      "# %time res = view.map(ANN, inputs)\n",
      "results = ANN(rows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ANN(rows_range):\n",
      "    \n",
      "    keys = [str(i) for i in range(1,param3+1)]\n",
      "    results = pd.DataFrame(columns=[\"Index\",\"Error_train\",\"Error_valid\", \"Error_test\"]+keys)\n",
      "\n",
      "    param4 = fh+10\n",
      "\n",
      "    for row in rows_range:\n",
      "        if row%500==0:\n",
      "            print row\n",
      "        #Take a row and transfrom it\n",
      "        ts_train = df_ts_rolling_sum.irow([row])\n",
      "        max_value = ts_train.max(axis=1).values[0]\n",
      "        time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "        #Transform the row's values to the [0,1] values\n",
      "        time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "        time_serie_table = time_serie_table/(1.0*max_value)\n",
      "        time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "        time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "        x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "        #Get train data\n",
      "        train = time_serie_table.irow(range(0,param3-param4))\n",
      "        #train = train.drop_duplicates(x_cols)\n",
      "        x_train = train[x_cols]\n",
      "        x_train = x_train.astype('float64')\n",
      "        y_train = train['y'].values\n",
      "        #Get validation data\n",
      "        x_valid = time_serie_table[x_cols].irow(range(param3-param4,param3-fh))\n",
      "        x_valid = x_valid.astype('float64')\n",
      "        y_valid = time_serie_table['y'].irow(range(param3-param4,param3-fh)).values\n",
      "        #Get test data\n",
      "        x_test = time_serie_table[x_cols].irow(range(param3-fh,param3))\n",
      "        x_test = x_test.astype('float64')\n",
      "        y_test = time_serie_table['y'].irow(range(param3-fh,param3)).values\n",
      "        # Create network with 2 layers and random initialized\n",
      "        if y_train.sum()==0 or y_train.sum()==len(y_train):\n",
      "            continue\n",
      "        if y_train.sum()==0:\n",
      "            out_train = y_train\n",
      "            out_valid = y_valid*0\n",
      "            out_test = y_test*0\n",
      "        elif y_train.sum()==len(y_train):\n",
      "            out_train = y_train\n",
      "            out_valid = y_valid*0+1\n",
      "            out_test = y_test*0+1\n",
      "        else :\n",
      "        \n",
      "            xgboost.fit(x_train, y_train)\n",
      "\n",
      "            # Simulate network\n",
      "            out_train = xgboost.predict_proba(x_train)[:,1]\n",
      "            out_valid = xgboost.predict_proba(x_valid)[:,1]\n",
      "            out_test = xgboost.predict_proba(x_test)[:,1]\n",
      "\n",
      "#         plt.subplot(1,1,1)\n",
      "#         plt.plot(np.concatenate((y_train,y_valid, y_test),axis=0), color='b')\n",
      "#         plt.plot(np.concatenate((out_train,out_valid,out_test),axis=0), color='r')\n",
      "#         plt.ylim(-1,1.5)\n",
      "#         plt.show()\n",
      "\n",
      "\n",
      "        #Get results\n",
      "        index = ts_train.index[0]\n",
      "        error_train = mean_absolute_error(y_train, out_train)\n",
      "        error_valid = mean_absolute_error(y_valid, out_valid)\n",
      "        error_test = mean_absolute_error(y_test, out_test)\n",
      "        values = list(np.concatenate((out_train,out_valid,out_test)))\n",
      "        values = np.reshape(values,(len(values),))\n",
      "        data_dict = {\"Index\":[index],\"Error_train\":[error_train],\"Error_valid\":[error_valid], \"Error_test\":[error_test]}\n",
      "        for i in range(1,param3+1):\n",
      "            data_dict[str(i)] = [values[i-1]]\n",
      "        new_row = pd.DataFrame(data=data_dict)\n",
      "        results = results.append(new_row)\n",
      "        \n",
      "    #results.to_csv('/mnt/w76/notebook/datasets/mikhail/ann_res.csv',mode='a',header=False)\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = range(0,5704)#5704\n",
      "# step = len(rows)/int(engines)\n",
      "# inputs = []\n",
      "# for i in range(0,engines-1):\n",
      "#     inp = rows[step*i:step*(i+1)]\n",
      "#     inputs.append(inp)\n",
      "# inp = rows[step*(i+1):]\n",
      "# inputs.append(inp)\n",
      "# len(inputs[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "# view = clients.load_balanced_view()\n",
      "# %time res = view.map(ANN, inputs)\n",
      "results = ANN(rows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "# results = pd.concat(res)\n",
      "results.to_csv('tree_res.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('tree_res.csv')\n",
      "results.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results['nb_peaks'] = [data['nb_peaks'].ix[int(i)] for i in results['Index'].values]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_ts_rolling_sum.columns\n",
      "#df_ts_rolling_sum = (df_ts_rolling_sum>0)*1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=1)*(results['Error_train']<=1)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "#non_nan_res[val_cols] = (non_nan_res[val_cols].values>=0.95)*1\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=2)*(results['Error_train']<=2)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "#non_nan_res[val_cols] = (non_nan_res[val_cols].values>=0.95)*1\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ANN(rows_range):\n",
      "    \n",
      "    keys = [str(i) for i in range(1,param3+1)]\n",
      "    results = pd.DataFrame(columns=[\"Index\",\"Error_train\",\"Error_valid\", \"Error_test\"]+keys)\n",
      "\n",
      "    param4 = fh+10\n",
      "\n",
      "    for row in rows_range:\n",
      "        if row%500==0:\n",
      "            print row\n",
      "        #Take a row and transfrom it\n",
      "        ts_train = df_ts_rolling_sum.irow([row])\n",
      "        max_value = ts_train.max(axis=1).values[0]\n",
      "        time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "        #Transform the row's values to the [0,1] values\n",
      "        time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "        time_serie_table = time_serie_table/(1.0*max_value)\n",
      "        time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "        time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "        x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "        #Get train data\n",
      "        train = time_serie_table.irow(range(0,param3-param4))\n",
      "        #train = train.drop_duplicates(x_cols)\n",
      "        x_train = train[x_cols]\n",
      "        x_train = x_train.astype('float64')\n",
      "        y_train = train['y'].values\n",
      "        #Get validation data\n",
      "        x_valid = time_serie_table[x_cols].irow(range(param3-param4,param3-fh))\n",
      "        x_valid = x_valid.astype('float64')\n",
      "        y_valid = time_serie_table['y'].irow(range(param3-param4,param3-fh)).values\n",
      "        #Get test data\n",
      "        x_test = time_serie_table[x_cols].irow(range(param3-fh,param3))\n",
      "        x_test = x_test.astype('float64')\n",
      "        y_test = time_serie_table['y'].irow(range(param3-fh,param3)).values\n",
      "        # Create network with 2 layers and random initialized\n",
      "        if y_train.sum()==0:\n",
      "            out_train = y_train\n",
      "            out_valid = y_valid*0\n",
      "            out_test = y_test*0\n",
      "        elif y_train.sum()==len(y_train):\n",
      "            out_train = y_train\n",
      "            out_valid = y_valid*0+1\n",
      "            out_test = y_test*0+1\n",
      "        else :\n",
      "        \n",
      "            xgboost.fit(x_train, y_train)\n",
      "\n",
      "            # Simulate network\n",
      "            out_train = xgboost.predict_proba(x_train)[:,1]\n",
      "            out_valid = xgboost.predict_proba(x_valid)[:,1]\n",
      "            out_test = xgboost.predict_proba(x_test)[:,1]\n",
      "\n",
      "#         plt.subplot(1,1,1)\n",
      "#         plt.plot(np.concatenate((y_train,y_valid, y_test),axis=0), color='b')\n",
      "#         plt.plot(np.concatenate((out_train,out_valid,out_test),axis=0), color='r')\n",
      "#         plt.ylim(-1,1.5)\n",
      "#         plt.show()\n",
      "\n",
      "\n",
      "        #Get results\n",
      "        index = ts_train.index[0]\n",
      "        error_train = mean_absolute_error(y_train, out_train)\n",
      "        error_valid = mean_absolute_error(y_valid, out_valid)\n",
      "        error_test = mean_absolute_error(y_test, out_test)\n",
      "        values = list(np.concatenate((out_train,out_valid,out_test)))\n",
      "        values = np.reshape(values,(len(values),))\n",
      "        data_dict = {\"Index\":[index],\"Error_train\":[error_train],\"Error_valid\":[error_valid], \"Error_test\":[error_test]}\n",
      "        for i in range(1,param3+1):\n",
      "            data_dict[str(i)] = [values[i-1]]\n",
      "        new_row = pd.DataFrame(data=data_dict)\n",
      "        results = results.append(new_row)\n",
      "        \n",
      "    #results.to_csv('/mnt/w76/notebook/datasets/mikhail/ann_res.csv',mode='a',header=False)\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "#!easy_install neurolab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# engines = len(clients.ids)\n",
      "# print engines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for i in range(0,50):\n",
      "#     ts_train = df_ts_rolling_sum.irow([i])\n",
      "#     time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "#     y = time_serie_table['y']\n",
      "\n",
      "#     plt.plot( y)\n",
      "#     plt.title(str(i))\n",
      "#     plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for i in range(0,50):\n",
      "#     ts_train = df_ts_rolling_sum.irow([i])\n",
      "\n",
      "#     plt.plot(range(0,ts_train.values[0].shape[0]), ts_train.values[0])\n",
      "#     plt.title(str(i))\n",
      "#     plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = range(0,5704)#5704\n",
      "# step = len(rows)/int(engines)\n",
      "# inputs = []\n",
      "# for i in range(0,engines-1):\n",
      "#     inp = rows[step*i:step*(i+1)]\n",
      "#     inputs.append(inp)\n",
      "# inp = rows[step*(i+1):]\n",
      "# inputs.append(inp)\n",
      "# len(inputs[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "# view = clients.load_balanced_view()\n",
      "# %time res = view.map(ANN, inputs)\n",
      "results = ANN(rows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "# results = pd.concat(res)\n",
      "results.to_csv('tree_res.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('tree_res.csv')\n",
      "results.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results['nb_peaks'] = [data['nb_peaks'].ix[int(i)] for i in results['Index'].values]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_ts_rolling_sum.columns\n",
      "#df_ts_rolling_sum = (df_ts_rolling_sum>0)*1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=2)*(results['Error_train']<=2)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "#non_nan_res[val_cols] = (non_nan_res[val_cols].values>=0.95)*1\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_values = df_ts_rolling_sum.max(axis=1)\n",
      "df_ts_rolling_sum_std = df_ts_rolling_sum.copy()\n",
      "for col in df_ts_rolling_sum.columns:\n",
      "    df_ts_rolling_sum_std[col] = df_ts_rolling_sum[col]/max_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]\n",
      "val_x = range(105-66,105)\n",
      "cols = range(13,105)\n",
      "a=0\n",
      "b=60\n",
      "N=b-a\n",
      "figure(figsize=(15, 5*(N//3+1)))\n",
      "for row in range(a,b):\n",
      "    subplot(N//3+1,3,row)\n",
      "    plt.plot(val_x,non_nan_res[val_cols].irow([row]).values[0], color='r', label='predict')\n",
      "    index = int(non_nan_res.irow([row])['Index'].values)\n",
      "    plt.plot(cols, (df_ts_rolling_sum_std[cols].xs(index)>0)*1, color='b', label='real')\n",
      "    plt.plot([param3+fh+ws,param3+fh+ws], [-1,1], color='black')\n",
      "    plt.plot([param3+fh-10+ws,param3+fh-10+ws], [-1,1], color='black')\n",
      "    plt.title('Index is '+str(index))\n",
      "    plt.xlim(ws,105)\n",
      "    plt.ylim(-1,1.1)\n",
      "    plt.legend(loc='best')\n",
      "    #plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print error hists\n",
      "figure(figsize=(15, 5))\n",
      "subplot(121)\n",
      "plt.hist(non_nan_res['Error_test'].values, color='r', bins=20, label='test', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_train'].values, color='b', bins=20, label='train', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_valid'].values, color='g', bins=20, label='valid', alpha=1, histtype='step')\n",
      "plt.title('Errors')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for the last point\n",
      "subplot(122)\n",
      "plt.hist(non_nan_res['66'].values, bins=10, label='last point')\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_last=[]\n",
      "y_valid_last = []\n",
      "for i in non_nan_res['Index']:\n",
      "    i=int(i)\n",
      "    cur_serie = df_ts_rolling_sum.xs(i).values\n",
      "    y_last.append(cur_serie[104-fh]/(1.0*cur_serie.max()))\n",
      "    y_valid_last.append(cur_serie[104-fh-13]/(1.0*cur_serie.max()))\n",
      "y_last = np.array(y_last)\n",
      "y_valid_last = np.array(y_valid_last)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "non_nan_res[y_last==0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "#print predict value for the last point\n",
      "subplot(2,2,1)\n",
      "values = non_nan_res['66'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,2)\n",
      "values = non_nan_res['Error_test'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_test')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,3)\n",
      "values = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,4)\n",
      "values = non_nan_res['Error_valid'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "y_score = non_nan_res['66'].values\n",
      "#y_score = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr, tpr)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetCoord(xedges, yedges, x, y):\n",
      "    for i in range(0,len(xedges)):\n",
      "        if x<xedges[i]:\n",
      "            break\n",
      "            \n",
      "    for j in range(0,len(yedges)):\n",
      "        if y<yedges[j]:\n",
      "            break\n",
      "    \n",
      "    return i-1,j-1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib.colors import LogNorm\n",
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(y_last, non_nan_res['66'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(y_valid_last, non_nan_res['53'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, y_valid_last[i], non_nan_res['53'].values[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[y_last==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[y_last!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(y_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(y_valid_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_value_predict_test = []\n",
      "avg_value_true_test = []\n",
      "avg_value_predict_valid = []\n",
      "avg_value_true_valid = []\n",
      "test_cols = [str(i) for i in range(53,66)]\n",
      "valid_cols = [str(i) for i in range(43,53)]\n",
      "\n",
      "for row in range(0,non_nan_res.shape[0]):\n",
      "    avg_val_pred_test = non_nan_res[test_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_test.append(avg_val_pred_test)\n",
      "    avg_val_true_test = df_ts_rolling_sum_std[range(92,105)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_test.append(avg_val_true_test)\n",
      "    \n",
      "    avg_val_pred_valid = non_nan_res[valid_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_valid.append(avg_val_pred_valid)\n",
      "    avg_val_true_valid = df_ts_rolling_sum_std[range(82,92)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_valid.append(avg_val_true_valid)\n",
      "    \n",
      "avg_value_predict_test = np.array(avg_value_predict_test)\n",
      "avg_value_true_test = np.array(avg_value_true_test)\n",
      "avg_value_predict_valid = np.array(avg_value_predict_valid)\n",
      "avg_value_true_valid = np.array(avg_value_true_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "\n",
      "subplot(2,2,1)\n",
      "values = avg_value_predict_test\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,2)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error valid')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,3)\n",
      "values = (avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,4)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true_avg = (avg_value_true_test>0)*1\n",
      "#y_score_avg = 0.5*(avg_value_predict_test+2.0)\n",
      "y_score_avg = 0.5*(avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)+0.5\n",
      "fpr_avg, tpr_avg, _ = roc_curve(y_true_avg, y_score_avg, pos_label=None, sample_weight=None)\n",
      "roc_auc_avg = auc(fpr_avg, tpr_avg)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr_avg, tpr_avg)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc_avg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(avg_value_true_test, avg_value_predict_test, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(avg_value_true_valid, avg_value_predict_valid, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, avg_value_true_valid[i], avg_value_predict_valid[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[avg_value_true_test==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[avg_value_true_test!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(avg_value_true_test, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(avg_value_true_valid, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (avg_value_true_test>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('ann_res_50.csv')\n",
      "results['nb_peaks'] = [data['nb_peaks'].ix[int(i)] for i in results['Index'].values]\n",
      "\n",
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=0.5)*(results['Error_train']<=0.05)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_values = df_ts_rolling_sum.max(axis=1)\n",
      "df_ts_rolling_sum_std = df_ts_rolling_sum.copy()\n",
      "for col in df_ts_rolling_sum.columns:\n",
      "    df_ts_rolling_sum_std[col] = df_ts_rolling_sum[col]/max_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]\n",
      "val_x = range(105-66,105)\n",
      "cols = range(13,105)\n",
      "a=0\n",
      "b=60\n",
      "N=b-a\n",
      "figure(figsize=(15, 5*(N//3+1)))\n",
      "for row in range(a,b):\n",
      "    subplot(N//3+1,3,row)\n",
      "    plt.plot(val_x,non_nan_res[val_cols].irow([row]).values[0], color='r', label='predict')\n",
      "    index = int(non_nan_res.irow([row])['Index'].values)\n",
      "    plt.plot(cols, df_ts_rolling_sum_std[cols].xs(index), color='b', label='real')\n",
      "    plt.plot([param3+fh+ws,param3+fh+ws], [-1,1], color='black')\n",
      "    plt.plot([param3+fh-10+ws,param3+fh-10+ws], [-1,1], color='black')\n",
      "    plt.title('Index is '+str(index))\n",
      "    plt.xlim(ws,105)\n",
      "    plt.ylim(-1,1.1)\n",
      "    plt.legend(loc='best')\n",
      "    #plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print error hists\n",
      "figure(figsize=(15, 5))\n",
      "subplot(121)\n",
      "plt.hist(non_nan_res['Error_test'].values, color='r', bins=20, label='test', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_train'].values, color='b', bins=20, label='train', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_valid'].values, color='g', bins=20, label='valid', alpha=1, histtype='step')\n",
      "plt.title('Errors')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for the last point\n",
      "subplot(122)\n",
      "plt.hist(non_nan_res['66'].values, bins=10, label='last point')\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_last=[]\n",
      "y_valid_last = []\n",
      "for i in non_nan_res['Index']:\n",
      "    i=int(i)\n",
      "    cur_serie = df_ts_rolling_sum.xs(i).values\n",
      "    y_last.append(cur_serie[104-fh]/(1.0*cur_serie.max()))\n",
      "    y_valid_last.append(cur_serie[104-fh-13]/(1.0*cur_serie.max()))\n",
      "y_last = np.array(y_last)\n",
      "y_valid_last = np.array(y_valid_last)\n",
      "non_nan_res[y_last==0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "#print predict value for the last point\n",
      "subplot(2,2,1)\n",
      "values = non_nan_res['66'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,2)\n",
      "values = non_nan_res['Error_test'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_test')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,3)\n",
      "values = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,4)\n",
      "values = non_nan_res['Error_valid'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "#y_score = non_nan_res['66'].values\n",
      "y_score = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr, tpr)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(y_last, non_nan_res['66'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(y_valid_last, non_nan_res['53'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, y_valid_last[i], non_nan_res['53'].values[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[y_last==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[y_last!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(y_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(y_valid_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_value_predict_test = []\n",
      "avg_value_true_test = []\n",
      "avg_value_predict_valid = []\n",
      "avg_value_true_valid = []\n",
      "test_cols = [str(i) for i in range(53,66)]\n",
      "valid_cols = [str(i) for i in range(43,53)]\n",
      "\n",
      "for row in range(0,non_nan_res.shape[0]):\n",
      "    avg_val_pred_test = non_nan_res[test_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_test.append(avg_val_pred_test)\n",
      "    avg_val_true_test = df_ts_rolling_sum_std[range(92,105)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_test.append(avg_val_true_test)\n",
      "    \n",
      "    avg_val_pred_valid = non_nan_res[valid_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_valid.append(avg_val_pred_valid)\n",
      "    avg_val_true_valid = df_ts_rolling_sum_std[range(82,92)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_valid.append(avg_val_true_valid)\n",
      "    \n",
      "avg_value_predict_test = np.array(avg_value_predict_test)\n",
      "avg_value_true_test = np.array(avg_value_true_test)\n",
      "avg_value_predict_valid = np.array(avg_value_predict_valid)\n",
      "avg_value_true_valid = np.array(avg_value_true_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('tree_res.csv')\n",
      "results['nb_peaks'] = [data['nb_peaks'].ix[int(i)] for i in results['Index'].values]\n",
      "\n",
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=0.5)*(results['Error_train']<=0.05)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_values = df_ts_rolling_sum.max(axis=1)\n",
      "df_ts_rolling_sum_std = df_ts_rolling_sum.copy()\n",
      "for col in df_ts_rolling_sum.columns:\n",
      "    df_ts_rolling_sum_std[col] = df_ts_rolling_sum[col]/max_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]\n",
      "val_x = range(105-66,105)\n",
      "cols = range(13,105)\n",
      "a=0\n",
      "b=60\n",
      "N=b-a\n",
      "figure(figsize=(15, 5*(N//3+1)))\n",
      "for row in range(a,b):\n",
      "    subplot(N//3+1,3,row)\n",
      "    plt.plot(val_x,non_nan_res[val_cols].irow([row]).values[0], color='r', label='predict')\n",
      "    index = int(non_nan_res.irow([row])['Index'].values)\n",
      "    plt.plot(cols, df_ts_rolling_sum_std[cols].xs(index), color='b', label='real')\n",
      "    plt.plot([param3+fh+ws,param3+fh+ws], [-1,1], color='black')\n",
      "    plt.plot([param3+fh-10+ws,param3+fh-10+ws], [-1,1], color='black')\n",
      "    plt.title('Index is '+str(index))\n",
      "    plt.xlim(ws,105)\n",
      "    plt.ylim(-1,1.1)\n",
      "    plt.legend(loc='best')\n",
      "    #plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print error hists\n",
      "figure(figsize=(15, 5))\n",
      "subplot(121)\n",
      "plt.hist(non_nan_res['Error_test'].values, color='r', bins=20, label='test', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_train'].values, color='b', bins=20, label='train', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_valid'].values, color='g', bins=20, label='valid', alpha=1, histtype='step')\n",
      "plt.title('Errors')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for the last point\n",
      "subplot(122)\n",
      "plt.hist(non_nan_res['66'].values, bins=10, label='last point')\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_last=[]\n",
      "y_valid_last = []\n",
      "for i in non_nan_res['Index']:\n",
      "    i=int(i)\n",
      "    cur_serie = df_ts_rolling_sum.xs(i).values\n",
      "    y_last.append(cur_serie[104-fh]/(1.0*cur_serie.max()))\n",
      "    y_valid_last.append(cur_serie[104-fh-13]/(1.0*cur_serie.max()))\n",
      "y_last = np.array(y_last)\n",
      "y_valid_last = np.array(y_valid_last)\n",
      "non_nan_res[y_last==0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "#print predict value for the last point\n",
      "subplot(2,2,1)\n",
      "values = non_nan_res['66'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,2)\n",
      "values = non_nan_res['Error_test'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_test')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,3)\n",
      "values = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,4)\n",
      "values = non_nan_res['Error_valid'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "#y_score = non_nan_res['66'].values\n",
      "y_score = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr, tpr)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(y_last, non_nan_res['66'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(y_valid_last, non_nan_res['53'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, y_valid_last[i], non_nan_res['53'].values[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[y_last==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[y_last!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(y_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(y_valid_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_value_predict_test = []\n",
      "avg_value_true_test = []\n",
      "avg_value_predict_valid = []\n",
      "avg_value_true_valid = []\n",
      "test_cols = [str(i) for i in range(53,66)]\n",
      "valid_cols = [str(i) for i in range(43,53)]\n",
      "\n",
      "for row in range(0,non_nan_res.shape[0]):\n",
      "    avg_val_pred_test = non_nan_res[test_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_test.append(avg_val_pred_test)\n",
      "    avg_val_true_test = df_ts_rolling_sum_std[range(92,105)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_test.append(avg_val_true_test)\n",
      "    \n",
      "    avg_val_pred_valid = non_nan_res[valid_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_valid.append(avg_val_pred_valid)\n",
      "    avg_val_true_valid = df_ts_rolling_sum_std[range(82,92)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_valid.append(avg_val_true_valid)\n",
      "    \n",
      "avg_value_predict_test = np.array(avg_value_predict_test)\n",
      "avg_value_true_test = np.array(avg_value_true_test)\n",
      "avg_value_predict_valid = np.array(avg_value_predict_valid)\n",
      "avg_value_true_valid = np.array(avg_value_true_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "\n",
      "subplot(2,2,1)\n",
      "values = avg_value_predict_test\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,2)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error valid')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,3)\n",
      "values = (avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,4)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true_avg = (avg_value_true_test>0)*1\n",
      "#y_score_avg = 0.5*(avg_value_predict_test+2.0)\n",
      "y_score_avg = 0.5*(avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)+0.5\n",
      "fpr_avg, tpr_avg, _ = roc_curve(y_true_avg, y_score_avg, pos_label=None, sample_weight=None)\n",
      "roc_auc_avg = auc(fpr_avg, tpr_avg)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr_avg, tpr_avg)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc_avg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(avg_value_true_test, avg_value_predict_test, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(avg_value_true_valid, avg_value_predict_valid, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, avg_value_true_valid[i], avg_value_predict_valid[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[avg_value_true_test==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[avg_value_true_test!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(avg_value_true_test, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(avg_value_true_valid, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (avg_value_true_test>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "#ipykee.create_project(project_name=\"D._UsageForecast\", repository=\"git@github.com:hushchyn-mikhail/CERN_Time_Series.git\")\n",
      "session = ipykee.Session(project_name=\"D._UsageForecast\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.commit(\"Trees. Report 1.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data = pd.DataFrame()\n",
      "\n",
      "param4 = fh+10\n",
      "\n",
      "for row in [0,1,2,3,4,5]:\n",
      "    if row%500==0:\n",
      "        print row\n",
      "     #Take a row and transfrom it\n",
      "    ts_train = df_ts_rolling_sum.irow([row])\n",
      "    max_value = ts_train.max(axis=1).values[0]\n",
      "    time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "    #Transform the row's values to the [0,1] values\n",
      "    time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "    time_serie_table = time_serie_table/(1.0*max_value)\n",
      "    time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "    time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "    x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "    #Get train data\n",
      "    train = time_serie_table.irow(range(0,param3-param4))\n",
      "    #train = train.drop_duplicates(x_cols)\n",
      "    x_train = x_train.astype('float64')\n",
      "    \n",
      "    all_data = pd.concat([all_data, x_train])\n",
      "\n",
      "all_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data = pd.DataFrame()\n",
      "\n",
      "param4 = fh+10\n",
      "\n",
      "for row in [0,1,2,3,4,5]:\n",
      "    if row%500==0:\n",
      "        print row\n",
      "     #Take a row and transfrom it\n",
      "    ts_train = df_ts_rolling_sum.irow([row])\n",
      "    max_value = ts_train.max(axis=1).values[0]\n",
      "    time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "    #Transform the row's values to the [0,1] values\n",
      "    time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "    time_serie_table = time_serie_table/(1.0*max_value)\n",
      "    time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "    time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "    x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "    #Get train data\n",
      "    train = time_serie_table.irow(range(0,param3-param4))\n",
      "    #train = train.drop_duplicates(x_cols)\n",
      "    train = train.astype('float64')\n",
      "    \n",
      "    all_data = pd.concat([all_data, train])\n",
      "\n",
      "all_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data = pd.DataFrame()\n",
      "\n",
      "param4 = fh+10\n",
      "\n",
      "for row in [0,1,2,3,4,5]:\n",
      "    if row%500==0:\n",
      "        print row\n",
      "     #Take a row and transfrom it\n",
      "    ts_train = df_ts_rolling_sum.irow([row])\n",
      "    max_value = ts_train.max(axis=1).values[0]\n",
      "    time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "    #Transform the row's values to the [0,1] values\n",
      "    time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "    time_serie_table = time_serie_table/(1.0*max_value)\n",
      "    time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "    time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "    x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "    #Get train data\n",
      "    train = time_serie_table.irow(range(0,param3-param4))\n",
      "    #train = train.drop_duplicates(x_cols)\n",
      "    train = train.astype('float64')\n",
      "    \n",
      "    all_data = pd.concat([all_data, train])\n",
      "\n",
      "all_data.shape()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data = pd.DataFrame()\n",
      "\n",
      "param4 = fh+10\n",
      "\n",
      "for row in [0,1,2,3,4,5]:\n",
      "    if row%500==0:\n",
      "        print row\n",
      "     #Take a row and transfrom it\n",
      "    ts_train = df_ts_rolling_sum.irow([row])\n",
      "    max_value = ts_train.max(axis=1).values[0]\n",
      "    time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "    #Transform the row's values to the [0,1] values\n",
      "    time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "    time_serie_table = time_serie_table/(1.0*max_value)\n",
      "    time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "    time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "    x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "    #Get train data\n",
      "    train = time_serie_table.irow(range(0,param3-param4))\n",
      "    #train = train.drop_duplicates(x_cols)\n",
      "    train = train.astype('float64')\n",
      "    \n",
      "    all_data = pd.concat([all_data, train])\n",
      "\n",
      "all_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data = pd.DataFrame()\n",
      "\n",
      "param4 = fh+10\n",
      "\n",
      "for row in range(0,5704):\n",
      "    if row%500==0:\n",
      "        print row\n",
      "     #Take a row and transfrom it\n",
      "    ts_train = df_ts_rolling_sum.irow([row])\n",
      "    max_value = ts_train.max(axis=1).values[0]\n",
      "    time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "    #Transform the row's values to the [0,1] values\n",
      "    time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "    time_serie_table = time_serie_table/(1.0*max_value)\n",
      "    time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "    time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "    x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "    #Get train data\n",
      "    train = time_serie_table.irow(range(0,param3-param4))\n",
      "    #train = train.drop_duplicates(x_cols)\n",
      "    train = train.astype('float64')\n",
      "    \n",
      "    all_data = pd.concat([all_data, train])\n",
      "    \n",
      "all_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "all_data = pd.DataFrame()\n",
      "\n",
      "param4 = fh+10\n",
      "\n",
      "for row in range(0,5704):\n",
      "    if row%500==0:\n",
      "        print row\n",
      "     #Take a row and transfrom it\n",
      "    ts_train = df_ts_rolling_sum.irow([row])\n",
      "    max_value = ts_train.max(axis=1).values[0]\n",
      "    time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "    #Transform the row's values to the [0,1] values\n",
      "    time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "    time_serie_table = time_serie_table/(1.0*max_value)\n",
      "    time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "    time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "    x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "    #Get train data\n",
      "    train = time_serie_table.irow(range(0,param3-param4))\n",
      "    #train = train.drop_duplicates(x_cols)\n",
      "    train = train.astype('float64')\n",
      "    \n",
      "    all_data = pd.concat([all_data, train])\n",
      "    \n",
      "all_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data.to_csv('all_data.csv')\n",
      "all_data = pd.read_csv('all_data.csv')\n",
      "all_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#all_data.to_csv('all_data.csv')\n",
      "all_data = pd.read_csv('all_data.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.utils import train_test_split\n",
      "from sklearn.metrics import roc_auc_score\n",
      "\n",
      "train_data, test_data, train_labels, test_labels = train_test_split(all_data[x_cols], all_data['y'], train_size=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"../notebooks/xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from rep.classifiers import XGBoostClassifier\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "from rep.classifiers import SklearnClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "# Using gradient boosting with default settings\n",
      "classifier = SklearnClassifier(GradientBoostingClassifier())\n",
      "#classifier = XGBoostClassifier(objective='binary:logitraw', eta=0.2, max_depth=6, subsample=0.8, n_estimators=50)\n",
      "\n",
      "%time classifier.fit(train_data, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.report import ClassificationReport\n",
      "from rep.data.storage import DataStorageDF, LabeledDataStorage\n",
      "\n",
      "lds_test = LabeledDataStorage(DataStorageDF(test_data), test_labels)\n",
      "#report_test_mc = ClassificationReport({'xgboost':xgboost}, lds_test)\n",
      "report_test = ClassificationReport({'classifiert':classifier}, lds_test)\n",
      "\n",
      "lds_train = LabeledDataStorage(DataStorageDF(train_data), train_labels)\n",
      "report_train = ClassificationReport({'classifier':classifiert}, lds_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.report import ClassificationReport\n",
      "from rep.data.storage import DataStorageDF, LabeledDataStorage\n",
      "\n",
      "lds_test = LabeledDataStorage(DataStorageDF(test_data), test_labels)\n",
      "#report_test_mc = ClassificationReport({'xgboost':xgboost}, lds_test)\n",
      "report_test = ClassificationReport({'classifiert':classifier}, lds_test)\n",
      "\n",
      "lds_train = LabeledDataStorage(DataStorageDF(train_data), train_labels)\n",
      "report_train = ClassificationReport({'classifier':classifier}, lds_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = xgboost.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = classifier.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"../notebooks/xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from rep.classifiers import XGBoostClassifier\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "from rep.classifiers import SklearnClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "# Using gradient boosting with default settings\n",
      "#classifier = SklearnClassifier(GradientBoostingClassifier())\n",
      "classifier = XGBoostClassifier(objective='binary:logitraw', eta=0.2, max_depth=6, subsample=0.8, n_estimators=50)\n",
      "\n",
      "%time classifier.fit(train_data, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.report import ClassificationReport\n",
      "from rep.data.storage import DataStorageDF, LabeledDataStorage\n",
      "\n",
      "lds_test = LabeledDataStorage(DataStorageDF(test_data), test_labels)\n",
      "#report_test_mc = ClassificationReport({'xgboost':xgboost}, lds_test)\n",
      "report_test = ClassificationReport({'classifiert':classifier}, lds_test)\n",
      "\n",
      "lds_train = LabeledDataStorage(DataStorageDF(train_data), train_labels)\n",
      "report_train = ClassificationReport({'classifier':classifier}, lds_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = classifier.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred[:,1])   \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_test.learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train.learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred[:,1])   \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_test.learning_curve( { 'roc_auc(test)':roc_auc}, steps=1)\n",
      "lc_train = report_train.learning_curve( { 'roc_auc(train)':roc_auc}, steps=1)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"../notebooks/xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from rep.classifiers import XGBoostClassifier\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "from rep.classifiers import SklearnClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "# Using gradient boosting with default settings\n",
      "#classifier = SklearnClassifier(GradientBoostingClassifier())\n",
      "classifier = XGBoostClassifier(objective='binary:logitraw', eta=0.2, max_depth=6, subsample=0.8, n_estimators=1500)\n",
      "\n",
      "%time classifier.fit(train_data, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.report import ClassificationReport\n",
      "from rep.data.storage import DataStorageDF, LabeledDataStorage\n",
      "\n",
      "lds_test = LabeledDataStorage(DataStorageDF(test_data), test_labels)\n",
      "#report_test_mc = ClassificationReport({'xgboost':xgboost}, lds_test)\n",
      "report_test = ClassificationReport({'classifiert':classifier}, lds_test)\n",
      "\n",
      "lds_train = LabeledDataStorage(DataStorageDF(train_data), train_labels)\n",
      "report_train = ClassificationReport({'classifier':classifier}, lds_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = classifier.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred[:,1])   \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_test.learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train.learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(15, 9))\n",
      "report_test.roc().plot()\n",
      "report_train.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = hist(report_test.prediction['classifier'][test_labels==1,1],  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(report_test.prediction['classifier'][test_labels!=1,1],  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.report import ClassificationReport\n",
      "from rep.data.storage import DataStorageDF, LabeledDataStorage\n",
      "\n",
      "lds_test = LabeledDataStorage(DataStorageDF(test_data), test_labels)\n",
      "#report_test_mc = ClassificationReport({'xgboost':xgboost}, lds_test)\n",
      "report_test = ClassificationReport({'classifier':classifier}, lds_test)\n",
      "\n",
      "lds_train = LabeledDataStorage(DataStorageDF(train_data), train_labels)\n",
      "report_train = ClassificationReport({'classifier':classifier}, lds_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = classifier.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(15, 9))\n",
      "report_test.roc().plot()\n",
      "report_train.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = hist(report_test.prediction['classifier'][test_labels==1,1],  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(report_test.prediction['classifier'][test_labels!=1,1],  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred[:,1])   \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_test.learning_curve( { 'roc_auc(test)':roc_auc}, steps=100)\n",
      "lc_train = report_train.learning_curve( { 'roc_auc(train)':roc_auc}, steps=100)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"../notebooks/xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from rep.classifiers import XGBoostClassifier\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "from rep.classifiers import SklearnClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "# Using gradient boosting with default settings\n",
      "classifier = SklearnClassifier(GradientBoostingClassifier())\n",
      "#classifier = XGBoostClassifier(objective='binary:logitraw', eta=0.2, max_depth=6, subsample=0.8, n_estimators=1500)\n",
      "\n",
      "%time classifier.fit(train_data, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.report import ClassificationReport\n",
      "from rep.data.storage import DataStorageDF, LabeledDataStorage\n",
      "\n",
      "lds_test = LabeledDataStorage(DataStorageDF(test_data), test_labels)\n",
      "#report_test_mc = ClassificationReport({'xgboost':xgboost}, lds_test)\n",
      "report_test = ClassificationReport({'classifier':classifier}, lds_test)\n",
      "\n",
      "lds_train = LabeledDataStorage(DataStorageDF(train_data), train_labels)\n",
      "report_train = ClassificationReport({'classifier':classifier}, lds_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = classifier.get_feature_importances()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred[:,1])   \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_test.learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train.learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(15, 9))\n",
      "report_test.roc().plot()\n",
      "report_train.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = hist(report_test.prediction['classifier'][test_labels==1,1],  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(report_test.prediction['classifier'][test_labels!=1,1],  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"../notebooks/xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from rep.classifiers import XGBoostClassifier\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "from rep.classifiers import SklearnClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "# Using gradient boosting with default settings\n",
      "classifier = SklearnClassifier(GradientBoostingClassifier(n_estimators=1000))\n",
      "#classifier = XGBoostClassifier(objective='binary:logitraw', eta=0.2, max_depth=6, subsample=0.8, n_estimators=1500)\n",
      "\n",
      "%time classifier.fit(train_data, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.report import ClassificationReport\n",
      "from rep.data.storage import DataStorageDF, LabeledDataStorage\n",
      "\n",
      "lds_test = LabeledDataStorage(DataStorageDF(test_data), test_labels)\n",
      "#report_test_mc = ClassificationReport({'xgboost':xgboost}, lds_test)\n",
      "report_test = ClassificationReport({'classifier':classifier}, lds_test)\n",
      "\n",
      "lds_train = LabeledDataStorage(DataStorageDF(train_data), train_labels)\n",
      "report_train = ClassificationReport({'classifier':classifier}, lds_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = classifier.get_feature_importances()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred[:,1])   \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_test.learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train.learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(15, 9))\n",
      "report_test.roc().plot()\n",
      "report_train.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = hist(report_test.prediction['classifier'][test_labels==1,1],  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(report_test.prediction['classifier'][test_labels!=1,1],  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"../notebooks/xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from rep.classifiers import XGBoostClassifier\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "from rep.classifiers import SklearnClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "# Using gradient boosting with default settings\n",
      "classifier = SklearnClassifier(GradientBoostingClassifier(n_estimators=3000, learning_rate=0.02, subsample=0.8, max_depth=6))\n",
      "#classifier = XGBoostClassifier(objective='binary:logitraw', eta=0.2, max_depth=6, subsample=0.8, n_estimators=1500)\n",
      "\n",
      "%time classifier.fit(train_data, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.report import ClassificationReport\n",
      "from rep.data.storage import DataStorageDF, LabeledDataStorage\n",
      "\n",
      "lds_test = LabeledDataStorage(DataStorageDF(test_data), test_labels)\n",
      "#report_test_mc = ClassificationReport({'xgboost':xgboost}, lds_test)\n",
      "report_test = ClassificationReport({'classifier':classifier}, lds_test)\n",
      "\n",
      "lds_train = LabeledDataStorage(DataStorageDF(train_data), train_labels)\n",
      "report_train = ClassificationReport({'classifier':classifier}, lds_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = classifier.get_feature_importances()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred[:,1])   \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_test.learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train.learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(15, 9))\n",
      "report_test.roc().plot()\n",
      "report_train.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = hist(report_test.pprediction['classifier'][test_labels==1,1],  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(report_test.prediction['classifier'][test_labels!=1,1],  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = hist(report_test.prediction['classifier'][test_labels==1,1],  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(report_test.prediction['classifier'][test_labels!=1,1],  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.utils import train_test_split\n",
      "from sklearn.metrics import roc_auc_score\n",
      "\n",
      "train_data, test_data, train_labels, test_labels = train_test_split(all_data[x_cols], all_data['y'], train_size=0.8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"../notebooks/xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from rep.classifiers import XGBoostClassifier\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "from rep.classifiers import SklearnClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "# Using gradient boosting with default settings\n",
      "classifier = SklearnClassifier(GradientBoostingClassifier(n_estimators=1000, learning_rate=0.1, subsample=0.8, max_depth=6))\n",
      "#classifier = XGBoostClassifier(objective='binary:logitraw', eta=0.2, max_depth=6, subsample=0.8, n_estimators=1500)\n",
      "\n",
      "%time classifier.fit(train_data, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.report import ClassificationReport\n",
      "from rep.data.storage import DataStorageDF, LabeledDataStorage\n",
      "\n",
      "lds_test = LabeledDataStorage(DataStorageDF(test_data), test_labels)\n",
      "#report_test_mc = ClassificationReport({'xgboost':xgboost}, lds_test)\n",
      "report_test = ClassificationReport({'classifier':classifier}, lds_test)\n",
      "\n",
      "lds_train = LabeledDataStorage(DataStorageDF(train_data), train_labels)\n",
      "report_train = ClassificationReport({'classifier':classifier}, lds_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = classifier.get_feature_importances()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred[:,1])   \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_test.learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train.learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(15, 9))\n",
      "report_test.roc().plot()\n",
      "report_train.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = hist(report_test.prediction['classifier'][test_labels==1,1],  histtype='bar', bins=20, alpha=0.5, label='signal')\n",
      "_ = hist(report_test.prediction['classifier'][test_labels!=1,1],  histtype='bar', bins=20, alpha=0.5, label='bck')\n",
      "legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ANN(rows_range, classifier):\n",
      "    \n",
      "    keys = [str(i) for i in range(1,param3+1)]\n",
      "    results = pd.DataFrame(columns=[\"Index\",\"Error_train\",\"Error_valid\", \"Error_test\"]+keys)\n",
      "\n",
      "    param4 = fh+10\n",
      "\n",
      "    for row in rows_range:\n",
      "        if row%500==0:\n",
      "            print row\n",
      "        #Take a row and transfrom it\n",
      "        ts_train = df_ts_rolling_sum.irow([row])\n",
      "        max_value = ts_train.max(axis=1).values[0]\n",
      "        time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "        #Transform the row's values to the [0,1] values\n",
      "        time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "        time_serie_table = time_serie_table/(1.0*max_value)\n",
      "        time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "        time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "        x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "        #Get train data\n",
      "        train = time_serie_table.irow(range(0,param3-param4))\n",
      "        #train = train.drop_duplicates(x_cols)\n",
      "        x_train = train[x_cols]\n",
      "        x_train = x_train.astype('float64')\n",
      "        y_train = train['y'].values\n",
      "        #Get validation data\n",
      "        x_valid = time_serie_table[x_cols].irow(range(param3-param4,param3-fh))\n",
      "        x_valid = x_valid.astype('float64')\n",
      "        y_valid = time_serie_table['y'].irow(range(param3-param4,param3-fh)).values\n",
      "        #Get test data\n",
      "        x_test = time_serie_table[x_cols].irow(range(param3-fh,param3))\n",
      "        x_test = x_test.astype('float64')\n",
      "        y_test = time_serie_table['y'].irow(range(param3-fh,param3)).values\n",
      "        \n",
      "\n",
      "        # Simulate network\n",
      "        out_train = classifier.predict_proba(x_train)[:,1]\n",
      "        out_valid = classifier.predict_proba(x_valid)[:,1]\n",
      "        out_test = classifier.predict_proba(x_test)[:,1]\n",
      "\n",
      "        plt.subplot(1,1,1)\n",
      "        plt.plot(np.concatenate((y_train,y_valid, y_test),axis=0), color='b')\n",
      "        plt.plot(np.concatenate((out_train,out_valid,out_test),axis=0), color='r')\n",
      "        plt.ylim(-1,1.5)\n",
      "        plt.show()\n",
      "\n",
      "\n",
      "        #Get results\n",
      "        index = ts_train.index[0]\n",
      "        error_train = mean_absolute_error(y_train, out_train)\n",
      "        error_valid = mean_absolute_error(y_valid, out_valid)\n",
      "        error_test = mean_absolute_error(y_test, out_test)\n",
      "        values = list(np.concatenate((out_train,out_valid,out_test)))\n",
      "        values = np.reshape(values,(len(values),))\n",
      "        data_dict = {\"Index\":[index],\"Error_train\":[error_train],\"Error_valid\":[error_valid], \"Error_test\":[error_test]}\n",
      "        for i in range(1,param3+1):\n",
      "            data_dict[str(i)] = [values[i-1]]\n",
      "        new_row = pd.DataFrame(data=data_dict)\n",
      "        results = results.append(new_row)\n",
      "        \n",
      "    #results.to_csv('/mnt/w76/notebook/datasets/mikhail/ann_res.csv',mode='a',header=False)\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "#!easy_install neurolab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = range(0,5)#5704\n",
      "# step = len(rows)/int(engines)\n",
      "# inputs = []\n",
      "# for i in range(0,engines-1):\n",
      "#     inp = rows[step*i:step*(i+1)]\n",
      "#     inputs.append(inp)\n",
      "# inp = rows[step*(i+1):]\n",
      "# inputs.append(inp)\n",
      "# len(inputs[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "# view = clients.load_balanced_view()\n",
      "# %time res = view.map(ANN, inputs)\n",
      "results = ANN(rows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "# view = clients.load_balanced_view()\n",
      "# %time res = view.map(ANN, inputs)\n",
      "results = ANN(rows, classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = range(0,5704)#5704\n",
      "# step = len(rows)/int(engines)\n",
      "# inputs = []\n",
      "# for i in range(0,engines-1):\n",
      "#     inp = rows[step*i:step*(i+1)]\n",
      "#     inputs.append(inp)\n",
      "# inp = rows[step*(i+1):]\n",
      "# inputs.append(inp)\n",
      "# len(inputs[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ANN(rows_range, classifier):\n",
      "    \n",
      "    keys = [str(i) for i in range(1,param3+1)]\n",
      "    results = pd.DataFrame(columns=[\"Index\",\"Error_train\",\"Error_valid\", \"Error_test\"]+keys)\n",
      "\n",
      "    param4 = fh+10\n",
      "\n",
      "    for row in rows_range:\n",
      "        if row%500==0:\n",
      "            print row\n",
      "        #Take a row and transfrom it\n",
      "        ts_train = df_ts_rolling_sum.irow([row])\n",
      "        max_value = ts_train.max(axis=1).values[0]\n",
      "        time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "        #Transform the row's values to the [0,1] values\n",
      "        time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "        time_serie_table = time_serie_table/(1.0*max_value)\n",
      "        time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "        time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "        x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "        #Get train data\n",
      "        train = time_serie_table.irow(range(0,param3-param4))\n",
      "        #train = train.drop_duplicates(x_cols)\n",
      "        x_train = train[x_cols]\n",
      "        x_train = x_train.astype('float64')\n",
      "        y_train = train['y'].values\n",
      "        #Get validation data\n",
      "        x_valid = time_serie_table[x_cols].irow(range(param3-param4,param3-fh))\n",
      "        x_valid = x_valid.astype('float64')\n",
      "        y_valid = time_serie_table['y'].irow(range(param3-param4,param3-fh)).values\n",
      "        #Get test data\n",
      "        x_test = time_serie_table[x_cols].irow(range(param3-fh,param3))\n",
      "        x_test = x_test.astype('float64')\n",
      "        y_test = time_serie_table['y'].irow(range(param3-fh,param3)).values\n",
      "        \n",
      "\n",
      "        # Simulate network\n",
      "        out_train = classifier.predict_proba(x_train)[:,1]\n",
      "        out_valid = classifier.predict_proba(x_valid)[:,1]\n",
      "        out_test = classifier.predict_proba(x_test)[:,1]\n",
      "\n",
      "#         plt.subplot(1,1,1)\n",
      "#         plt.plot(np.concatenate((y_train,y_valid, y_test),axis=0), color='b')\n",
      "#         plt.plot(np.concatenate((out_train,out_valid,out_test),axis=0), color='r')\n",
      "#         plt.ylim(-1,1.5)\n",
      "#         plt.show()\n",
      "\n",
      "\n",
      "        #Get results\n",
      "        index = ts_train.index[0]\n",
      "        error_train = mean_absolute_error(y_train, out_train)\n",
      "        error_valid = mean_absolute_error(y_valid, out_valid)\n",
      "        error_test = mean_absolute_error(y_test, out_test)\n",
      "        values = list(np.concatenate((out_train,out_valid,out_test)))\n",
      "        values = np.reshape(values,(len(values),))\n",
      "        data_dict = {\"Index\":[index],\"Error_train\":[error_train],\"Error_valid\":[error_valid], \"Error_test\":[error_test]}\n",
      "        for i in range(1,param3+1):\n",
      "            data_dict[str(i)] = [values[i-1]]\n",
      "        new_row = pd.DataFrame(data=data_dict)\n",
      "        results = results.append(new_row)\n",
      "        \n",
      "    #results.to_csv('/mnt/w76/notebook/datasets/mikhail/ann_res.csv',mode='a',header=False)\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "#!easy_install neurolab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# engines = len(clients.ids)\n",
      "# print engines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = range(0,5704)#5704\n",
      "# step = len(rows)/int(engines)\n",
      "# inputs = []\n",
      "# for i in range(0,engines-1):\n",
      "#     inp = rows[step*i:step*(i+1)]\n",
      "#     inputs.append(inp)\n",
      "# inp = rows[step*(i+1):]\n",
      "# inputs.append(inp)\n",
      "# len(inputs[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "# view = clients.load_balanced_view()\n",
      "# %time res = view.map(ANN, inputs)\n",
      "results = ANN(rows, classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "# results = pd.concat(res)\n",
      "results.to_csv('super_tree_res.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('super_tree_res.csv')\n",
      "results.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results['nb_peaks'] = [data['nb_peaks'].ix[int(i)] for i in results['Index'].values]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_ts_rolling_sum.columns\n",
      "#df_ts_rolling_sum = (df_ts_rolling_sum>0)*1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=2)*(results['Error_train']<=2)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "#non_nan_res[val_cols] = (non_nan_res[val_cols].values>=0.95)*1\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_values = df_ts_rolling_sum.max(axis=1)\n",
      "df_ts_rolling_sum_std = df_ts_rolling_sum.copy()\n",
      "for col in df_ts_rolling_sum.columns:\n",
      "    df_ts_rolling_sum_std[col] = df_ts_rolling_sum[col]/max_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]\n",
      "val_x = range(105-66,105)\n",
      "cols = range(13,105)\n",
      "a=0\n",
      "b=60\n",
      "N=b-a\n",
      "figure(figsize=(15, 5*(N//3+1)))\n",
      "for row in range(a,b):\n",
      "    subplot(N//3+1,3,row)\n",
      "    plt.plot(val_x,non_nan_res[val_cols].irow([row]).values[0], color='r', label='predict')\n",
      "    index = int(non_nan_res.irow([row])['Index'].values)\n",
      "    plt.plot(cols, (df_ts_rolling_sum_std[cols].xs(index)>0)*1, color='b', label='real')\n",
      "    plt.plot([param3+fh+ws,param3+fh+ws], [-1,1], color='black')\n",
      "    plt.plot([param3+fh-10+ws,param3+fh-10+ws], [-1,1], color='black')\n",
      "    plt.title('Index is '+str(index))\n",
      "    plt.xlim(ws,105)\n",
      "    plt.ylim(-1,1.1)\n",
      "    plt.legend(loc='best')\n",
      "    #plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print error hists\n",
      "figure(figsize=(15, 5))\n",
      "subplot(121)\n",
      "plt.hist(non_nan_res['Error_test'].values, color='r', bins=20, label='test', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_train'].values, color='b', bins=20, label='train', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_valid'].values, color='g', bins=20, label='valid', alpha=1, histtype='step')\n",
      "plt.title('Errors')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for the last point\n",
      "subplot(122)\n",
      "plt.hist(non_nan_res['66'].values, bins=10, label='last point')\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_last=[]\n",
      "y_valid_last = []\n",
      "for i in non_nan_res['Index']:\n",
      "    i=int(i)\n",
      "    cur_serie = df_ts_rolling_sum.xs(i).values\n",
      "    y_last.append(cur_serie[104-fh]/(1.0*cur_serie.max()))\n",
      "    y_valid_last.append(cur_serie[104-fh-13]/(1.0*cur_serie.max()))\n",
      "y_last = np.array(y_last)\n",
      "y_valid_last = np.array(y_valid_last)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "non_nan_res[y_last==0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "#print predict value for the last point\n",
      "subplot(2,2,1)\n",
      "values = non_nan_res['66'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,2)\n",
      "values = non_nan_res['Error_test'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_test')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,3)\n",
      "values = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,4)\n",
      "values = non_nan_res['Error_valid'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "y_score = non_nan_res['66'].values\n",
      "#y_score = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr, tpr)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetCoord(xedges, yedges, x, y):\n",
      "    for i in range(0,len(xedges)):\n",
      "        if x<xedges[i]:\n",
      "            break\n",
      "            \n",
      "    for j in range(0,len(yedges)):\n",
      "        if y<yedges[j]:\n",
      "            break\n",
      "    \n",
      "    return i-1,j-1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib.colors import LogNorm\n",
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(y_last, non_nan_res['66'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(y_valid_last, non_nan_res['53'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, y_valid_last[i], non_nan_res['53'].values[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[y_last==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[y_last!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(y_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(y_valid_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_value_predict_test = []\n",
      "avg_value_true_test = []\n",
      "avg_value_predict_valid = []\n",
      "avg_value_true_valid = []\n",
      "test_cols = [str(i) for i in range(53,66)]\n",
      "valid_cols = [str(i) for i in range(43,53)]\n",
      "\n",
      "for row in range(0,non_nan_res.shape[0]):\n",
      "    avg_val_pred_test = non_nan_res[test_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_test.append(avg_val_pred_test)\n",
      "    avg_val_true_test = df_ts_rolling_sum_std[range(92,105)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_test.append(avg_val_true_test)\n",
      "    \n",
      "    avg_val_pred_valid = non_nan_res[valid_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_valid.append(avg_val_pred_valid)\n",
      "    avg_val_true_valid = df_ts_rolling_sum_std[range(82,92)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_valid.append(avg_val_true_valid)\n",
      "    \n",
      "avg_value_predict_test = np.array(avg_value_predict_test)\n",
      "avg_value_true_test = np.array(avg_value_true_test)\n",
      "avg_value_predict_valid = np.array(avg_value_predict_valid)\n",
      "avg_value_true_valid = np.array(avg_value_true_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "\n",
      "subplot(2,2,1)\n",
      "values = avg_value_predict_test\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,2)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error valid')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,3)\n",
      "values = (avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,4)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true_avg = (avg_value_true_test>0)*1\n",
      "#y_score_avg = 0.5*(avg_value_predict_test+2.0)\n",
      "y_score_avg = 0.5*(avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)+0.5\n",
      "fpr_avg, tpr_avg, _ = roc_curve(y_true_avg, y_score_avg, pos_label=None, sample_weight=None)\n",
      "roc_auc_avg = auc(fpr_avg, tpr_avg)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr_avg, tpr_avg)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc_avg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(avg_value_true_test, avg_value_predict_test, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(avg_value_true_valid, avg_value_predict_valid, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, avg_value_true_valid[i], avg_value_predict_valid[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[avg_value_true_test==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[avg_value_true_test!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(avg_value_true_test, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(avg_value_true_valid, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (avg_value_true_test>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('tree_res.csv')\n",
      "results['nb_peaks'] = [data['nb_peaks'].ix[int(i)] for i in results['Index'].values]\n",
      "\n",
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=0.5)*(results['Error_train']<=0.05)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_values = df_ts_rolling_sum.max(axis=1)\n",
      "df_ts_rolling_sum_std = df_ts_rolling_sum.copy()\n",
      "for col in df_ts_rolling_sum.columns:\n",
      "    df_ts_rolling_sum_std[col] = df_ts_rolling_sum[col]/max_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('super_tree_res.csv')\n",
      "results['nb_peaks'] = [data['nb_peaks'].ix[int(i)] for i in results['Index'].values]\n",
      "\n",
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=0.5)*(results['Error_train']<=0.05)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_values = df_ts_rolling_sum.max(axis=1)\n",
      "df_ts_rolling_sum_std = df_ts_rolling_sum.copy()\n",
      "for col in df_ts_rolling_sum.columns:\n",
      "    df_ts_rolling_sum_std[col] = df_ts_rolling_sum[col]/max_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('super_tree_res.csv')\n",
      "results['nb_peaks'] = [data['nb_peaks'].ix[int(i)] for i in results['Index'].values]\n",
      "\n",
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=0.5)*(results['Error_train']<=0.5)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('super_tree_res.csv')\n",
      "results['nb_peaks'] = [data['nb_peaks'].ix[int(i)] for i in results['Index'].values]\n",
      "\n",
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=0.4)*(results['Error_train']<=0.5)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_values = df_ts_rolling_sum.max(axis=1)\n",
      "df_ts_rolling_sum_std = df_ts_rolling_sum.copy()\n",
      "for col in df_ts_rolling_sum.columns:\n",
      "    df_ts_rolling_sum_std[col] = df_ts_rolling_sum[col]/max_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]\n",
      "val_x = range(105-66,105)\n",
      "cols = range(13,105)\n",
      "a=0\n",
      "b=60\n",
      "N=b-a\n",
      "figure(figsize=(15, 5*(N//3+1)))\n",
      "for row in range(a,b):\n",
      "    subplot(N//3+1,3,row)\n",
      "    plt.plot(val_x,non_nan_res[val_cols].irow([row]).values[0], color='r', label='predict')\n",
      "    index = int(non_nan_res.irow([row])['Index'].values)\n",
      "    plt.plot(cols, df_ts_rolling_sum_std[cols].xs(index), color='b', label='real')\n",
      "    plt.plot([param3+fh+ws,param3+fh+ws], [-1,1], color='black')\n",
      "    plt.plot([param3+fh-10+ws,param3+fh-10+ws], [-1,1], color='black')\n",
      "    plt.title('Index is '+str(index))\n",
      "    plt.xlim(ws,105)\n",
      "    plt.ylim(-1,1.1)\n",
      "    plt.legend(loc='best')\n",
      "    #plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print error hists\n",
      "figure(figsize=(15, 5))\n",
      "subplot(121)\n",
      "plt.hist(non_nan_res['Error_test'].values, color='r', bins=20, label='test', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_train'].values, color='b', bins=20, label='train', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_valid'].values, color='g', bins=20, label='valid', alpha=1, histtype='step')\n",
      "plt.title('Errors')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for the last point\n",
      "subplot(122)\n",
      "plt.hist(non_nan_res['66'].values, bins=10, label='last point')\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_last=[]\n",
      "y_valid_last = []\n",
      "for i in non_nan_res['Index']:\n",
      "    i=int(i)\n",
      "    cur_serie = df_ts_rolling_sum.xs(i).values\n",
      "    y_last.append(cur_serie[104-fh]/(1.0*cur_serie.max()))\n",
      "    y_valid_last.append(cur_serie[104-fh-13]/(1.0*cur_serie.max()))\n",
      "y_last = np.array(y_last)\n",
      "y_valid_last = np.array(y_valid_last)\n",
      "non_nan_res[y_last==0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "#print predict value for the last point\n",
      "subplot(2,2,1)\n",
      "values = non_nan_res['66'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,2)\n",
      "values = non_nan_res['Error_test'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_test')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,3)\n",
      "values = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,4)\n",
      "values = non_nan_res['Error_valid'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "#y_score = non_nan_res['66'].values\n",
      "y_score = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr, tpr)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(y_last, non_nan_res['66'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(y_valid_last, non_nan_res['53'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, y_valid_last[i], non_nan_res['53'].values[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[y_last==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[y_last!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(y_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(y_valid_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_value_predict_test = []\n",
      "avg_value_true_test = []\n",
      "avg_value_predict_valid = []\n",
      "avg_value_true_valid = []\n",
      "test_cols = [str(i) for i in range(53,66)]\n",
      "valid_cols = [str(i) for i in range(43,53)]\n",
      "\n",
      "for row in range(0,non_nan_res.shape[0]):\n",
      "    avg_val_pred_test = non_nan_res[test_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_test.append(avg_val_pred_test)\n",
      "    avg_val_true_test = df_ts_rolling_sum_std[range(92,105)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_test.append(avg_val_true_test)\n",
      "    \n",
      "    avg_val_pred_valid = non_nan_res[valid_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_valid.append(avg_val_pred_valid)\n",
      "    avg_val_true_valid = df_ts_rolling_sum_std[range(82,92)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_valid.append(avg_val_true_valid)\n",
      "    \n",
      "avg_value_predict_test = np.array(avg_value_predict_test)\n",
      "avg_value_true_test = np.array(avg_value_true_test)\n",
      "avg_value_predict_valid = np.array(avg_value_predict_valid)\n",
      "avg_value_true_valid = np.array(avg_value_true_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "\n",
      "subplot(2,2,1)\n",
      "values = avg_value_predict_test\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,2)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error valid')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,3)\n",
      "values = (avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,4)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true_avg = (avg_value_true_test>0)*1\n",
      "#y_score_avg = 0.5*(avg_value_predict_test+2.0)\n",
      "y_score_avg = 0.5*(avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)+0.5\n",
      "fpr_avg, tpr_avg, _ = roc_curve(y_true_avg, y_score_avg, pos_label=None, sample_weight=None)\n",
      "roc_auc_avg = auc(fpr_avg, tpr_avg)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr_avg, tpr_avg)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc_avg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(avg_value_true_test, avg_value_predict_test, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(avg_value_true_valid, avg_value_predict_valid, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, avg_value_true_valid[i], avg_value_predict_valid[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[avg_value_true_test==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[avg_value_true_test!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(avg_value_true_test, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(avg_value_true_valid, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (avg_value_true_test>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report_test.roc().plot()\n",
      "report_train.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "import inspect\n",
      "import os\n",
      "import sys\n",
      "\n",
      "code_path = os.path.join(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"../notebooks/xgboost-master/wrapper\")\n",
      "sys.path.append(code_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "from rep.classifiers import XGBoostClassifier\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "from rep.classifiers import SklearnClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "# Using gradient boosting with default settings\n",
      "classifier = SklearnClassifier(GradientBoostingClassifier(n_estimators=1000, learning_rate=0.2, subsample=0.8, max_depth=6))\n",
      "#classifier = XGBoostClassifier(objective='binary:logitraw', eta=0.2, max_depth=6, subsample=0.8, n_estimators=1500)\n",
      "\n",
      "%time classifier.fit(train_data, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rep.report import ClassificationReport\n",
      "from rep.data.storage import DataStorageDF, LabeledDataStorage\n",
      "\n",
      "lds_test = LabeledDataStorage(DataStorageDF(test_data), test_labels)\n",
      "#report_test_mc = ClassificationReport({'xgboost':xgboost}, lds_test)\n",
      "report_test = ClassificationReport({'classifier':classifier}, lds_test)\n",
      "\n",
      "lds_train = LabeledDataStorage(DataStorageDF(train_data), train_labels)\n",
      "report_train = ClassificationReport({'classifier':classifier}, lds_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = classifier.get_feature_importances()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred[:,1])   \n",
      "\n",
      "figure(figsize=(10, 6))\n",
      "lc_test = report_test.learning_curve( { 'roc_auc(test)':roc_auc}, steps=10)\n",
      "lc_train = report_train.learning_curve( { 'roc_auc(train)':roc_auc}, steps=10)\n",
      "lc_test.plots[0].plot()\n",
      "lc_train.plots[0].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "figure(figsize=(5, 3))\n",
      "report_test.roc().plot()\n",
      "report_train.roc().plot()\n",
      "legend(['test', 'train'], loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ANN(rows_range, classifier):\n",
      "    \n",
      "    keys = [str(i) for i in range(1,param3+1)]\n",
      "    results = pd.DataFrame(columns=[\"Index\",\"Error_train\",\"Error_valid\", \"Error_test\"]+keys)\n",
      "\n",
      "    param4 = fh+10\n",
      "\n",
      "    for row in rows_range:\n",
      "        if row%500==0:\n",
      "            print row\n",
      "        #Take a row and transfrom it\n",
      "        ts_train = df_ts_rolling_sum.irow([row])\n",
      "        max_value = ts_train.max(axis=1).values[0]\n",
      "        time_serie_table, time_serie_4predict = N_M_Transformation_Bolean(ts_train, ws, fh)\n",
      "        #Transform the row's values to the [0,1] values\n",
      "        time_serie_table['y'] = max_value*time_serie_table['y'].values\n",
      "        time_serie_table = time_serie_table/(1.0*max_value)\n",
      "        time_serie_table['y'] = map(int, time_serie_table['y'].values)\n",
      "        time_serie_4predict = time_serie_4predict/(1.0*max_value)\n",
      "        x_cols = ['x'+str(i) for i in range(1,ws+1)]\n",
      "        #Get train data\n",
      "        train = time_serie_table.irow(range(0,param3-param4))\n",
      "        #train = train.drop_duplicates(x_cols)\n",
      "        x_train = train[x_cols]\n",
      "        x_train = x_train.astype('float64')\n",
      "        y_train = train['y'].values\n",
      "        #Get validation data\n",
      "        x_valid = time_serie_table[x_cols].irow(range(param3-param4,param3-fh))\n",
      "        x_valid = x_valid.astype('float64')\n",
      "        y_valid = time_serie_table['y'].irow(range(param3-param4,param3-fh)).values\n",
      "        #Get test data\n",
      "        x_test = time_serie_table[x_cols].irow(range(param3-fh,param3))\n",
      "        x_test = x_test.astype('float64')\n",
      "        y_test = time_serie_table['y'].irow(range(param3-fh,param3)).values\n",
      "        \n",
      "\n",
      "        # Simulate network\n",
      "        out_train = classifier.predict_proba(x_train)[:,1]\n",
      "        out_valid = classifier.predict_proba(x_valid)[:,1]\n",
      "        out_test = classifier.predict_proba(x_test)[:,1]\n",
      "\n",
      "#         plt.subplot(1,1,1)\n",
      "#         plt.plot(np.concatenate((y_train,y_valid, y_test),axis=0), color='b')\n",
      "#         plt.plot(np.concatenate((out_train,out_valid,out_test),axis=0), color='r')\n",
      "#         plt.ylim(-1,1.5)\n",
      "#         plt.show()\n",
      "\n",
      "\n",
      "        #Get results\n",
      "        index = ts_train.index[0]\n",
      "        error_train = mean_absolute_error(y_train, out_train)\n",
      "        error_valid = mean_absolute_error(y_valid, out_valid)\n",
      "        error_test = mean_absolute_error(y_test, out_test)\n",
      "        values = list(np.concatenate((out_train,out_valid,out_test)))\n",
      "        values = np.reshape(values,(len(values),))\n",
      "        data_dict = {\"Index\":[index],\"Error_train\":[error_train],\"Error_valid\":[error_valid], \"Error_test\":[error_test]}\n",
      "        for i in range(1,param3+1):\n",
      "            data_dict[str(i)] = [values[i-1]]\n",
      "        new_row = pd.DataFrame(data=data_dict)\n",
      "        results = results.append(new_row)\n",
      "        \n",
      "    #results.to_csv('/mnt/w76/notebook/datasets/mikhail/ann_res.csv',mode='a',header=False)\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%px\n",
      "#!easy_install neurolab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# engines = len(clients.ids)\n",
      "# print engines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = range(0,5704)#5704\n",
      "# step = len(rows)/int(engines)\n",
      "# inputs = []\n",
      "# for i in range(0,engines-1):\n",
      "#     inp = rows[step*i:step*(i+1)]\n",
      "#     inputs.append(inp)\n",
      "# inp = rows[step*(i+1):]\n",
      "# inputs.append(inp)\n",
      "# len(inputs[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "# view = clients.load_balanced_view()\n",
      "# %time res = view.map(ANN, inputs)\n",
      "results = ANN(rows, classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "# results = pd.concat(res)\n",
      "results.to_csv('super_tree_res.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('super_tree_res.csv')\n",
      "results.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 196
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('super_tree_res.csv')\n",
      "results.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results['nb_peaks'] = [data['nb_peaks'].ix[int(i)] for i in results['Index'].values]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_ts_rolling_sum.columns\n",
      "#df_ts_rolling_sum = (df_ts_rolling_sum>0)*1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=2)*(results['Error_train']<=2)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "#non_nan_res[val_cols] = (non_nan_res[val_cols].values>=0.95)*1\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_values = df_ts_rolling_sum.max(axis=1)\n",
      "df_ts_rolling_sum_std = df_ts_rolling_sum.copy()\n",
      "for col in df_ts_rolling_sum.columns:\n",
      "    df_ts_rolling_sum_std[col] = df_ts_rolling_sum[col]/max_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]\n",
      "val_x = range(105-66,105)\n",
      "cols = range(13,105)\n",
      "a=0\n",
      "b=60\n",
      "N=b-a\n",
      "figure(figsize=(15, 5*(N//3+1)))\n",
      "for row in range(a,b):\n",
      "    subplot(N//3+1,3,row)\n",
      "    plt.plot(val_x,non_nan_res[val_cols].irow([row]).values[0], color='r', label='predict')\n",
      "    index = int(non_nan_res.irow([row])['Index'].values)\n",
      "    plt.plot(cols, (df_ts_rolling_sum_std[cols].xs(index)>0)*1, color='b', label='real')\n",
      "    plt.plot([param3+fh+ws,param3+fh+ws], [-1,1], color='black')\n",
      "    plt.plot([param3+fh-10+ws,param3+fh-10+ws], [-1,1], color='black')\n",
      "    plt.title('Index is '+str(index))\n",
      "    plt.xlim(ws,105)\n",
      "    plt.ylim(-1,1.1)\n",
      "    plt.legend(loc='best')\n",
      "    #plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print error hists\n",
      "figure(figsize=(15, 5))\n",
      "subplot(121)\n",
      "plt.hist(non_nan_res['Error_test'].values, color='r', bins=20, label='test', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_train'].values, color='b', bins=20, label='train', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_valid'].values, color='g', bins=20, label='valid', alpha=1, histtype='step')\n",
      "plt.title('Errors')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for the last point\n",
      "subplot(122)\n",
      "plt.hist(non_nan_res['66'].values, bins=10, label='last point')\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 203
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_last=[]\n",
      "y_valid_last = []\n",
      "for i in non_nan_res['Index']:\n",
      "    i=int(i)\n",
      "    cur_serie = df_ts_rolling_sum.xs(i).values\n",
      "    y_last.append(cur_serie[104-fh]/(1.0*cur_serie.max()))\n",
      "    y_valid_last.append(cur_serie[104-fh-13]/(1.0*cur_serie.max()))\n",
      "y_last = np.array(y_last)\n",
      "y_valid_last = np.array(y_valid_last)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 204
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "non_nan_res[y_last==0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "#print predict value for the last point\n",
      "subplot(2,2,1)\n",
      "values = non_nan_res['66'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,2)\n",
      "values = non_nan_res['Error_test'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_test')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,3)\n",
      "values = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,4)\n",
      "values = non_nan_res['Error_valid'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "y_score = non_nan_res['66'].values\n",
      "#y_score = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr, tpr)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetCoord(xedges, yedges, x, y):\n",
      "    for i in range(0,len(xedges)):\n",
      "        if x<xedges[i]:\n",
      "            break\n",
      "            \n",
      "    for j in range(0,len(yedges)):\n",
      "        if y<yedges[j]:\n",
      "            break\n",
      "    \n",
      "    return i-1,j-1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib.colors import LogNorm\n",
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(y_last, non_nan_res['66'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(y_valid_last, non_nan_res['53'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, y_valid_last[i], non_nan_res['53'].values[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[y_last==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[y_last!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(y_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(y_valid_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_value_predict_test = []\n",
      "avg_value_true_test = []\n",
      "avg_value_predict_valid = []\n",
      "avg_value_true_valid = []\n",
      "test_cols = [str(i) for i in range(53,66)]\n",
      "valid_cols = [str(i) for i in range(43,53)]\n",
      "\n",
      "for row in range(0,non_nan_res.shape[0]):\n",
      "    avg_val_pred_test = non_nan_res[test_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_test.append(avg_val_pred_test)\n",
      "    avg_val_true_test = df_ts_rolling_sum_std[range(92,105)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_test.append(avg_val_true_test)\n",
      "    \n",
      "    avg_val_pred_valid = non_nan_res[valid_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_valid.append(avg_val_pred_valid)\n",
      "    avg_val_true_valid = df_ts_rolling_sum_std[range(82,92)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_valid.append(avg_val_true_valid)\n",
      "    \n",
      "avg_value_predict_test = np.array(avg_value_predict_test)\n",
      "avg_value_true_test = np.array(avg_value_true_test)\n",
      "avg_value_predict_valid = np.array(avg_value_predict_valid)\n",
      "avg_value_true_valid = np.array(avg_value_true_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "\n",
      "subplot(2,2,1)\n",
      "values = avg_value_predict_test\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,2)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error valid')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,3)\n",
      "values = (avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,4)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 211
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true_avg = (avg_value_true_test>0)*1\n",
      "#y_score_avg = 0.5*(avg_value_predict_test+2.0)\n",
      "y_score_avg = 0.5*(avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)+0.5\n",
      "fpr_avg, tpr_avg, _ = roc_curve(y_true_avg, y_score_avg, pos_label=None, sample_weight=None)\n",
      "roc_auc_avg = auc(fpr_avg, tpr_avg)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr_avg, tpr_avg)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc_avg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(avg_value_true_test, avg_value_predict_test, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(avg_value_true_valid, avg_value_predict_valid, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, avg_value_true_valid[i], avg_value_predict_valid[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[avg_value_true_test==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[avg_value_true_test!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(avg_value_true_test, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(avg_value_true_valid, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (avg_value_true_test>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = pd.read_csv('super_tree_res.csv')\n",
      "results['nb_peaks'] = [data['nb_peaks'].ix[int(i)] for i in results['Index'].values]\n",
      "\n",
      "val_cols = [str(i) for i in range(1,67)]  \n",
      "non_nan_res = results[(pd.isnull(results).sum(axis=1)==0)*(results['Error_valid']<=0.4)*(results['Error_train']<=0.5)*\\\n",
      "                      (results['nb_peaks']>=0)]\n",
      "non_nan_res.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_values = df_ts_rolling_sum.max(axis=1)\n",
      "df_ts_rolling_sum_std = df_ts_rolling_sum.copy()\n",
      "for col in df_ts_rolling_sum.columns:\n",
      "    df_ts_rolling_sum_std[col] = df_ts_rolling_sum[col]/max_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_cols = [str(i) for i in range(1,67)]\n",
      "val_x = range(105-66,105)\n",
      "cols = range(13,105)\n",
      "a=0\n",
      "b=60\n",
      "N=b-a\n",
      "figure(figsize=(15, 5*(N//3+1)))\n",
      "for row in range(a,b):\n",
      "    subplot(N//3+1,3,row)\n",
      "    plt.plot(val_x,non_nan_res[val_cols].irow([row]).values[0], color='r', label='predict')\n",
      "    index = int(non_nan_res.irow([row])['Index'].values)\n",
      "    plt.plot(cols, df_ts_rolling_sum_std[cols].xs(index), color='b', label='real')\n",
      "    plt.plot([param3+fh+ws,param3+fh+ws], [-1,1], color='black')\n",
      "    plt.plot([param3+fh-10+ws,param3+fh-10+ws], [-1,1], color='black')\n",
      "    plt.title('Index is '+str(index))\n",
      "    plt.xlim(ws,105)\n",
      "    plt.ylim(-1,1.1)\n",
      "    plt.legend(loc='best')\n",
      "    #plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print error hists\n",
      "figure(figsize=(15, 5))\n",
      "subplot(121)\n",
      "plt.hist(non_nan_res['Error_test'].values, color='r', bins=20, label='test', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_train'].values, color='b', bins=20, label='train', alpha=1, histtype='step')\n",
      "plt.hist(non_nan_res['Error_valid'].values, color='g', bins=20, label='valid', alpha=1, histtype='step')\n",
      "plt.title('Errors')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for the last point\n",
      "subplot(122)\n",
      "plt.hist(non_nan_res['66'].values, bins=10, label='last point')\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_last=[]\n",
      "y_valid_last = []\n",
      "for i in non_nan_res['Index']:\n",
      "    i=int(i)\n",
      "    cur_serie = df_ts_rolling_sum.xs(i).values\n",
      "    y_last.append(cur_serie[104-fh]/(1.0*cur_serie.max()))\n",
      "    y_valid_last.append(cur_serie[104-fh-13]/(1.0*cur_serie.max()))\n",
      "y_last = np.array(y_last)\n",
      "y_valid_last = np.array(y_valid_last)\n",
      "non_nan_res[y_last==0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "#print predict value for the last point\n",
      "subplot(2,2,1)\n",
      "values = non_nan_res['66'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,2)\n",
      "values = non_nan_res['Error_test'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_test')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,3)\n",
      "values = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()\n",
      "\n",
      "#print predict value for 66th week\n",
      "subplot(2,2,4)\n",
      "values = non_nan_res['Error_valid'].values\n",
      "plt.hist(values[y_last==0], bins=10, label='y_last=0', alpha=0.5)\n",
      "plt.hist(values[y_last!=0], bins=10, label='y_last!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "#y_score = non_nan_res['66'].values\n",
      "y_score = non_nan_res['Error_valid'].values/(non_nan_res['66'].values+2.0)\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr, tpr)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(y_last, non_nan_res['66'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(y_valid_last, non_nan_res['53'].values, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, y_valid_last[i], non_nan_res['53'].values[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[y_last==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[y_last!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(y_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(y_valid_last, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (y_last>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_value_predict_test = []\n",
      "avg_value_true_test = []\n",
      "avg_value_predict_valid = []\n",
      "avg_value_true_valid = []\n",
      "test_cols = [str(i) for i in range(53,66)]\n",
      "valid_cols = [str(i) for i in range(43,53)]\n",
      "\n",
      "for row in range(0,non_nan_res.shape[0]):\n",
      "    avg_val_pred_test = non_nan_res[test_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_test.append(avg_val_pred_test)\n",
      "    avg_val_true_test = df_ts_rolling_sum_std[range(92,105)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_test.append(avg_val_true_test)\n",
      "    \n",
      "    avg_val_pred_valid = non_nan_res[valid_cols].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_predict_valid.append(avg_val_pred_valid)\n",
      "    avg_val_true_valid = df_ts_rolling_sum_std[range(82,92)].irow([row]).mean(axis=1).values[0]\n",
      "    avg_value_true_valid.append(avg_val_true_valid)\n",
      "    \n",
      "avg_value_predict_test = np.array(avg_value_predict_test)\n",
      "avg_value_true_test = np.array(avg_value_true_test)\n",
      "avg_value_predict_valid = np.array(avg_value_predict_valid)\n",
      "avg_value_true_valid = np.array(avg_value_true_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 10))\n",
      "\n",
      "subplot(2,2,1)\n",
      "values = avg_value_predict_test\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Predict values')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,2)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error valid')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,3)\n",
      "values = (avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Relative valid error')\n",
      "plt.legend(loc='best')\n",
      "\n",
      "subplot(2,2,4)\n",
      "values = avg_value_predict_valid - avg_value_true_valid\n",
      "plt.hist(values[avg_value_true_test==0], bins=20, label='avg_value_true=0', alpha=0.5)\n",
      "plt.hist(values[avg_value_true_test!=0], bins=20, label='avg_value_true!=0', alpha=0.5)\n",
      "plt.title('Error_valid')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 223
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true_avg = (avg_value_true_test>0)*1\n",
      "#y_score_avg = 0.5*(avg_value_predict_test+2.0)\n",
      "y_score_avg = 0.5*(avg_value_predict_valid - avg_value_true_valid)/(avg_value_predict_test+2.0)+0.5\n",
      "fpr_avg, tpr_avg, _ = roc_curve(y_true_avg, y_score_avg, pos_label=None, sample_weight=None)\n",
      "roc_auc_avg = auc(fpr_avg, tpr_avg)\n",
      "\n",
      "figure(figsize=(15, 5))\n",
      "subplot(1,2,1)\n",
      "plt.plot(fpr_avg, tpr_avg)\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "print 'ROC AUC is ', roc_auc_avg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(20, 10))\n",
      "\n",
      "subplot(231)\n",
      "plt.hist2d(avg_value_true_test, avg_value_predict_test, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('Predicted value of the last point in test')\n",
      "plt.title('LogNormed histogram for test')\n",
      "\n",
      "subplot(232)\n",
      "(counts, xedges, yedges, Image) = plt.hist2d(avg_value_true_valid, avg_value_predict_valid, norm=LogNorm(), bins=20)\n",
      "plt.colorbar()\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('Predicted value of the last point in valid')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "\n",
      "counts_std = counts/counts.max()\n",
      "y_score = []\n",
      "for i in range(0, len(y_last)):\n",
      "    x,y = GetCoord(xedges, yedges, avg_value_true_valid[i], avg_value_predict_valid[i])\n",
      "    y_score.append(1-counts_std[x,y])\n",
      "y_score = np.array(y_score)\n",
      "\n",
      "subplot(2,3,3)\n",
      "plt.hist(y_score[avg_value_true_test==0], label='y_true=0', alpha=0.5)\n",
      "plt.hist(y_score[avg_value_true_test!=0], label = 'y_true!=0', alpha=0.5)\n",
      "plt.legend(loc='best')\n",
      "plt.title(\"y_score distribution\")\n",
      "\n",
      "subplot(234)\n",
      "plt.hist2d(avg_value_true_test, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in test')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for test')\n",
      "plt.colorbar()\n",
      "\n",
      "subplot(235)\n",
      "plt.hist2d(avg_value_true_valid, y_score, norm=LogNorm(), bins=20)\n",
      "plt.xlabel('Value of the last point in valid')\n",
      "plt.ylabel('y_score')\n",
      "plt.title('LogNormed histogram for valid')\n",
      "plt.colorbar()\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "y_true = (avg_value_true_test>0)*1\n",
      "fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "subplot(2,3,6)\n",
      "plt.plot(fpr, tpr, label='ROC auc = '+str(roc_auc))\n",
      "plt.title('ROC curve')\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# #get variables\n",
      "# import ipykee\n",
      "# keeper = ipykee.Keeper(\"C._NewFeatures\")\n",
      "# session = keeper[\"C2.1.1._RelativeNewFeatures_78weeks\"]\n",
      "# vars_c21 = session.get_variables(\"master\")\n",
      "# #variables.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "#ipykee.create_project(project_name=\"D._UsageForecast\", repository=\"git@github.com:hushchyn-mikhail/CERN_Time_Series.git\")\n",
      "session = ipykee.Session(project_name=\"D._UsageForecast\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#session.commit(\"Trees. Report 1.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 228
    }
   ],
   "metadata": {}
  }
 ]
}