{
 "metadata": {
  "name": "/ipykee/workdir/tmpR4kskF/B"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load original data\n",
      "data = pd.read_excel('../../popularity-728days_my.xls')\n",
      "data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Select data\n",
      "selection = ((data['Now'] - data['Creation-week']) > 52)&((data['Now'] - data['FirstUsage']) > 52)&((data[52] - data[1]) != 0)\n",
      "data_sel = data[selection].copy()\n",
      "#data_sel = data.copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Transform string features to digits\n",
      "cols_str = ['Configuration', 'ProcessingPass', 'FileType', 'Storage']\n",
      "df_str = data_sel.get(cols_str)\n",
      "\n",
      "for col in cols_str:\n",
      "    unique = np.unique(df_str[col])\n",
      "    index = range(0, len(unique))\n",
      "    mapping = dict(zip(unique, index))\n",
      "    df_str = df_str.replace({col:mapping})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get normed series\n",
      "cols_series = range(1, 53)\n",
      "df_series = data_sel.get(cols_series).copy()\n",
      "df_c = data_sel.get(cols_series).copy()\n",
      "\n",
      "df_series[0] = 0\n",
      "for i in range(2, 53):\n",
      "    df_series[i] = df_c[i] - df_c[i-1]\n",
      "\n",
      "df_series = pd.rolling_mean(df_series, window = 26, axis = 1).get(range(26,53))\n",
      "\n",
      "\n",
      "mins = df_series.min(axis = 1)\n",
      "maxs = df_series.max(axis = 1)\n",
      "\n",
      "for col in range(26,53):\n",
      "    df_series[col] = (df_series[col]-mins)/(maxs-mins+1)\n",
      "\n",
      "#Add new features\n",
      "first_usage = np.nan_to_num(df_c[df_c != 0].idxmin(axis = 1).values)\n",
      "last_usage = np.nan_to_num(df_c[df_c > 0].idxmax(axis = 1).values)\n",
      "interval_usage = last_usage - first_usage\n",
      "\n",
      "df_series['First'] = first_usage\n",
      "df_series['Last'] = last_usage\n",
      "df_series['Interval'] = interval_usage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df_series"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get other features\n",
      "cols_other = ['Type', 'Creation-week', 'NbLFN', 'LFNSize', 'NbDisk',\n",
      "              'DiskSize', 'NbTape', 'TapeSize', 'NbArchived', 'ArchivedSize', 'Nb Replicas', 'Nb ArchReps', \n",
      "              'FirstUsage', 'LastUsage', 'Now']\n",
      "df_other = data_sel.get(cols_other)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Label the data\n",
      "labels = ((data_sel[104] - data_sel[52]) == 0)*1\n",
      "labels.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Concatenate all data sets\n",
      "data_use = pd.concat([df_str,df_series,df_other], axis = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Preparing signal and background data for classifier\n",
      "data_sig = data_use[labels == 1]\n",
      "data_bck = data_use[labels == 0]\n",
      "\n",
      "#save signal and background data for classifier\n",
      "data_sig.to_csv('../../Cern_Time_Series/Classification/data_sig_rolling_mean_original_classifier_10_13.csv')\n",
      "data_bck.to_csv('../../Cern_Time_Series/Classification/data_bck_rolling_mean_original_classifier_10_13.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert data to DataStorage\n",
      "from cern_utils import converter_csv\n",
      "\n",
      "#Load signal and background data\n",
      "signal_data = converter_csv.load_from_csv('../../Cern_Time_Series/Classification/data_sig_rolling_mean_original_classifier_10_13.csv', sep=',')\n",
      "bck_data = converter_csv.load_from_csv('../../Cern_Time_Series/Classification/data_bck_rolling_mean_original_classifier_10_13.csv', sep=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get train and test data\n",
      "signal_train, signal_test = signal_data.get_train_test(train_size=0.8)\n",
      "bck_train, bck_test = bck_data.get_train_test(train_size=0.8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = signal_data.columns\n",
      "print columns\n",
      "\n",
      "#select variables for classifier\n",
      "\"\"\"\n",
      "variables = [u'Configuration', u'ProcessingPass', u'FileType', u'Storage', u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', \n",
      "             u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'23', u'24', u'25', \n",
      "             u'26', u'27', u'28', u'29', u'30', u'31', u'32', u'33', u'34', u'35', u'36', u'37', u'38', u'39', u'40', u'41', \n",
      "             u'42', u'43', u'44', u'45', u'46', u'47', u'48', u'49', u'50', u'51',u'52', u'Type', u'Creation-week', u'NbLFN', \n",
      "             u'LFNSize', u'NbDisk', u'DiskSize', u'NbTape', u'TapeSize', u'NbArchived', u'ArchivedSize', u'Nb Replicas', \n",
      "             u'Nb ArchReps', u'FirstUsage', u'LastUsage', u'Now']\n",
      "\"\"\"\n",
      "variables = [ u'Configuration', u'ProcessingPass', u'FileType', \n",
      "             u'26', u'27', u'28', u'29', u'30', u'31', u'32', u'33', u'34', u'35', u'36', u'37', u'38', u'39', u'40', u'41', \n",
      "             u'42', u'43', u'44', u'45', u'46', u'47', u'48', u'49', u'50', u'51',u'52', 'First', 'Last', 'Interval','Type',\n",
      "             u'Creation-week', u'NbLFN', u'LFNSize', u'NbDisk', u'DiskSize', u'NbTape', u'TapeSize', u'NbArchived', u'ArchivedSize',\n",
      "             u'Nb Replicas', u'Nb ArchReps', u'FirstUsage']\n",
      "\n",
      "print variables"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cern_utils import sklearn_classifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "# configuring classifier\n",
      "\"\"\"\n",
      "classifier = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0,\n",
      "                                        min_samples_split=2, min_samples_leaf=1, max_depth=3, init=None, random_state=None, \n",
      "                                        max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False)\n",
      "\"\"\"\n",
      "\"\"\"\n",
      "classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
      "            max_depth=6, max_features=None, min_density=None,\n",
      "            min_samples_leaf=1, min_samples_split=2, random_state=None,\n",
      "            splitter='best'), n_estimators=2000, learning_rate=0.1, algorithm='SAMME.R', random_state=None)\n",
      "\"\"\"\n",
      "\n",
      "gbc = sklearn_classifier.ClassifierSklearn(base_classifier=GradientBoostingClassifier(n_estimators=1500, learning_rate=0.05,max_depth=6),\n",
      "                                           directory='cern_time_series_classification_gbc/')\n",
      "\n",
      "\"\"\"\n",
      "gbc = sklearn_classifier.ClassifierSklearn(base_classifier=classifier,\n",
      "                                           directory='cern_time_series_classification_gbc/')\n",
      "\"\"\"\n",
      "\n",
      "gbc.set_params(features=variables)\n",
      "\n",
      "# training classifier\n",
      "gbc.fit(signal_train, bck_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get prediction on data after classification\n",
      "from cern_utils.predictions_report import PredictionsInfo\n",
      "report = PredictionsInfo({'GBC': gbc}, signal_test, bck_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot importances of features according to trained model\n",
      "importance = gbc.get_feature_importance()\n",
      "importance.sort(['effect'], ascending=False)[['effect']].plot(figsize=(13,3), kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curves to see possible overfitting of trained classifier\n",
      "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
      "\n",
      "def deviance(y_true, y_pred, sample_weight):\n",
      "    return gbc.base_classifier.loss_(y_true, y_pred)\n",
      "\n",
      "def roc_auc(y_true, y_pred, sample_weight):\n",
      "    return roc_auc_score(y_true, y_pred)  \n",
      "\n",
      "def average_precision(y_true, y_pred, sample_weight):\n",
      "    return average_precision_score(y_true, y_pred)  \n",
      "\n",
      "\n",
      "report.learning_curve( { 'roc_auc':roc_auc, 'average_precision':average_precision}, steps=1).plot(figsize = (7,5))\n",
      "plt.subplot(1,1,1)\n",
      "report.learning_curve( {'devianse': deviance}, steps=1).plot(figsize = (7,5))\n",
      "plt.subplot(1,1,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "plt.plot(gbc.base_classifier.train_score_)\n",
      "plt.title('Train Score')\n",
      "plt.xlabel('Iterations')\n",
      "plt.ylabel('Deviance')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Correlation matrix\n",
      "report.features_correlation_matrix().plot(show_legend=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Features histogramms\n",
      "hist_var = variables[:]\n",
      "hist_var.remove(u'NbTape')\n",
      "hist_var.remove(u'TapeSize')\n",
      "report.features_pdf(features=hist_var, bins = 10).plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "report.roc().plot(xlim=(0, 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define metric functions\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.metrics import precision_score\n",
      "\n",
      "\n",
      "import numpy\n",
      "\n",
      "\n",
      "def accuracy(s, b, t_s, t_b, s_NORM=1., b_NORM = 1.): \n",
      "\n",
      "    return (s + t_b - b)/(t_s + t_b)\n",
      "\n",
      "def precision(s, b, t_s, t_b, s_NORM=1., b_NORM = 1.):\n",
      "    return 1- b/t_b\n",
      "\n",
      "report.metrics_vs_cut({'precision': precision, 'accuracy': accuracy}).plot(new_plot=True, figsize=(8, 4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "report.prediction_pdf(bins = 20, normed = True, plot_type='bar').plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def ReleaseMemory(cut = 0.9):\n",
      "\n",
      "    signal_release = (report.prediction_sig['GBC'] >= cut)*1\n",
      "    bck_release = (report.prediction_bck['GBC'] >= cut)*1\n",
      "\n",
      "    released_memory = (signal_release*signal_test.get_data(['DiskSize']).values[:,0]).sum() + (bck_release*bck_test.get_data(['DiskSize']).values[:,0]).sum()\n",
      "    good_memory = (signal_release*signal_test.get_data(['DiskSize']).values[:,0]).sum()\n",
      "\n",
      "    part_of_good_memory = good_memory/released_memory*100\n",
      "    \n",
      "    return released_memory, good_memory, part_of_good_memory\n",
      "\n",
      "def ReleaseMemoryPlot(mincut = 0.9, maxcut = 1, N = 100):\n",
      "    step = (maxcut - mincut)/N\n",
      "    cuts = [mincut + step*i for i in range(0, N+1)]\n",
      "    \n",
      "    released_memory = []\n",
      "    good_memory = []\n",
      "    part_of_good_memory = []\n",
      "    \n",
      "    all_memory = signal_test.get_data(['DiskSize']).values[:,0].sum() + bck_test.get_data(['DiskSize']).values[:,0].sum()\n",
      "    memory_can_be_free = signal_test.get_data(['DiskSize']).values[:,0].sum()\n",
      "    \n",
      "    for i in cuts:\n",
      "        rm, gm, pm = ReleaseMemory(cut = i)\n",
      "        released_memory.append(rm)\n",
      "        good_memory.append(gm)\n",
      "        part_of_good_memory.append(pm)\n",
      "    \n",
      "    print 'all_memory = ', all_memory\n",
      "    print 'memory_can_be_free = ', memory_can_be_free\n",
      "    \n",
      "    plt.subplot(1,1,1)\n",
      "    plt.plot(cuts, released_memory, 'b', label = 'released memory')\n",
      "    plt.plot(cuts, good_memory, 'r', label = 'good memory')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.show()\n",
      "    \n",
      "    plt.subplot(1,1,1)\n",
      "    plt.plot(cuts, part_of_good_memory, 'r', label = 'part of good memory')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.show()\n",
      "       \n",
      "        \n",
      "ReleaseMemoryPlot(mincut = 0.1, maxcut = 1, N = 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Select data\n",
      "selection2 = ((data['Now'] - data['Creation-week']) > 26)&((data['Now'] - data['FirstUsage']) > 26)&((data[78] - data[1]) != 0)\n",
      "data_sel2 = data[selection2].copy()\n",
      "#data_sel2 = data.copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Transform string features to digits\n",
      "df_str2 = data_sel2.get(cols_str)\n",
      "\n",
      "for col in cols_str:\n",
      "    unique = np.unique(df_str2[col])\n",
      "    index = range(0, len(unique))\n",
      "    mapping = dict(zip(unique, index))\n",
      "    df_str2 = df_str2.replace({col:mapping})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get normed series\n",
      "cols_series2 = range(27, 79)\n",
      "df_series2 = data_sel2.get(cols_series2).copy()\n",
      "df_c2 = data_sel2.get(cols_series2).copy()\n",
      "\n",
      "df_series2[27] = 0\n",
      "for i in range(28, 79):\n",
      "    df_series2[i] = df_c2[i] - df_c2[i-1]\n",
      "\n",
      "df_series2 = pd.rolling_mean(df_series2, window = 26, axis = 1).get(range(52,79))\n",
      "\n",
      "\n",
      "mins2 = df_series2.min(axis = 1)\n",
      "maxs2 = df_series2.max(axis = 1)\n",
      "\n",
      "for col in range(52,79):\n",
      "    df_series2[col] = (df_series2[col]-mins2)/(maxs2-mins2+1)\n",
      "\n",
      "df_series2.columns = range(26,53)\n",
      "df_series2.columns\n",
      "    \n",
      "#Add new features\n",
      "first_usage2 = np.nan_to_num(df_c2[df_c2 != 0].idxmin(axis = 1).values)\n",
      "last_usage2 = np.nan_to_num(df_c2[df_c2 > 0].idxmax(axis = 1).values)\n",
      "interval_usage2 = last_usage2 - first_usage2\n",
      "\n",
      "df_series2['First'] = first_usage2\n",
      "df_series2['Last'] = last_usage2\n",
      "df_series2['Interval'] = interval_usage2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df_series2.columns = range(26,53)\n",
      "#df_series2.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get other features\n",
      "df_other2 = data_sel2.get(cols_other)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Label the data\n",
      "labels2 = ((data_sel2[104] - data_sel2[78]) == 0)*1\n",
      "labels2.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Concatenate all data sets\n",
      "data_use2 = pd.concat([df_str2,df_series2,df_other2], axis = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Preparing signal and background data for classifier\n",
      "data_sig2 = data_use2[labels2 == 1]\n",
      "data_bck2 = data_use2[labels2 == 0]\n",
      "\n",
      "#save signal and background data for classifier\n",
      "data_sig2.to_csv('/home/mikhail91/Documents/LBox/Cern_Time_Series/Classification/data_sig2_rolling_mean_original_classifier_10_13.csv')\n",
      "data_bck2.to_csv('/home/mikhail91/Documents/LBox/Cern_Time_Series/Classification/data_bck2_rolling_mean_original_classifier_10_13.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "#ipykee.create_project(\"B._Classification\", internal_path=\"B._Classification\", repository=\"git@github.com:hushchyn-mikhail/CERN_Time_Series.git\")\n",
      "session = ipykee.Session(project_name=\"B._Classification\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.add(report2.roc(), \"report2.roc()\")\n",
      "\n",
      "session.add(report2.prediction_sig['GBC'], \"report2.prediction_sig['GBC']\")\n",
      "\n",
      "session.add(report2.prediction_bck['GBC'], \"report2.prediction_bck['GBC']\")\n",
      "\n",
      "session.add(report2.prediction_pdf(bins = 20, normed = True, plot_type='bar'), \"report2.prediction_pdf()\")\n",
      "\n",
      "a=1\n",
      "session.add(a, \"test\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Preparing signal and background data for classifier\n",
      "data_sig2 = data_use2[labels2 == 1]\n",
      "data_bck2 = data_use2[labels2 == 0]\n",
      "\n",
      "#save signal and background data for classifier\n",
      "data_sig2.to_csv('../../Cern_Time_Series/Classification/data_sig2_rolling_mean_original_classifier_10_13.csv')\n",
      "data_bck2.to_csv('../../Cern_Time_Series/Classification/data_bck2_rolling_mean_original_classifier_10_13.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert data to DataStorage\n",
      "from cern_utils import converter_csv\n",
      "\n",
      "#Load signal and background data\n",
      "signal_data2 = converter_csv.load_from_csv('../../Cern_Time_Series/Classification/data_sig2_rolling_mean_original_classifier_10_13.csv', sep=',')\n",
      "bck_data2 = converter_csv.load_from_csv('../../Cern_Time_Series/Classification/data_bck2_rolling_mean_original_classifier_10_13.csv', sep=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get train and test data\n",
      "signal_train2, signal_test2 = signal_data2.get_train_test(train_size=0.01)\n",
      "bck_train2, bck_test2 = bck_data2.get_train_test(train_size=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get prediction on data after classification\n",
      "from cern_utils.predictions_report import PredictionsInfo\n",
      "report2 = PredictionsInfo({'GBC': gbc}, signal_test2, bck_test2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Correlation matrix\n",
      "report2.features_correlation_matrix().plot(show_legend=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Features histogramms\n",
      "report2.features_pdf(features=hist_var, bins = 10).plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ROC - curve\n",
      "report2.roc().plot(xlim=(0, 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define metric functions\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.metrics import precision_score\n",
      "\n",
      "\n",
      "report2.metrics_vs_cut({'precision': precision, 'accuracy': accuracy}).plot(new_plot=True, figsize=(8, 4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "report2.prediction_pdf(bins = 20, normed = True, plot_type='bar').plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def ReleaseMemory2(cut = 0.9):\n",
      "\n",
      "    signal_release = (report2.prediction_sig['GBC'] >= cut)*1\n",
      "    bck_release = (report2.prediction_bck['GBC'] >= cut)*1\n",
      "\n",
      "    released_memory = (signal_release*signal_test2.get_data(['DiskSize']).values[:,0]).sum() + (bck_release*bck_test2.get_data(['DiskSize']).values[:,0]).sum()\n",
      "    good_memory = (signal_release*signal_test2.get_data(['DiskSize']).values[:,0]).sum()\n",
      "\n",
      "    part_of_good_memory = good_memory/released_memory*100\n",
      "    \n",
      "    return released_memory, good_memory, part_of_good_memory\n",
      "\n",
      "def ReleaseMemoryPlot2(mincut = 0.9, maxcut = 1, N = 100):\n",
      "    step = (maxcut - mincut)/N\n",
      "    cuts = [mincut + step*i for i in range(0, N+1)]\n",
      "    \n",
      "    released_memory = []\n",
      "    good_memory = []\n",
      "    part_of_good_memory = []\n",
      "    \n",
      "    all_memory = signal_test2.get_data(['DiskSize']).values[:,0].sum() + bck_test2.get_data(['DiskSize']).values[:,0].sum()\n",
      "    memory_can_be_free = signal_test2.get_data(['DiskSize']).values[:,0].sum()\n",
      "    \n",
      "    for i in cuts:\n",
      "        rm, gm, pm = ReleaseMemory2(cut = i)\n",
      "        released_memory.append(rm)\n",
      "        good_memory.append(gm)\n",
      "        part_of_good_memory.append(pm)\n",
      "    \n",
      "    print 'all_memory = ', all_memory\n",
      "    print 'memory_can_be_free = ', memory_can_be_free\n",
      "    \n",
      "    plt.subplot(1,1,1)\n",
      "    plt.plot(cuts, released_memory, 'b', label = 'released memory')\n",
      "    plt.plot(cuts, good_memory, 'r', label = 'good memory')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.show()\n",
      "    \n",
      "    plt.subplot(1,1,1)\n",
      "    plt.plot(cuts, part_of_good_memory, 'r', label = 'part of good memory')\n",
      "    plt.legend(loc = 'best')\n",
      "    plt.show()\n",
      "       \n",
      "        \n",
      "ReleaseMemoryPlot2(mincut = 0.1, maxcut = 1, N = 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ipykee\n",
      "#ipykee.create_project(\"B._Classification\", internal_path=\"B._Classification\", repository=\"git@github.com:hushchyn-mikhail/CERN_Time_Series.git\")\n",
      "session = ipykee.Session(project_name=\"B._Classification\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session.add(report2.roc(), \"report2.roc()\")\n",
      "\n",
      "session.add(report2.prediction_sig['GBC'], \"report2.prediction_sig['GBC']\")\n",
      "\n",
      "session.add(report2.prediction_bck['GBC'], \"report2.prediction_bck['GBC']\")\n",
      "\n",
      "session.add(report2.prediction_pdf(bins = 20, normed = True, plot_type='bar'), \"report2.prediction_pdf()\")\n",
      "\n",
      "a=1\n",
      "session.add(a, \"test\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    }
   ],
   "metadata": {}
  }
 ]
}